# Stimatrix ML Pipeline

Un pipeline modulare di machine learning per la stima automatica dei prezzi immobiliari, con funzionalitÃ  avanzate di preprocessing, feature engineering e training di modelli.

## ğŸ¯ Obiettivo

Questo progetto implementa un sistema completo per l'analisi e la predizione di prezzi immobiliari attraverso:
- **Feature extraction** automatica da geometrie WKT e dati GeoJSON
- **Preprocessing** modulare con imputazione, encoding e scaling
- **Training** di modelli ML (alberi decisionali, linear models, boosting, CatBoost)
- **Ottimizzazione** degli iperparametri con Optuna
- **Valutazione** con metriche avanzate e SHAP analysis

## ğŸš€ Quick Start

### Prerequisiti
- **Python 3.13+**
- Virtual environment (raccomandato)

### Installazione
```bash
# Clona il repository
git clone <repository-url>
cd stimatrix-ml-pipeline

# Crea virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Linux/macOS
# oppure
.venv\Scripts\activate     # Windows

# Installa dipendenze
pip install -r requirements.txt
```

### Esecuzione
```bash
# Esegui l'intera pipeline
python main.py --config config/config.yaml --steps all

# Oppure step specifici
python main.py --config config/config.yaml --steps preprocessing training
```

## ğŸ“‚ Struttura del Progetto

```
stimatrix-ml-pipeline/
â”œâ”€â”€ main.py                 # ğŸ® Orchestratore CLI principale
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml         # âš™ï¸ Configurazione pipeline
â”œâ”€â”€ src/                    # ğŸ“¦ Codice sorgente
â”‚   â”œâ”€â”€ dataset_builder/    # ğŸ—„ï¸ Retrieval dati dal database
â”‚   â”œâ”€â”€ db/                 # ğŸ”Œ UtilitÃ  database e schema extraction
â”‚   â”œâ”€â”€ preprocessing/      # ğŸ”§ Pipeline preprocessing e feature engineering
â”‚   â”œâ”€â”€ training/           # ğŸ¤– Training, tuning e valutazione modelli
â”‚   â””â”€â”€ utils/              # ğŸ› ï¸ Logging, I/O e utilitÃ  generali
â”œâ”€â”€ tests/                  # ğŸ§ª Test suite completa
â”œâ”€â”€ data/                   # ğŸ“Š Dati (ignorati da git)
â”‚   â”œâ”€â”€ raw/                # Dati grezzi
â”‚   â””â”€â”€ preprocessed/       # Dati processati
â””â”€â”€ models/                 # ğŸ¯ Modelli salvati (ignorati da git)
```

## ğŸ§ª Testing

### Test Rapidi (Raccomandato)
```bash
# Linux/macOS
./run_tests.sh basic

# Windows
run_tests.bat basic
```

I test di base verificano:
- âœ… Import di tutti i moduli
- âœ… Feature extraction da geometrie WKT
- âœ… Validazione e preprocessing dati
- âœ… Training dei modelli
- âœ… Sistema di logging

### Test Completi
```bash
# Linux/macOS
./run_tests.sh all

# Windows
run_tests.bat all
```

### ModalitÃ  Test Disponibili

| Comando | Descrizione |
|---------|-------------|
| `basic` | Test essenziali senza dipendenze pesanti |
| `all` | Suite completa con pytest |
| `features` | Test feature extractors |
| `preprocessing` | Test pipeline preprocessing |
| `training` | Test training modelli |
| `coverage` | Test con report di copertura |
| `verbose` | Output dettagliato |

## âš™ï¸ Configurazione

Il file `config/config.yaml` controlla tutti gli aspetti della pipeline:

### Sezioni Principali

- **`paths`**: Percorsi input/output per dati e modelli
- **`target`**: Configurazione variabile target e trasformazioni
- **`feature_extraction`**: Estrazione da geometrie WKT e JSON
- **`temporal_split`**: Split temporale per evitare data leakage
- **`outliers`**: Rimozione outlier per gruppo o globale
- **`imputation`**: Strategie di imputazione per numeriche/categoriche
- **`encoding`**: Piani di encoding (OHE/ordinal) con gestione cardinalitÃ 
- **`profiles`**: Tre profili predefiniti (`scaled`, `tree`, `catboost`)
- **`training`**: Configurazione modelli, tuning e valutazione

### Profili di Preprocessing

1. **`scaled`**: Per modelli lineari e reti neurali
   - Encoding categorico completo
   - Scaling e PCA opzionale
   - Winsorization outlier

2. **`tree`**: Per modelli ad albero (Random Forest, XGBoost)
   - Encoding semplificato
   - Preservazione informazione ordinale
   - Pruning correlazioni

3. **`catboost`**: Per CatBoost nativo
   - Mantenimento variabili categoriche
   - Preprocessing minimo
   - Gestione automatica delle categorie

## ğŸ”§ Pipeline di Preprocessing

### Flusso Principale

1. **Caricamento Dati**: Import da `data/raw/*.parquet`
2. **Feature Extraction**:
   - **WKT Geometries**: `POINT` â†’ coordinate x,y; `POLYGON` â†’ conteggio vertici; `MULTIPOLYGON` â†’ statistiche avanzate
   - **GeoJSON**: Estrazione `areaMq`, `perimetroM`, codici catastali, bounding box
3. **Normalizzazioni**:
   - **Superfici**: Unificazione in `AI_Superficie` (mÂ²)
   - **Piani**: Feature engineering robusto con parsing di token complessi
   - **Indirizzi**: Estrazione parte numerica da `AI_Civico`
4. **Split Temporale**: Divisione train/validation/test basata su timestamp
5. **Outlier Detection**: Rimozione outlier con metodi configurabili
6. **Imputazione**: Gestione valori mancanti per tipo di variabile
7. **Encoding**: Trasformazione variabili categoriche
8. **Scaling/PCA**: Normalizzazione e riduzione dimensionalitÃ  (profilo `scaled`)

### Feature Engineering Avanzato

- **Geometrie WKT**: Parsing nativo senza dipendenze GIS
- **Piano Building**: Riconoscimento pattern complessi (P1-P12, S/S1/S2, PT/T/ST, RIAL, AMMEZZATO)
- **Coercizione Numerica**: Conversione automatica con blacklist configurabile
- **Temporal Keys**: Creazione chiavi temporali da anno/mese stipula

## ğŸ¤– Training e Modelli

### Modelli Supportati

- **Linear Models**: Ridge, Lasso, Elastic Net
- **Tree-based**: Random Forest, Extra Trees
- **Boosting**: XGBoost, LightGBM, CatBoost
- **Ensemble**: Stacking e averaging

### Ottimizzazione

- **Optuna**: Hyperparameter tuning automatico
- **Cross-validation**: Validazione robusta dei risultati
- **Early stopping**: Prevenzione overfitting
- **Parallelizzazione**: Supporto multi-core configurabile

### Valutazione

- **Metriche**: MAE, RMSE, RÂ², MAPE
- **SHAP Analysis**: InterpretabilitÃ  dei modelli
- **Validation**: Split temporale per prevenire data leakage

## ğŸ“Š Output

### Dati Preprocessati
```
data/preprocessed/
â”œâ”€â”€ scaled/          # Dati per modelli lineari
â”œâ”€â”€ tree/            # Dati per modelli ad albero  
â”œâ”€â”€ catboost/        # Dati per CatBoost
â””â”€â”€ preprocessed.parquet  # Dataset combinato
```

### Modelli Addestrati
```
models/
â”œâ”€â”€ model_*.pkl      # Modelli serializzati
â”œâ”€â”€ scaler_*.pkl     # Oggetti di scaling
â””â”€â”€ shap/            # Report di interpretabilitÃ 
```

## ğŸ” Troubleshooting

### Problemi Comuni

| Problema | Soluzione |
|----------|-----------|
| Errori di import | Verifica `PYTHONPATH` o esegui via `main.py` |
| Pacchetti mancanti | Attiva virtual environment e reinstalla `requirements.txt` |
| File raw assente | Posiziona dati in `data/raw/raw.parquet` |
| Test falliscono | Prova `./run_tests.sh basic` per verificare setup |
| Memory error | Riduci batch size o abilita processing incrementale |

### Logging e Debug

Il sistema di logging Ã¨ configurabile tramite `config.yaml`:
- **Livelli**: DEBUG, INFO, WARNING, ERROR
- **Output**: Console e file rotating
- **Filtri**: Per modulo e categoria

## ğŸ”’ Sicurezza e Privacy

- **Dati sensibili**: Non committare mai dati reali
- **Credenziali**: Usa file `.env` per configurazioni sensibili
- **Modelli**: I modelli addestrati sono esclusi dal version control

## ğŸ“ Sviluppo

### Contribuire al Progetto

1. **Fork** del repository
2. **Branch**: Crea feature branch (`git checkout -b feature/amazing-feature`)
3. **Test**: Esegui test suite (`./run_tests.sh all`)
4. **Commit**: Commit con messaggi descrittivi
5. **Push**: Push del branch (`git push origin feature/amazing-feature`)
6. **PR**: Apri Pull Request

### Coding Standards

- **Python**: PEP 8, type hints, docstrings
- **Testing**: Coverage minima 80%
- **Documentation**: Aggiorna README per nuove feature

## ğŸ“œ Licenza

Proprietario. Uso interno.

---

**Sviluppato con â¤ï¸ per l'analisi immobiliare intelligente**