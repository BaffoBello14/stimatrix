# üìã EXECUTIVE SUMMARY: Filtri Sperimentali Dataset 2022+

**Branch**: `cursor/analyze-and-test-data-subset-176c`  
**Data**: 2025-11-14  
**Status**: ‚úÖ VERIFICATO - NO LEAKAGE

---

## üéØ CONFIGURAZIONE ATTUALE

### Filtri Applicati

```yaml
data_filters:
  anno_min: 2022                    # Solo transazioni recenti
  zone_escluse: ['E1','E2','E3','R1']  # Escludi zone periferiche/rurali
  tipologie_escluse: ['4']          # Escludi ville
```

### Obiettivo

Valutare se un **modello specializzato** su:
- ‚úÖ Transazioni recenti (2022+) - riduce temporal drift
- ‚úÖ Zone urbane/semicentrali - escluse periferie/rurali
- ‚úÖ Residenziale standard - escluse ville (mercato di nicchia)

...performa meglio di un modello generico su tutto il dataset.

---

## ‚úÖ VERIFICA NON-LEAKAGE

### 1. Filtri Pre-Split

I filtri sono applicati **PRIMA** dello split train/val/test:
- ‚úÖ Tutti gli split vedono lo stesso subset
- ‚úÖ No information leakage tra split
- ‚úÖ Feature contestuali calcolate solo su dati post-filtro

### 2. Feature Contestuali

**Rimosso** tutte le feature che richiedono il target dell'istanza:
```python
# ‚ùå REMOVED (9 feature):
- price_vs_zone_mean_ratio
- price_zone_zscore
- prezzo_mq
- price_vs_temporal_mean
# ... altre 5 feature
```

**Mantenuto** solo feature calcolabili senza target:
```python
# ‚úÖ KEEP:
- zone_price_mean/median/std  (statistiche aggregate)
- zone_count, type_zone_count  (conteggi)
- surface_vs_zone_mean  (usa solo superficie)
- temporal_count  (conteggi temporali)
```

### 3. Encoding

Test automatici verificano:
- ‚úÖ Encoder fit solo su train
- ‚úÖ Categorie unseen gestite correttamente
- ‚úÖ No leakage tra train/val/test

**Coverage**: `tests/test_encoding_no_leakage.py` (267 righe, 8 test)

---

## üìä IMPATTO STIMATO

### Dataset Raw

```
Righe totali:        5,733
Target:              AI_Prezzo_Ridistribuito
Mean:                ‚Ç¨62,592
Median:              ‚Ç¨42,000
Range:               ‚Ç¨179 - ‚Ç¨1,483,526
Skewness:            5.16 (molto asimmetrico)
```

### Filtri

| Filtro | Righe Rimosse | % Dataset | Note |
|--------|--------------|-----------|------|
| **Zone escluse** (E1/E2/E3/R1) | ~153 | 2.7% | Minimo impatto |
| **Tipologie escluse** (ville) | ~41 | 0.7% | Minimo impatto |
| **Anno >= 2022** | ‚ö†Ô∏è **DA VERIFICARE** | **40-60%?** | **Impatto maggiore** |

‚ö†Ô∏è **CRITICO**: Il filtro temporale potrebbe rimuovere la maggioranza dei dati!

### Stima Dataset Finale

**Scenario conservativo** (dataset originale 2019-2023):
```
Dataset finale:      ~3,000 righe (52% originale)
Split 70/20/10:
  - Train:           ~2,100 righe
  - Validation:      ~600 righe
  - Test:            ~300 righe
```

**Scenario ottimistico** (dataset originale 2021-2023):
```
Dataset finale:      ~4,500 righe (78% originale)
Split 70/20/10:
  - Train:           ~3,150 righe
  - Validation:      ~900 righe
  - Test:            ~450 righe
```

---

## üö® RACCOMANDAZIONI PRIORITARIE

### 1. VERIFICA DIMENSIONE DATASET

```bash
# PRIMA di procedere con training, esegui:
python analyze_filters_impact.py
```

Questo script:
- ‚úÖ Mostra distribuzione temporale completa
- ‚úÖ Calcola esattamente quante righe vengono rimosse
- ‚úÖ Confronta statistiche target pre/post filtri
- ‚úÖ Valuta se dataset finale √® sufficiente per training

**Threshold critici**:
- üö® < 2,000 righe finale ‚Üí Dataset troppo piccolo, ridurre complessit√† modelli
- ‚ö†Ô∏è < 3,000 righe finale ‚Üí Usare `config_fast.yaml` (5 trial vs 150)
- ‚úÖ > 4,000 righe finale ‚Üí OK per `config.yaml` (150 trial)

### 2. ADATTA CONFIGURAZIONE

Se dataset < 3,000 righe:

```yaml
# Usa config_fast.yaml
training:
  trials_advanced: 5  # invece di 150
  
  ensembles:
    stacking:
      cv_folds: 5  # invece di 10

# Aumenta regularizzazione
models:
  catboost:
    base_params:
      depth: 4  # ridotto da 7
      l2_leaf_reg: 10.0  # aumentato
```

### 3. BASELINE COMPARISON

```bash
# 1. Train su dataset COMPLETO (no filtri)
# Disabilita temporaneamente i filtri in config.yaml
data_filters:
  anno_min: null
  zone_escluse: null
  tipologie_escluse: null

python main.py --config fast --steps preprocessing training evaluation

# 2. Train su dataset FILTRATO (config attuale)
# Riabilita i filtri
python main.py --config fast --steps preprocessing training evaluation

# 3. Confronta metriche
# Modello specializzato ha R¬≤ e RMSE migliori?
```

### 4. ABLATION STUDY

Identifica quale filtro ha maggior impatto:

```yaml
# Test A: Solo filtro temporale
data_filters:
  anno_min: 2022
  zone_escluse: null
  tipologie_escluse: null

# Test B: Solo filtro zone
data_filters:
  anno_min: null
  zone_escluse: ['E1','E2','E3','R1']
  tipologie_escluse: null

# Confronta performance ‚Üí quale filtro migliora di pi√π?
```

---

## üìà METRICHE ATTESE

### Scenario Ottimistico (filtri efficaci)

```
Baseline (no filtri):
  R¬≤:      0.75
  RMSE:    ‚Ç¨38,000
  MAPE:    52%

Con filtri:
  R¬≤:      0.82  ‚úÖ (+7 punti)
  RMSE:    ‚Ç¨30,000  ‚úÖ (-21%)
  MAPE:    42%  ‚úÖ (-10 punti)
```

### Scenario Realistico

```
Baseline:
  R¬≤:      0.75
  RMSE:    ‚Ç¨38,000
  MAPE:    52%

Con filtri:
  R¬≤:      0.78  ‚ö†Ô∏è (+3 punti, leggero miglioramento)
  RMSE:    ‚Ç¨35,000  ‚ö†Ô∏è (-8%)
  MAPE:    48%  ‚ö†Ô∏è (-4 punti)
```

**Trade-off**: Migliore performance su subset, ma modello **non generalizza** a:
- Transazioni pre-2022
- Zone periferiche/rurali (E1/E2/E3/R1)
- Ville (tipologia 4)

---

## ‚öñÔ∏è DECISIONE: MODELLO SPECIALIZZATO vs GENERALIZZATO

### Quando usare MODELLO SPECIALIZZATO (con filtri)

‚úÖ **PRO**:
- Performance migliore su subset specifico
- Riduce complessit√† (meno eterogeneit√†)
- Riduce temporal drift (solo dati recenti)

‚ùå **CONTRO**:
- Non generalizza fuori dal subset
- Richiede dataset filtrato sufficiente (>2,000 righe)
- Deployment limitato a scope ristretto

**Use Case**: 
- Predizioni solo su transazioni 2022+, zone urbane, residenziale standard
- Applicazione specializzata (es. solo appartamenti semicentrali)

### Quando usare MODELLO GENERALIZZATO (no filtri)

‚úÖ **PRO**:
- Generalizza a tutto il dataset
- Dataset pi√π grande (pi√π robusto)
- Deployment universale

‚ùå **CONTRO**:
- Performance media inferiore (gestisce pi√π eterogeneit√†)
- Maggiore temporal/spatial drift

**Use Case**:
- Predizioni su qualsiasi transazione (passate, future, tutte le zone)
- Applicazione general-purpose

---

## üé¨ PROSSIMI PASSI

### Immediati (oggi)

1. ‚úÖ **Esegui analisi impatto filtri**:
   ```bash
   python analyze_filters_impact.py
   ```

2. ‚úÖ **Verifica dimensione dataset finale**:
   - Se < 2,000 righe ‚Üí üö® Dataset troppo piccolo, considera di ridurre filtri
   - Se 2,000-3,000 righe ‚Üí ‚ö†Ô∏è Usa `config_fast.yaml`
   - Se > 3,000 righe ‚Üí ‚úÖ Usa `config.yaml` o `config_fast.yaml`

3. ‚úÖ **Training baseline** (opzionale ma raccomandato):
   ```bash
   # Disabilita filtri temporaneamente
   python main.py --config fast --steps preprocessing training evaluation
   # Salva metriche per confronto
   ```

### Breve termine (questa settimana)

4. ‚úÖ **Training con filtri**:
   ```bash
   python main.py --config fast --steps preprocessing training evaluation
   ```

5. ‚úÖ **Confronto baseline vs filtrato**:
   - R¬≤, RMSE, MAPE migliorati?
   - Di quanto? (se < 5%, filtri non valgono la perdita di generalizzazione)

6. ‚úÖ **Ablation study** (opzionale):
   - Quale filtro ha maggior impatto?
   - Conviene usare solo alcuni filtri?

### Medio termine (prossime iterazioni)

7. ‚úÖ **Error analysis**:
   ```python
   # Analizza worst predictions
   # Pattern comuni? Zone specifiche? Prezzi estremi?
   ```

8. ‚úÖ **Production readiness**:
   - Documenta scope del modello (solo 2022+, no zone E/R, no ville)
   - Implementa warning per predizioni out-of-distribution
   - Considera A/B test in production (baseline vs specializzato)

---

## üìö DOCUMENTAZIONE

### File Generati

```
/workspace/
  - ANALISI_SUBSET_CONFIG_2022.md       (analisi completa, 654 righe)
  - EXECUTIVE_SUMMARY_FILTERS.md        (questo file, executive summary)
  - analyze_filters_impact.py           (script verifica impatto)
```

### File Chiave da Consultare

```
config/
  - config.yaml                (linee 56-80: data_filters)
  - config_fast.yaml          (filtri identici)

src/preprocessing/
  - pipeline.py               (linee 98-212: apply_data_filters)
  - contextual_features.py    (leak-free features)

tests/
  - test_encoding_no_leakage.py  (verifica no leakage)

notebooks/eda_outputs/
  - target_statistics.csv
  - correlations_with_target.csv
  - group_summary_AI_ZonaOmi.csv
```

---

## ‚úÖ CONCLUSIONE

### Status Attuale

‚úÖ **Configurazione valida**: Filtri applicati correttamente, no leakage  
‚ö†Ô∏è **Da verificare**: Impatto reale filtro temporale sul dataset size  
üìä **Prossimo step**: Eseguire `analyze_filters_impact.py` per confermare fattibilit√†

### Raccomandazione Finale

1. **Esegui analisi**: `python analyze_filters_impact.py`
2. **Se dataset > 3,000 righe** ‚Üí Procedi con training filtrato
3. **Se dataset < 3,000 righe** ‚Üí Valuta riduzione filtri o uso config_fast
4. **Confronta con baseline** ‚Üí Verifica se filtri migliorano realmente performance

**L'architettura √® solida e leak-free. Il successo dipende dalla dimensione del dataset finale dopo filtri.**

---

**Analisi completata il**: 2025-11-14  
**Autore**: Claude (Sonnet 4.5)  
**Contatti**: [team data science]
