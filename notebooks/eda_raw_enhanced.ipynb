# Riepilogo e listing outputs
print("="*60)
print("ðŸ“¦ Riepilogo file generati")
for f in output_dir.rglob('*.csv'):
    print(" -", f.relative_to(output_dir).as_posix())
print("âœ… EDA esteso completato")# Associazioni feature-feature
# 1) Numeriche: Pearson e Spearman
num_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()
num_cols = [c for c in num_cols if df_raw[c].nunique(dropna=True) > 1]

if len(num_cols) >= 2:
    corr_pearson = df_raw[num_cols].corr(method='pearson')
    corr_spearman = df_raw[num_cols].corr(method='spearman')

    # Coppie ad alta correlazione
    pairs = []
    for i, c1 in enumerate(num_cols):
        for c2 in num_cols[i+1:]:
            r = corr_pearson.loc[c1, c2]
            if pd.notna(r) and abs(r) >= high_corr_threshold:
                pairs.append((c1, c2, float(r)))
    pairs_sorted = sorted(pairs, key=lambda x: -abs(x[2]))[:top_k_pairs]
    highcorr_df = pd.DataFrame(pairs_sorted, columns=['col1','col2','pearson_r'])
    display(highcorr_df.head(30))
    corr_pearson.to_csv(associations_dir / 'numeric_numeric_pearson.csv')
    corr_spearman.to_csv(associations_dir / 'numeric_numeric_spearman.csv')
    highcorr_df.to_csv(associations_dir / f'numeric_numeric_highcorr_{int(high_corr_threshold*100)}.csv', index=False)
    print("ðŸ’¾ Salvate matrici e coppie ad alta correlazione (numeriche)")
else:
    print("Poche colonne numeriche per assoc numeriche")

# 2) Categoriche-categoriche: CramÃ©r's V e Theil's U
cat_cols = df_raw.select_dtypes(include=['object','category','bool']).columns.tolist()
# Converti bool in category per coerenza
for c in cat_cols:
    if df_raw[c].dtype == 'bool':
        df_raw[c] = df_raw[c].astype('category')
# Filtra cardinalitÃ 
cat_cols = [c for c in cat_cols if df_raw[c].nunique(dropna=True) <= max_cat_cardinality and df_raw[c].nunique(dropna=True) > 1]

cramers_records = []
theils_records = []
for i, c1 in enumerate(cat_cols):
    for c2 in cat_cols[i+1:]:
        v = cramers_v_corrected(df_raw[c1], df_raw[c2])
        u = theils_u(df_raw[c1], df_raw[c2])
        cramers_records.append((c1, c2, v))
        theils_records.append((c1, c2, u))

if cramers_records:
    cramers_df = pd.DataFrame(cramers_records, columns=['col1','col2','cramers_v']).sort_values('cramers_v', ascending=False)
    theils_df = pd.DataFrame(theils_records, columns=['col1','col2','theils_u']).sort_values('theils_u', ascending=False)
    cramers_df.head(top_k_pairs).to_csv(associations_dir / 'categorical_categorical_top_cramersV.csv', index=False)
    theils_df.head(top_k_pairs).to_csv(associations_dir / 'categorical_categorical_top_theilsU.csv', index=False)
    print("ðŸ’¾ Salvate top associazioni cat-cat (CramÃ©r's V, Theil's U)")
else:
    print("Nessuna coppia cat-cat idonea")

# 3) Miste (num-cat): correlation ratio (eta) e NMI (discretizzando il numerico)
records_eta = []
records_nmi = []
for num in num_cols:
    for cat in cat_cols:
        eta = correlation_ratio(df_raw[cat], df_raw[num])
        # Discretizza num
        dnum = discretize_numeric_series(df_raw[num])
        nmi = normalized_mutual_info_score(dnum, df_raw[cat].astype('category'))
        records_eta.append((cat, num, eta))
        records_nmi.append((cat, num, nmi))

if records_eta:
    eta_df = pd.DataFrame(records_eta, columns=['cat','num','eta']).sort_values('eta', ascending=False)
    nmi_df = pd.DataFrame(records_nmi, columns=['cat','num','nmi']).sort_values('nmi', ascending=False)
    eta_df.head(top_k_pairs).to_csv(associations_dir / 'mixed_cat_num_top_eta.csv', index=False)
    nmi_df.head(top_k_pairs).to_csv(associations_dir / 'mixed_cat_num_top_nmi.csv', index=False)
    print("ðŸ’¾ Salvate top associazioni miste (eta, NMI)")
else:
    print("Nessuna coppia mista calcolata")# Correlazioni con i target (Pearson su numeriche)
for tgt in targets_presenti:
    print("="*60)
    print(f"ðŸ“Š Correlazioni numeriche con {tgt}")
    num_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()
    if tgt in num_cols:
        num_cols.remove(tgt)
    # Rimuovi colonne costanti
    num_cols = [c for c in num_cols if df_raw[c].nunique(dropna=True) > 1]
    data = df_raw[num_cols + [tgt]].dropna()
    if data.empty:
        print("Nessun dato per correlazioni.")
        continue
    corr = data.corr(numeric_only=True)[tgt].drop(tgt, errors='ignore')
    corr_df = (
        pd.DataFrame({'Colonna': corr.index, 'Correlazione': corr.values, 'Assoluta': np.abs(corr.values)})
        .sort_values('Assoluta', ascending=False)
    )
    display(corr_df.head(20))
    out_csv = targets_dir / f'correlations_with_target__{tgt}.csv'
    corr_df.to_csv(out_csv, index=False)
    print(f"ðŸ’¾ Salvato: {out_csv}")# Analisi per-target: statistiche e distribuzioni
for tgt in targets_presenti:
    print("="*60)
    print(f"ðŸŽ¯ Analisi target: {tgt}")
    s = pd.to_numeric(df_raw[tgt], errors='coerce').dropna()
    if s.empty:
        print("Target vuoto, skip")
        continue
    stats = s.describe()
    print(f"count={stats['count']:.0f}, mean={stats['mean']:.2f}, median={stats['50%']:.2f}, std={stats['std']:.2f}, min={stats['min']:.2f}, max={stats['max']:.2f}")
    # Quantili
    qs = s.quantile([0,0.2,0.4,0.6,0.8,1.0])
    print("Quantili:")
    for (q, val) in qs.items():
        print(f"  q{int(q*100):02d}: {val:,.2f}")
    # Grafici
    fig, axes = plt.subplots(1, 2, figsize=(16,6))
    axes[0].hist(s, bins=50, color='skyblue', edgecolor='black')
    axes[0].set_title(f'Istogramma {tgt}')
    axes[0].grid(True, alpha=0.3)
    axes[1].boxplot(s, vert=False)
    axes[1].set_title(f'Boxplot {tgt}')
    axes[1].grid(True, alpha=0.3)
    plt.tight_layout(); plt.show()

    # Log-trasformazione
    s_log = np.log1p(s.clip(lower=1e-6))
    fig, axes = plt.subplots(1, 2, figsize=(16,6))
    axes[0].hist(s_log, bins=50, color='lightgreen', edgecolor='black')
    axes[0].set_title(f'Istogramma log1p({tgt})')
    axes[0].grid(True, alpha=0.3)
    scipy_stats.probplot(s_log.sample(min(len(s_log), 5000), random_state=42), dist='norm', plot=axes[1])
    axes[1].set_title(f'Q-Q plot log1p({tgt})')
    axes[1].grid(True, alpha=0.3)
    plt.tight_layout(); plt.show()

    # Salva stats su CSV
    out_csv = targets_dir / f'target_statistics__{tgt}.csv'
    pd.DataFrame(stats).rename(columns={tgt:'value'}).to_csv(out_csv)
    print(f"ðŸ’¾ Salvato: {out_csv}")# Parametri analisi
high_corr_threshold = 0.90
max_cat_cardinality = 50
top_k_pairs = 30
print(f"Soglie: high_corr_threshold={high_corr_threshold}, max_cat_cardinality={max_cat_cardinality}, top_k_pairs={top_k_pairs}")# Utility funzioni per associazioni
from itertools import combinations
from math import sqrt
from sklearn.metrics import normalized_mutual_info_score

def _safe_crosstab(x, y):
    x = pd.Series(x).astype('category')
    y = pd.Series(y).astype('category')
    return pd.crosstab(x, y)


def cramers_v_corrected(x, y):
    confusion_matrix = _safe_crosstab(x, y).values
    if confusion_matrix.size == 0:
        return np.nan
    chi2 = scipy_stats.chi2_contingency(confusion_matrix, correction=False)[0]
    n = confusion_matrix.sum()
    if n == 0:
        return np.nan
    phi2 = chi2 / n
    r, k = confusion_matrix.shape
    phi2corr = max(0, phi2 - (k - 1) * (r - 1) / (n - 1)) if n > 1 else 0
    rcorr = r - (r - 1) ** 2 / (n - 1) if n > 1 else r
    kcorr = k - (k - 1) ** 2 / (n - 1) if n > 1 else k
    denom = min((kcorr - 1), (rcorr - 1))
    if denom <= 0:
        return np.nan
    return sqrt(phi2corr / denom)


def theils_u(x, y):
    x = pd.Series(x).astype('category')
    y = pd.Series(y).astype('category')
    px = x.value_counts(normalize=True)
    py = y.value_counts(normalize=True)
    h_x = -np.sum(px * np.log2(px + 1e-12))
    if h_x <= 0:
        return np.nan
    h_x_given_y = 0.0
    for lvl, p_y in py.items():
        x_given_y = x[y == lvl]
        pxgy = x_given_y.value_counts(normalize=True)
        h_xgy = -np.sum(pxgy * np.log2(pxgy + 1e-12)) if len(pxgy) > 0 else 0.0
        h_x_given_y += p_y * h_xgy
    return max(0.0, (h_x - h_x_given_y) / (h_x + 1e-12))


def correlation_ratio(categories, measurements):
    cat = pd.Series(categories).astype('category')
    y = pd.to_numeric(pd.Series(measurements), errors='coerce')
    mask = cat.notna() & y.notna()
    cat = cat[mask]
    y = y[mask]
    if len(y) == 0:
        return np.nan
    overall_mean = y.mean()
    classes = cat.cat.categories
    ss_between = 0.0
    ss_total = ((y - overall_mean) ** 2).sum()
    for c in classes:
        y_c = y[cat == c]
        if len(y_c) == 0:
            continue
        ss_between += len(y_c) * (y_c.mean() - overall_mean) ** 2
    if ss_total <= 0:
        return 0.0
    return float(np.sqrt(ss_between / ss_total))


def discretize_numeric_series(s: pd.Series, bins: int = 10) -> pd.Series:
    s = pd.to_numeric(s, errors='coerce')
    s = s.replace([np.inf, -np.inf], np.nan)
    if s.notna().nunique() <= 1:
        return pd.Series(index=s.index, dtype='category')
    try:
        q = pd.qcut(s, q=min(bins, s.nunique()), duplicates='drop')
    except Exception:
        q = pd.cut(s, bins=min(bins, max(2, s.nunique())), include_lowest=True)
    return q.astype('category')# Directory aggiuntive
targets_dir = output_dir / 'targets'
associations_dir = output_dir / 'associations'
for d in [targets_dir, associations_dir]:
    d.mkdir(parents=True, exist_ok=True)
print(f"ðŸ“ Dir targ: {targets_dir}")
print(f"ðŸ“ Dir assoc: {associations_dir}")# Setup
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import yaml
from pathlib import Path
from scipy import stats as scipy_stats
import warnings
warnings.filterwarnings('ignore')

plt.style.use('default')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

output_dir = Path('eda_outputs')
output_dir.mkdir(parents=True, exist_ok=True)
print(f"ðŸ“ Output dir: {output_dir}")

# Carica config e dati
config_path = '../config/config.yaml'
with open(config_path, 'r', encoding='utf-8') as f:
    config = yaml.safe_load(f)

raw_path = '../data/raw/raw.parquet'
df_raw = pd.read_parquet(raw_path)
print(f"âœ… Dati caricati: {df_raw.shape}")

# Target principali
preferred_targets = config.get('target', {}).get('column_candidates', ['AI_Prezzo_Ridistribuito','AI_Prezzo_MQ'])
targets_presenti = [t for t in preferred_targets if t in df_raw.columns]
if not targets_presenti:
    raise ValueError("Nessun target presente nel dataset tra i candidati")
print(f"ðŸŽ¯ Target trovati: {targets_presenti}")