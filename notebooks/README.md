# ğŸ““ Notebooks - Analisi e Sperimentazione

Questa cartella contiene i notebook Jupyter per l'analisi esplorativa dei dati (EDA), la sperimentazione di strategie di preprocessing e l'analisi dei risultati dei modelli.

## ğŸ“‹ Indice dei Notebook

### ğŸ” Analisi Esplorativa

#### 1. [`eda_project_analysis.ipynb`](eda_project_analysis.ipynb)
**Analisi esplorativa completa del dataset**

**Obiettivo**: Comprendere la struttura, distribuzione e qualitÃ  dei dati

**Analisi incluse**:
- ğŸ“Š Statistiche descrittive complete
- ğŸ“ˆ Distribuzione delle variabili numeriche e categoriche
- ğŸ—ºï¸ Analisi geografica (zone OMI, comuni)
- ğŸ  Analisi tipologie immobiliari
- ğŸ’° Distribuzione prezzi e target variable
- ğŸ”— Correlazioni tra features
- âŒ Missing values e data quality
- ğŸ“Š Outliers detection e analisi

**Prerequisiti**: 
```bash
# Nessun prerequisito - usa i dati raw
```

**Output**: Grafici e insights salvati in `eda_outputs/`

---

#### 2. [`outlier_detection_analysis.ipynb`](outlier_detection_analysis.ipynb)
**Analisi approfondita degli outliers**

**Obiettivo**: Identificare e analizzare outliers nei dati per decidere strategie di gestione

**Analisi incluse**:
- ğŸ¯ Detection con metodi multipli (IQR, Z-score, Isolation Forest, LOF)
- ğŸ“Š Distribuzione outliers per feature
- ğŸ—ºï¸ Distribuzione geografica degli outliers
- ğŸ’¡ Impact analysis: effetto sulle metriche del modello
- ğŸ”§ Strategie di gestione (rimozione, capping, winsorization)

**Prerequisiti**: 
```bash
python main.py --config config/config.yaml --steps retrieve
```

**Output**: Report outliers salvati in `outlier_outputs/`

---

### ğŸ§ª Sperimentazione Preprocessing

#### 3. [`encoding_strategies_comparison.ipynb`](encoding_strategies_comparison.ipynb)
**Confronto strategie di encoding per variabili categoriche**

**Obiettivo**: Confrontare diverse tecniche di encoding per scegliere la migliore

**Strategie testate**:
- ğŸ”¢ **One-Hot Encoding**: Creazione colonne binarie
- ğŸ“Š **Target Encoding**: Encoding basato su media target
- ğŸ¯ **Frequency Encoding**: Encoding basato su frequenza
- ğŸ”„ **Leave-One-Out Encoding**: Target encoding con LOO per evitare leakage
- ğŸ“ˆ **Weight of Evidence (WoE)**: Encoding per regressione logistica
- ğŸ† **CatBoost Encoding**: Encoding ottimizzato per CatBoost

**Metriche confronto**:
- Performance modello (RÂ², MAE, RMSE)
- Training time
- DimensionalitÃ  risultante
- Robustezza a overfitting

**Prerequisiti**: 
```bash
python main.py --config config/config.yaml --steps retrieve
```

**Output**: Report comparativo salvato in `encoding_comparison_outputs/`

---

#### 4. [`target_transformations_comparison.ipynb`](target_transformations_comparison.ipynb)
**Confronto trasformazioni del target variable**

**Obiettivo**: Testare trasformazioni del target per migliorare performance e normalitÃ  residui

**Trasformazioni testate**:
- ğŸ”„ **Log Transform**: `log(y)` - per distribuzioni right-skewed
- ğŸ“¦ **Box-Cox**: Trasformazione parametrica ottimale
- ğŸ¯ **Yeo-Johnson**: Come Box-Cox ma gestisce valori negativi
- âˆš **Square Root**: `sqrt(y)` - trasformazione moderata
- ğŸ“ **Quantile Transform**: Mapping a distribuzione uniforme/normale

**Analisi**:
- Impatto su normalitÃ  residui
- Performance metriche (prima e dopo trasformazione)
- StabilitÃ  train/test
- InterpretabilitÃ  risultati

**Prerequisiti**: 
```bash
python main.py --config config/config.yaml --steps preprocess
```

**Output**: Report trasformazioni salvato in `target_transform_outputs/`

---

### ğŸ“Š Analisi Risultati

#### 5. [`model_results_deep_analysis.ipynb`](model_results_deep_analysis.ipynb)
**Analisi approfondita dei risultati dei modelli trainati**

**Obiettivo**: Valutare performance, identificare problemi e suggerire miglioramenti

**Analisi incluse**:
- ğŸ“Š **Model Comparison**: Confronto tra tutti i modelli trainati
- ğŸ† **Best Model Selection**: Identificazione modello ottimale
- ğŸ“‰ **Overfitting Analysis**: Gap train-test e generalizzazione
- ğŸ¯ **Group Performance**: Errori per categoria catastale, zona OMI, tipologia
- âŒ **Worst Predictions**: Analisi predizioni peggiori
- ğŸ“ˆ **Residual Analysis**: Distribuzione e pattern nei residui
- ğŸ“Š **Prediction Intervals**: Coverage e calibrazione intervalli di confidenza

**Metriche analizzate**:
- RÂ² (coefficient of determination)
- MAE (Mean Absolute Error)
- RMSE (Root Mean Squared Error)
- MAPE (Mean Absolute Percentage Error)

**Prerequisiti**: 
```bash
python main.py --config config/config.yaml --steps train
```

**Output**: Report completo salvato in `model_analysis_outputs/`

**File generati**:
- `00_analysis_summary.json` - Summary completo
- `01_model_comparison.csv` - Confronto modelli
- `02-08_*.png` - Grafici analisi
- `07_prediction_intervals.csv` - Analisi intervalli

---

## ğŸ› ï¸ Utility

### [`eda_utils.py`](eda_utils.py)
**Funzioni di supporto per EDA**

Contiene funzioni helper per:
- Plot standardizzati
- Statistiche comuni
- Formattazione output
- Color schemes

Importato automaticamente nei notebook EDA.

---

## ğŸš€ Quick Start

### 1. Setup Environment
```bash
# Attiva virtual environment
source venv/bin/activate  # Linux/Mac
# oppure
venv\Scripts\activate  # Windows

# Installa dipendenze
pip install -r requirements.txt
```

### 2. Run Pipeline (per avere dati per i notebook)
```bash
# Retrieve data
python main.py --config config/config.yaml --steps retrieve

# Preprocess
python main.py --config config/config.yaml --steps preprocess

# Train models
python main.py --config config/config.yaml --steps train
```

### 3. Open Notebooks
```bash
# Avvia Jupyter
jupyter notebook

# Oppure con JupyterLab
jupyter lab
```

### 4. Esegui i notebook nell'ordine suggerito:
1. **EDA** â†’ `eda_project_analysis.ipynb`
2. **Outliers** â†’ `outlier_detection_analysis.ipynb`
3. **Encoding** â†’ `encoding_strategies_comparison.ipynb`
4. **Target Transform** â†’ `target_transformations_comparison.ipynb`
5. **Results** â†’ `model_results_deep_analysis.ipynb`

---

## ğŸ“Š Spiegazione Prediction Intervals

I file `*_prediction_intervals.json` contengono informazioni sugli **intervalli di confidenza** delle predizioni:

```json
{
  "80%": {
    "coverage": 0.78,              // % valori reali nell'intervallo
    "average_width": 125277.86,    // Larghezza media intervallo (â‚¬)
    "average_width_pct": 209701.52, // Larghezza % rispetto al prezzo
    "target_coverage": 0.8         // Coverage target (80%)
  }
}
```

### Interpretazione:

- **`coverage`**: Percentuale di osservazioni reali che cadono nell'intervallo
  - Idealmente dovrebbe essere ~80% per intervallo 80%
  - Se < target: intervallo troppo stretto (under-coverage)
  - Se > target: intervallo troppo largo (over-coverage)

- **`average_width`**: Larghezza media dell'intervallo in euro
  - Indica l'incertezza del modello
  - Intervalli larghi = alta incertezza

- **`average_width_pct`**: Larghezza in percentuale rispetto al prezzo
  - Normalizza la larghezza per confronti
  - >100% indica intervalli molto ampi

### Diagnostics:

| Coverage Gap | Status | Azione |
|-------------|--------|--------|
| \|gap\| < 0.02 | ğŸŸ¢ Well calibrated | OK |
| gap < -0.05 | ğŸ”´ Under-coverage | Allarga intervalli |
| gap > 0.05 | ğŸŸ  Over-coverage | Restringi intervalli |
| -0.05 < gap < 0.05 | ğŸŸ¡ Acceptable | Minor tuning |

---

## ğŸ“ Output Directories

Ogni notebook crea una cartella di output:

```
notebooks/
â”œâ”€â”€ eda_outputs/                    # EDA analysis
â”œâ”€â”€ outlier_outputs/                # Outlier detection
â”œâ”€â”€ encoding_comparison_outputs/    # Encoding strategies
â”œâ”€â”€ target_transform_outputs/       # Target transformations
â””â”€â”€ model_analysis_outputs/         # Model results analysis
```

---

## ğŸ”§ Troubleshooting

### Problema: Notebook non trova i moduli
```python
import sys
from pathlib import Path
sys.path.insert(0, str(Path.cwd().parent / "src"))
```
Questo Ã¨ giÃ  incluso nei notebook, assicurati di eseguire dall'interno della cartella `notebooks/`.

### Problema: File non trovati
Assicurati di aver eseguito gli step del pipeline prima di aprire i notebook:
- `retrieve` â†’ per EDA e outlier analysis
- `preprocess` â†’ per encoding e target transform
- `train` â†’ per model results analysis

### Problema: Kernel non trovato
```bash
# Crea kernel per il progetto
python -m ipykernel install --user --name=stimatrix --display-name="Stimatrix"
```

### Problema: Memoria insufficiente
Se i notebook crashano per memoria, considera:
1. Ridurre il dataset in `config.yaml`
2. Usare `chunksize` per lettura dati
3. Liberare memoria con `del variable` dopo uso

---

## ğŸ“š Risorse

### Documentazione
- [Pandas](https://pandas.pydata.org/docs/)
- [Matplotlib](https://matplotlib.org/stable/contents.html)
- [Seaborn](https://seaborn.pydata.org/)
- [Scikit-learn](https://scikit-learn.org/stable/)

### Best Practices
- âœ… Esegui le celle in ordine
- âœ… Riavvia kernel se modifichi moduli esterni
- âœ… Salva output importanti in file
- âœ… Commenta insights direttamente nel notebook
- âœ… Usa `%matplotlib inline` per plot inline

---

## ğŸ¤ Contribuire

Per aggiungere nuovi notebook:

1. Segui la struttura esistente
2. Includi sezione "Obiettivo" e "Prerequisiti"
3. Salva output in cartella dedicata
4. Aggiungi documentazione in questo README
5. Testa il notebook da fresh kernel

---

## ğŸ“ Note

- I notebook sono **self-contained**: includono tutto il codice necessario
- Gli output sono **salvati automaticamente** nelle rispettive cartelle
- I plot usano **style consistente** per uniformitÃ 
- Le metriche sono **calcolate su scala originale** del target per interpretabilitÃ 

---

**Last Updated**: 2025-11-14  
**Maintainer**: Stimatrix Team  
**Python Version**: 3.12+  
**Jupyter Version**: Latest
