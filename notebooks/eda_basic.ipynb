{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Exploratory Data Analysis - Basic\n",
    "\n",
    "Questo notebook esegue un'analisi esplorativa **di base** del dataset per il progetto StiMatrix.\n",
    "\n",
    "**Nota**: Questo notebook utilizza il modulo `eda_utils.py` per funzioni comuni e best practices.\n",
    "\n",
    "## üéØ Obiettivi dell'analisi:\n",
    "1. Caricamento configurazione e dati\n",
    "2. Overview del dataset (shape, dtypes, memoria)\n",
    "3. Analisi missingness\n",
    "4. Distribuzione del target `AI_Prezzo_Ridistribuito`\n",
    "5. Correlazioni con il target (top features)\n",
    "6. Visualizzazioni base\n",
    "7. Summary per gruppi chiave\n",
    "\n",
    "## üí° Per analisi avanzate\n",
    "Vedi il notebook `eda_advanced.ipynb` per:\n",
    "- Analisi multi-target\n",
    "- Correlazioni avanzate (Spearman, Kendall, Cram√©r's V)\n",
    "- Feature importance comparativa\n",
    "- Matrici di correlazione complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup e Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import delle librerie necessarie\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Import del modulo utilities\n",
    "from eda_utils import (\n",
    "    setup_plotting_style,\n",
    "    setup_output_dir,\n",
    "    load_config_and_data,\n",
    "    get_target_column,\n",
    "    print_dataset_summary,\n",
    "    analyze_missingness,\n",
    "    analyze_target_distribution,\n",
    "    analyze_correlations,\n",
    "    plot_target_distribution,\n",
    "    create_correlation_heatmap,\n",
    "    save_plot\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup plotting style\n",
    "setup_plotting_style()\n",
    "\n",
    "print(\"‚úÖ Setup completato! Modulo eda_utils caricato.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Caricamento Dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup output directory\n",
    "output_dir = setup_output_dir('eda_outputs')\n",
    "\n",
    "# Carica configurazione e dati\n",
    "config, df = load_config_and_data(\n",
    "    config_path='../config/config.yaml',\n",
    "    data_path='../data/raw/raw.parquet'\n",
    ")\n",
    "\n",
    "# Identifica target\n",
    "target_col = get_target_column(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Overview Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary completo del dataset\n",
    "print_dataset_summary(df)\n",
    "\n",
    "# Prime righe\n",
    "print(\"\\nüîç Prime 5 righe del dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipi di dati e info dettagliate\n",
    "print(\"\\nüìã Distribuzione tipi di dati:\")\n",
    "dtype_counts = df.dtypes.value_counts()\n",
    "for dtype, count in dtype_counts.items():\n",
    "    print(f\"  {dtype}: {count} colonne\")\n",
    "\n",
    "# Info su colonne con valori mancanti\n",
    "print(\"\\n‚ùì Top 10 colonne per valori mancanti:\")\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing': df.isnull().sum(),\n",
    "    'Missing %': (df.isnull().mean() * 100).round(2)\n",
    "})\n",
    "missing_summary[missing_summary['Missing'] > 0].sort_values('Missing', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Analisi Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi completa della missingness\n",
    "missing_stats = analyze_missingness(df, output_dir)\n",
    "\n",
    "# Visualizza colonne con alta missingness\n",
    "high_missing = missing_stats[\n",
    "    missing_stats['Percentuale_Null'] > 50\n",
    "].sort_values('Percentuale_Null', ascending=False)\n",
    "\n",
    "if len(high_missing) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  {len(high_missing)} colonne con >50% valori mancanti\")\n",
    "    high_missing.head(10)\n",
    "else:\n",
    "    print(\"\\n‚úÖ Nessuna colonna con >50% valori mancanti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Analisi Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi distribuzione target\n",
    "stats, price_bands = analyze_target_distribution(df, target_col, output_dir)\n",
    "\n",
    "# Visualizza statistiche\n",
    "if stats is not None:\n",
    "    print(\"\\nüìä Statistiche Target:\")\n",
    "    print(f\"  Conteggio: {stats['count']:,.0f}\")\n",
    "    print(f\"  Media: ‚Ç¨{stats['mean']:,.2f}\")\n",
    "    print(f\"  Mediana: ‚Ç¨{stats['50%']:,.2f}\")\n",
    "    print(f\"  Std Dev: ‚Ç¨{stats['std']:,.2f}\")\n",
    "    print(f\"  Range: ‚Ç¨{stats['min']:,.2f} - ‚Ç¨{stats['max']:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione distribuzione target\n",
    "plot_target_distribution(\n",
    "    df, \n",
    "    target_col, \n",
    "    output_dir, \n",
    "    save_filename='target_distribution'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Grafici distribuzione salvati in eda_outputs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Correlazioni con Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi correlazioni\n",
    "corr_df = analyze_correlations(\n",
    "    df, \n",
    "    target_col, \n",
    "    output_dir,\n",
    "    threshold=0.1\n",
    ")\n",
    "\n",
    "# Top correlazioni\n",
    "print(\"\\nüîù Top 15 correlazioni (valore assoluto):\")\n",
    "corr_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap delle top 20 correlazioni\n",
    "create_correlation_heatmap(\n",
    "    df,\n",
    "    target_col,\n",
    "    top_n=20,\n",
    "    output_dir=output_dir,\n",
    "    save_filename='correlation_heatmap_top20'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Heatmap salvata in eda_outputs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Summary per Gruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi per gruppi chiave\n",
    "print(\"üë• ANALISI SUMMARY PER GRUPPI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "group_cols = ['AI_ZonaOmi', 'AI_IdCategoriaCatastale']\n",
    "\n",
    "for group_col in group_cols:\n",
    "    if group_col not in df.columns:\n",
    "        print(f\"\\n‚ö†Ô∏è  Colonna {group_col} non trovata, skip\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nüìä Summary per: {group_col}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    valid_data = df[[group_col, target_col]].dropna()\n",
    "    if len(valid_data) == 0:\n",
    "        print(f\"‚ùå Nessun dato valido per {group_col}\")\n",
    "        continue\n",
    "    \n",
    "    group_stats = valid_data.groupby(group_col)[target_col].agg([\n",
    "        'count', 'mean', 'median', 'std', 'min', 'max'\n",
    "    ]).round(2)\n",
    "    \n",
    "    group_stats = group_stats.sort_values('count', ascending=False)\n",
    "    group_stats['cv'] = (group_stats['std'] / group_stats['mean'] * 100).round(2)\n",
    "    \n",
    "    print(f\"Gruppi trovati: {len(group_stats)}\")\n",
    "    print(f\"\\nüîù Top 10 gruppi per dimensione:\")\n",
    "    display(group_stats.head(10))\n",
    "    \n",
    "    # Salva su CSV\n",
    "    output_file = output_dir / f'group_summary_{group_col}.csv'\n",
    "    group_stats.to_csv(output_file)\n",
    "    print(f\"üíæ Salvato: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Check Geospaziale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check rapido colonne geospaziali\n",
    "print(\"üó∫Ô∏è  CHECK GEOSPAZIALE RAPIDO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "geo_patterns = [\n",
    "    'lat', 'latitude', 'lon', 'lng', 'longitude',\n",
    "    'geometry', 'wkt', 'geojson', 'coord',\n",
    "    'posizione', 'location'\n",
    "]\n",
    "\n",
    "geo_candidates = []\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    for pattern in geo_patterns:\n",
    "        if pattern in col_lower:\n",
    "            sample_vals = df[col].dropna().head(3).tolist()\n",
    "            geo_candidates.append({\n",
    "                'Colonna': col,\n",
    "                'Tipo': str(df[col].dtype),\n",
    "                'Pattern': pattern,\n",
    "                'NonNull': int(df[col].count()),\n",
    "                'Esempio': str(sample_vals[0])[:50] if sample_vals else 'N/A'\n",
    "            })\n",
    "            break\n",
    "\n",
    "if geo_candidates:\n",
    "    geo_df = pd.DataFrame(geo_candidates)\n",
    "    print(f\"\\nüó∫Ô∏è  Trovate {len(geo_df)} colonne candidate geospaziali:\")\n",
    "    display(geo_df)\n",
    "    \n",
    "    # Salva\n",
    "    geo_df.to_csv(output_dir / 'geospatial_columns_check.csv', index=False)\n",
    "    print(f\"\\nüíæ Salvato in {output_dir}/geospatial_columns_check.csv\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Nessuna colonna geospaziale candidata trovata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Riepilogo Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ ANALISI ESPLORATIVA BASIC COMPLETATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä Dataset analizzato:\")\n",
    "print(f\"  ‚Ä¢ Dimensioni: {df.shape[0]:,} righe √ó {df.shape[1]} colonne\")\n",
    "print(f\"  ‚Ä¢ Target: {target_col}\")\n",
    "print(f\"  ‚Ä¢ Memoria: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\nüíæ File generati in {output_dir}/:\")\n",
    "output_files = list(output_dir.glob('*'))\n",
    "for f in sorted(output_files):\n",
    "    if f.is_file():\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f\"  ‚Ä¢ {f.name} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Analisi completata con successo!\")\n",
    "print(f\"\\nüí° Per analisi avanzate, vedi: eda_advanced.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
