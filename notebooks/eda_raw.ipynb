{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# 📊 Exploratory Data Analysis - Raw Dataset (VERSIONE AVANZATA)\n",
        "\n",
        "Questo notebook esegue analisi esplorativa **completa e avanzata** del dataset raw.\n",
        "\n",
        "## 🎯 Nuove funzionalità implementate:\n",
        "- **Analisi multi-target**: AI_Prezzo_Ridistribuito + AI_Prezzo_MQ\n",
        "- **Correlazioni complete**: Pearson + Spearman tra tutte le variabili numeriche\n",
        "- **Identificazione automatica target** dalla configurazione\n",
        "- **Confronto statistico** tra target multipli\n",
        "- **Analisi correlazioni non-lineari** (Spearman)\n",
        "- **Export completo** dei risultati in CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup-title",
      "metadata": {},
      "source": [
        "## 1. Setup e caricamento dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup-imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import delle librerie necessarie\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yaml\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from scipy import stats as scipy_stats\n",
        "from scipy.stats import chi2_contingency, f_oneway\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import networkx as nx\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from scipy.spatial.distance import squareform\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurazione matplotlib\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"✅ Setup completato! Tutte le librerie caricate correttamente.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup output directory e caricamento dati\n",
        "output_dir = Path('eda_outputs')\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"📁 Directory output: {output_dir}\")\n",
        "\n",
        "# Carica configurazione\n",
        "config_path = '../config/config.yaml'\n",
        "try:\n",
        "    with open(config_path, 'r', encoding='utf-8') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    print(f\"✅ Config caricata da: {config_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Errore nel caricamento config: {e}\")\n",
        "    raise\n",
        "\n",
        "# Carica dataset\n",
        "data_path = '../data/raw/raw.parquet'\n",
        "try:\n",
        "    df_raw = pd.read_parquet(data_path)\n",
        "    print(f\"✅ Dataset caricato da: {data_path}\")\n",
        "    print(f\"📊 Dimensioni: {df_raw.shape[0]:,} righe × {df_raw.shape[1]} colonne\")\n",
        "    print(f\"💾 Memoria utilizzata: {df_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    \n",
        "    # Identifica target dalla configurazione\n",
        "    target_candidates = config['target']['column_candidates']\n",
        "    print(f\"🎯 Target candidati dalla configurazione: {target_candidates}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Errore nel caricamento dati: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "multitarget-title",
      "metadata": {},
      "source": [
        "## 2. Analisi Multi-Target Avanzata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "multitarget-analysis",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ANALISI MULTI-TARGET AVANZATA\n",
        "print(\"=\" * 60)\n",
        "print(\"🎯 ANALISI MULTI-TARGET AVANZATA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n🎯 Target candidati dalla configurazione: {target_candidates}\")\n",
        "\n",
        "# Verifica presenza dei target nel dataset\n",
        "available_targets = [col for col in target_candidates if col in df_raw.columns]\n",
        "missing_targets = [col for col in target_candidates if col not in df_raw.columns]\n",
        "\n",
        "print(f\"✅ Target disponibili: {available_targets}\")\n",
        "if missing_targets:\n",
        "    print(f\"❌ Target mancanti: {missing_targets}\")\n",
        "\n",
        "if not available_targets:\n",
        "    print(\"❌ Nessun target disponibile nel dataset!\")\n",
        "    raise ValueError(\"No target columns found in dataset\")\n",
        "\n",
        "# Analisi per ogni target disponibile\n",
        "target_stats_all = {}\n",
        "target_data_all = {}\n",
        "\n",
        "for target_col in available_targets:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"🎯 ANALISI TARGET: {target_col}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    print(f\"\\n📊 Info target:\")\n",
        "    print(f\"  Tipo: {df_raw[target_col].dtype}\")\n",
        "    print(f\"  Valori non-nulli: {df_raw[target_col].count():,}\")\n",
        "    print(f\"  Valori mancanti: {df_raw[target_col].isnull().sum():,} ({df_raw[target_col].isnull().mean()*100:.2f}%)\")\n",
        "\n",
        "    target_data = df_raw[target_col].dropna()\n",
        "    target_data_all[target_col] = target_data\n",
        "    \n",
        "    if len(target_data) == 0:\n",
        "        print(f\"⚠️  Nessun dato valido per {target_col}, skip\")\n",
        "        continue\n",
        "        \n",
        "    stats = target_data.describe()\n",
        "    target_stats_all[target_col] = stats\n",
        "\n",
        "    # Unità di misura appropriate\n",
        "    unit = \"€/mq\" if \"MQ\" in target_col.upper() else \"€\"\n",
        "    \n",
        "    print(f\"\\n📈 Statistiche descrittive:\")\n",
        "    print(f\"  Conteggio: {stats['count']:,.0f}\")\n",
        "    print(f\"  Media: {unit}{stats['mean']:,.2f}\")\n",
        "    print(f\"  Mediana: {unit}{stats['50%']:,.2f}\")\n",
        "    print(f\"  Std Dev: {unit}{stats['std']:,.2f}\")\n",
        "    print(f\"  Min: {unit}{stats['min']:,.2f}\")\n",
        "    print(f\"  Max: {unit}{stats['max']:,.2f}\")\n",
        "    print(f\"  Skewness: {scipy_stats.skew(target_data):.4f}\")\n",
        "    print(f\"  Kurtosis: {scipy_stats.kurtosis(target_data):.4f}\")\n",
        "\n",
        "# Confronto tra target (se abbiamo più di uno)\n",
        "if len(available_targets) > 1:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"📊 CONFRONTO TRA TARGET\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Correlazione tra target\n",
        "    target_corr_data = df_raw[available_targets].dropna()\n",
        "    if len(target_corr_data) > 1:\n",
        "        target_corr = target_corr_data.corr()\n",
        "        print(f\"\\n🔗 Correlazione tra target:\")\n",
        "        display(target_corr.round(4))\n",
        "        \n",
        "        # Salva correlazione target\n",
        "        target_corr.to_csv(output_dir / 'target_correlation_matrix.csv')\n",
        "        print(f\"💾 Correlazione target salvata in {output_dir}/target_correlation_matrix.csv\")\n",
        "\n",
        "# Salva statistiche complete per tutti i target\n",
        "if target_stats_all:\n",
        "    all_stats_df = pd.DataFrame({target: stats for target, stats in target_stats_all.items()}).T\n",
        "    all_stats_df.to_csv(output_dir / 'target_statistics_all.csv')\n",
        "    print(f\"\\n💾 Statistiche complete salvate in {output_dir}/target_statistics_all.csv\")\n",
        "\n",
        "# Imposta target principale per le analisi successive\n",
        "primary_target = available_targets[0] if available_targets else None\n",
        "print(f\"\\n🎯 Target principale per analisi successive: {primary_target}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "correlations-title",
      "metadata": {},
      "source": [
        "## 3. Analisi Correlazioni Complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correlations-analysis",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ANALISI CORRELAZIONI COMPLETE\n",
        "print(\"=\" * 60)\n",
        "print(\"🔗 ANALISI CORRELAZIONI COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Identifica colonne numeriche\n",
        "numeric_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(f\"\\n🔢 Colonne numeriche totali: {len(numeric_cols)}\")\n",
        "\n",
        "# Rimuovi colonne costanti\n",
        "constant_cols = [col for col in numeric_cols if df_raw[col].nunique() <= 1]\n",
        "analysis_cols = [c for c in numeric_cols if c not in constant_cols]\n",
        "print(f\"⚠️  Colonne costanti rimosse: {len(constant_cols)}\")\n",
        "print(f\"✅ Colonne numeriche per analisi: {len(analysis_cols)}\")\n",
        "\n",
        "# Prepara dataset per correlazioni\n",
        "corr_data = df_raw[analysis_cols].dropna()\n",
        "print(f\"📊 Campioni validi per correlazioni: {len(corr_data):,}\")\n",
        "\n",
        "if len(corr_data) > 0 and len(analysis_cols) > 1:\n",
        "    \n",
        "    # 1. CORRELAZIONI PEARSON (lineari)\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"📈 CORRELAZIONI PEARSON (Lineari)\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    pearson_corr = corr_data.corr(method='pearson')\n",
        "    \n",
        "    # Trova correlazioni forti (escludendo diagonale)\n",
        "    strong_corr = []\n",
        "    for i in range(len(pearson_corr.columns)):\n",
        "        for j in range(i+1, len(pearson_corr.columns)):\n",
        "            corr_val = pearson_corr.iloc[i, j]\n",
        "            if abs(corr_val) >= 0.3:  # Soglia per correlazioni significative\n",
        "                strong_corr.append({\n",
        "                    'Var1': pearson_corr.columns[i],\n",
        "                    'Var2': pearson_corr.columns[j],\n",
        "                    'Pearson_Corr': corr_val,\n",
        "                    'Abs_Corr': abs(corr_val)\n",
        "                })\n",
        "    \n",
        "    strong_corr_df = pd.DataFrame(strong_corr).sort_values('Abs_Corr', ascending=False)\n",
        "    print(f\"\\n🔝 Correlazioni Pearson forti (|r| >= 0.3): {len(strong_corr_df)}\")\n",
        "    if len(strong_corr_df) > 0:\n",
        "        display(strong_corr_df.head(20))\n",
        "    \n",
        "    # 2. CORRELAZIONI SPEARMAN (monotone)\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"📊 CORRELAZIONI SPEARMAN (Monotone)\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    # Campiona per performance se dataset molto grande\n",
        "    sample_size = min(2000, len(corr_data))\n",
        "    if sample_size < len(corr_data):\n",
        "        corr_sample = corr_data.sample(n=sample_size, random_state=42)\n",
        "        print(f\"🎲 Campionamento per performance: {sample_size:,} righe\")\n",
        "    else:\n",
        "        corr_sample = corr_data\n",
        "    \n",
        "    spearman_corr = corr_sample.corr(method='spearman')\n",
        "    \n",
        "    # Trova correlazioni Spearman forti\n",
        "    strong_spearman = []\n",
        "    for i in range(len(spearman_corr.columns)):\n",
        "        for j in range(i+1, len(spearman_corr.columns)):\n",
        "            corr_val = spearman_corr.iloc[i, j]\n",
        "            if abs(corr_val) >= 0.3:\n",
        "                strong_spearman.append({\n",
        "                    'Var1': spearman_corr.columns[i],\n",
        "                    'Var2': spearman_corr.columns[j],\n",
        "                    'Spearman_Corr': corr_val,\n",
        "                    'Abs_Corr': abs(corr_val)\n",
        "                })\n",
        "    \n",
        "    strong_spearman_df = pd.DataFrame(strong_spearman).sort_values('Abs_Corr', ascending=False)\n",
        "    print(f\"\\n🔝 Correlazioni Spearman forti (|ρ| >= 0.3): {len(strong_spearman_df)}\")\n",
        "    if len(strong_spearman_df) > 0:\n",
        "        display(strong_spearman_df.head(15))\n",
        "    \n",
        "    # Salva risultati\n",
        "    pearson_corr.to_csv(output_dir / 'correlation_matrix_pearson.csv')\n",
        "    spearman_corr.to_csv(output_dir / 'correlation_matrix_spearman.csv')\n",
        "    \n",
        "    if len(strong_corr_df) > 0:\n",
        "        strong_corr_df.to_csv(output_dir / 'strong_correlations_pearson.csv', index=False)\n",
        "    if len(strong_spearman_df) > 0:\n",
        "        strong_spearman_df.to_csv(output_dir / 'strong_correlations_spearman.csv', index=False)\n",
        "    \n",
        "    print(f\"\\n💾 Matrici correlazione salvate in {output_dir}/\")\n",
        "    \n",
        "else:\n",
        "    print(\"❌ Dati insufficienti per analisi correlazioni\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary-title",
      "metadata": {},
      "source": [
        "## 4. Riepilogo Finale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "summary",
      "metadata": {},
      "outputs": [],
      "source": [
        "# RIEPILOGO FINALE\n",
        "print(\"=\" * 80)\n",
        "print(\"🎉 RIEPILOGO ANALISI ESPLORATIVA AVANZATA COMPLETATA\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\n📊 Dataset analizzato:\")\n",
        "print(f\"  • Dimensioni: {df_raw.shape[0]:,} righe × {df_raw.shape[1]} colonne\")\n",
        "print(f\"  • Memoria: {df_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Riepilogo target\n",
        "if 'available_targets' in locals():\n",
        "    print(f\"\\n🎯 Target analizzati:\")\n",
        "    for target in available_targets:\n",
        "        unit = \"€/mq\" if \"MQ\" in target.upper() else \"€\"\n",
        "        if target in df_raw.columns:\n",
        "            valid_count = df_raw[target].count()\n",
        "            mean_val = df_raw[target].mean()\n",
        "            print(f\"  • {target}: {valid_count:,} valori validi, media {unit}{mean_val:,.0f}\")\n",
        "\n",
        "# Riepilogo analisi correlazioni\n",
        "print(f\"\\n🔗 Analisi correlazioni eseguite:\")\n",
        "print(f\"  ✅ Correlazioni Pearson complete tra tutte le numeriche\")\n",
        "print(f\"  ✅ Correlazioni Spearman per relazioni monotone\")\n",
        "print(f\"  ✅ Analisi multi-target avanzata\")\n",
        "\n",
        "# Riepilogo file generati\n",
        "print(f\"\\n💾 File generati in {output_dir}/:\")\\ n",
        "try:\n",
        "    output_files = list(output_dir.glob('*.csv'))\n",
        "    print(f\"  📊 File di analisi: {len(output_files)}\")\n",
        "    for f in sorted(output_files):\n",
        "        print(f\"    • {f.name}\")\n",
        "except:\n",
        "    print(\"  📊 Directory output verrà popolata durante l'esecuzione\")\n",
        "\n",
        "print(f\"\\n🚀 MIGLIORAMENTI IMPLEMENTATI:\")\n",
        "print(f\"  ✅ Analisi multi-target (AI_Prezzo_Ridistribuito + AI_Prezzo_MQ)\")\n",
        "print(f\"  ✅ Matrice correlazione completa (non solo con target)\")\n",
        "print(f\"  ✅ Correlazioni non-lineari (Spearman)\")\n",
        "print(f\"  ✅ Identificazione automatica target dalla configurazione\")\n",
        "print(f\"  ✅ Confronto statistico tra target multipli\")\n",
        "\n",
        "print(f\"\\n🎯 PROSSIMI PASSI CONSIGLIATI:\")\n",
        "print(f\"  1. Utilizzare le correlazioni forti per feature engineering\")\n",
        "print(f\"  2. Sfruttare entrambi i target per modelli multi-output\")\n",
        "print(f\"  3. Analizzare le correlazioni Spearman per relazioni non-lineari\")\n",
        "print(f\"  4. Usare i file CSV generati per analisi successive\")\n",
        "\n",
        "print(f\"\\n✅ Analisi esplorativa avanzata completata con successo!\")\n",
        "print(f\"Ora puoi procedere con il preprocessing e training con una comprensione più profonda dei dati.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}