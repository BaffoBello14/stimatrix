{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# üìä Exploratory Data Analysis - Raw Dataset (VERSIONE AVANZATA)\n",
        "\n",
        "Questo notebook esegue analisi esplorativa **completa e avanzata** del dataset raw.\n",
        "\n",
        "## üéØ Nuove funzionalit√† implementate:\n",
        "- **Analisi multi-target**: AI_Prezzo_Ridistribuito + AI_Prezzo_MQ\n",
        "- **Correlazioni complete**: Pearson + Spearman tra tutte le variabili numeriche\n",
        "- **Identificazione automatica target** dalla configurazione\n",
        "- **Confronto statistico** tra target multipli\n",
        "- **Analisi correlazioni non-lineari** (Spearman)\n",
        "- **Export completo** dei risultati in CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup-title",
      "metadata": {},
      "source": [
        "## 1. Setup e caricamento dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup-imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import delle librerie necessarie\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yaml\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "from scipy import stats as scipy_stats\n",
        "from scipy.stats import chi2_contingency, f_oneway\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import networkx as nx\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from scipy.spatial.distance import squareform\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurazione matplotlib\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"‚úÖ Setup completato! Tutte le librerie caricate correttamente.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-data",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup output directory e caricamento dati\n",
        "output_dir = Path('eda_outputs')\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"üìÅ Directory output: {output_dir}\")\n",
        "\n",
        "# Carica configurazione\n",
        "config_path = '../config/config.yaml'\n",
        "try:\n",
        "    with open(config_path, 'r', encoding='utf-8') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    print(f\"‚úÖ Config caricata da: {config_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Errore nel caricamento config: {e}\")\n",
        "    raise\n",
        "\n",
        "# Carica dataset\n",
        "data_path = '../data/raw/raw.parquet'\n",
        "try:\n",
        "    df_raw = pd.read_parquet(data_path)\n",
        "    print(f\"‚úÖ Dataset caricato da: {data_path}\")\n",
        "    print(f\"üìä Dimensioni: {df_raw.shape[0]:,} righe √ó {df_raw.shape[1]} colonne\")\n",
        "    print(f\"üíæ Memoria utilizzata: {df_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    \n",
        "    # Identifica target dalla configurazione\n",
        "    target_candidates = config['target']['column_candidates']\n",
        "    print(f\"üéØ Target candidati dalla configurazione: {target_candidates}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Errore nel caricamento dati: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "multitarget-title",
      "metadata": {},
      "source": [
        "## 2. Analisi Multi-Target Avanzata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "multitarget-analysis",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ANALISI MULTI-TARGET AVANZATA\n",
        "print(\"=\" * 60)\n",
        "print(\"üéØ ANALISI MULTI-TARGET AVANZATA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nüéØ Target candidati dalla configurazione: {target_candidates}\")\n",
        "\n",
        "# Verifica presenza dei target nel dataset\n",
        "available_targets = [col for col in target_candidates if col in df_raw.columns]\n",
        "missing_targets = [col for col in target_candidates if col not in df_raw.columns]\n",
        "\n",
        "print(f\"‚úÖ Target disponibili: {available_targets}\")\n",
        "if missing_targets:\n",
        "    print(f\"‚ùå Target mancanti: {missing_targets}\")\n",
        "\n",
        "if not available_targets:\n",
        "    print(\"‚ùå Nessun target disponibile nel dataset!\")\n",
        "    raise ValueError(\"No target columns found in dataset\")\n",
        "\n",
        "# Analisi per ogni target disponibile\n",
        "target_stats_all = {}\n",
        "target_data_all = {}\n",
        "\n",
        "for target_col in available_targets:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"üéØ ANALISI TARGET: {target_col}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    print(f\"\\nüìä Info target:\")\n",
        "    print(f\"  Tipo: {df_raw[target_col].dtype}\")\n",
        "    print(f\"  Valori non-nulli: {df_raw[target_col].count():,}\")\n",
        "    print(f\"  Valori mancanti: {df_raw[target_col].isnull().sum():,} ({df_raw[target_col].isnull().mean()*100:.2f}%)\")\n",
        "\n",
        "    target_data = df_raw[target_col].dropna()\n",
        "    target_data_all[target_col] = target_data\n",
        "    \n",
        "    if len(target_data) == 0:\n",
        "        print(f\"‚ö†Ô∏è  Nessun dato valido per {target_col}, skip\")\n",
        "        continue\n",
        "        \n",
        "    stats = target_data.describe()\n",
        "    target_stats_all[target_col] = stats\n",
        "\n",
        "    # Unit√† di misura appropriate\n",
        "    unit = \"‚Ç¨/mq\" if \"MQ\" in target_col.upper() else \"‚Ç¨\"\n",
        "    \n",
        "    print(f\"\\nüìà Statistiche descrittive:\")\n",
        "    print(f\"  Conteggio: {stats['count']:,.0f}\")\n",
        "    print(f\"  Media: {unit}{stats['mean']:,.2f}\")\n",
        "    print(f\"  Mediana: {unit}{stats['50%']:,.2f}\")\n",
        "    print(f\"  Std Dev: {unit}{stats['std']:,.2f}\")\n",
        "    print(f\"  Min: {unit}{stats['min']:,.2f}\")\n",
        "    print(f\"  Max: {unit}{stats['max']:,.2f}\")\n",
        "    print(f\"  Skewness: {scipy_stats.skew(target_data):.4f}\")\n",
        "    print(f\"  Kurtosis: {scipy_stats.kurtosis(target_data):.4f}\")\n",
        "\n",
        "# Confronto tra target (se abbiamo pi√π di uno)\n",
        "if len(available_targets) > 1:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"üìä CONFRONTO TRA TARGET\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Correlazione tra target\n",
        "    target_corr_data = df_raw[available_targets].dropna()\n",
        "    if len(target_corr_data) > 1:\n",
        "        target_corr = target_corr_data.corr()\n",
        "        print(f\"\\nüîó Correlazione tra target:\")\n",
        "        display(target_corr.round(4))\n",
        "        \n",
        "        # Salva correlazione target\n",
        "        target_corr.to_csv(output_dir / 'target_correlation_matrix.csv')\n",
        "        print(f\"üíæ Correlazione target salvata in {output_dir}/target_correlation_matrix.csv\")\n",
        "\n",
        "# Salva statistiche complete per tutti i target\n",
        "if target_stats_all:\n",
        "    all_stats_df = pd.DataFrame({target: stats for target, stats in target_stats_all.items()}).T\n",
        "    all_stats_df.to_csv(output_dir / 'target_statistics_all.csv')\n",
        "    print(f\"\\nüíæ Statistiche complete salvate in {output_dir}/target_statistics_all.csv\")\n",
        "\n",
        "# Imposta target principale per le analisi successive\n",
        "primary_target = available_targets[0] if available_targets else None\n",
        "print(f\"\\nüéØ Target principale per analisi successive: {primary_target}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "correlations-title",
      "metadata": {},
      "source": [
        "## 3. Analisi Correlazioni Complete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correlations-analysis",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ANALISI CORRELAZIONI COMPLETE\n",
        "print(\"=\" * 60)\n",
        "print(\"üîó ANALISI CORRELAZIONI COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Identifica colonne numeriche\n",
        "numeric_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(f\"\\nüî¢ Colonne numeriche totali: {len(numeric_cols)}\")\n",
        "\n",
        "# Rimuovi colonne costanti\n",
        "constant_cols = [col for col in numeric_cols if df_raw[col].nunique() <= 1]\n",
        "analysis_cols = [c for c in numeric_cols if c not in constant_cols]\n",
        "print(f\"‚ö†Ô∏è  Colonne costanti rimosse: {len(constant_cols)}\")\n",
        "print(f\"‚úÖ Colonne numeriche per analisi: {len(analysis_cols)}\")\n",
        "\n",
        "# Prepara dataset per correlazioni\n",
        "corr_data = df_raw[analysis_cols].dropna()\n",
        "print(f\"üìä Campioni validi per correlazioni: {len(corr_data):,}\")\n",
        "\n",
        "if len(corr_data) > 0 and len(analysis_cols) > 1:\n",
        "    \n",
        "    # 1. CORRELAZIONI PEARSON (lineari)\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"üìà CORRELAZIONI PEARSON (Lineari)\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    pearson_corr = corr_data.corr(method='pearson')\n",
        "    \n",
        "    # Trova correlazioni forti (escludendo diagonale)\n",
        "    strong_corr = []\n",
        "    for i in range(len(pearson_corr.columns)):\n",
        "        for j in range(i+1, len(pearson_corr.columns)):\n",
        "            corr_val = pearson_corr.iloc[i, j]\n",
        "            if abs(corr_val) >= 0.3:  # Soglia per correlazioni significative\n",
        "                strong_corr.append({\n",
        "                    'Var1': pearson_corr.columns[i],\n",
        "                    'Var2': pearson_corr.columns[j],\n",
        "                    'Pearson_Corr': corr_val,\n",
        "                    'Abs_Corr': abs(corr_val)\n",
        "                })\n",
        "    \n",
        "    strong_corr_df = pd.DataFrame(strong_corr).sort_values('Abs_Corr', ascending=False)\n",
        "    print(f\"\\nüîù Correlazioni Pearson forti (|r| >= 0.3): {len(strong_corr_df)}\")\n",
        "    if len(strong_corr_df) > 0:\n",
        "        display(strong_corr_df.head(20))\n",
        "    \n",
        "    # 2. CORRELAZIONI SPEARMAN (monotone)\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(\"üìä CORRELAZIONI SPEARMAN (Monotone)\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    # Campiona per performance se dataset molto grande\n",
        "    sample_size = min(2000, len(corr_data))\n",
        "    if sample_size < len(corr_data):\n",
        "        corr_sample = corr_data.sample(n=sample_size, random_state=42)\n",
        "        print(f\"üé≤ Campionamento per performance: {sample_size:,} righe\")\n",
        "    else:\n",
        "        corr_sample = corr_data\n",
        "    \n",
        "    spearman_corr = corr_sample.corr(method='spearman')\n",
        "    \n",
        "    # Trova correlazioni Spearman forti\n",
        "    strong_spearman = []\n",
        "    for i in range(len(spearman_corr.columns)):\n",
        "        for j in range(i+1, len(spearman_corr.columns)):\n",
        "            corr_val = spearman_corr.iloc[i, j]\n",
        "            if abs(corr_val) >= 0.3:\n",
        "                strong_spearman.append({\n",
        "                    'Var1': spearman_corr.columns[i],\n",
        "                    'Var2': spearman_corr.columns[j],\n",
        "                    'Spearman_Corr': corr_val,\n",
        "                    'Abs_Corr': abs(corr_val)\n",
        "                })\n",
        "    \n",
        "    strong_spearman_df = pd.DataFrame(strong_spearman).sort_values('Abs_Corr', ascending=False)\n",
        "    print(f\"\\nüîù Correlazioni Spearman forti (|œÅ| >= 0.3): {len(strong_spearman_df)}\")\n",
        "    if len(strong_spearman_df) > 0:\n",
        "        display(strong_spearman_df.head(15))\n",
        "    \n",
        "    # Salva risultati\n",
        "    pearson_corr.to_csv(output_dir / 'correlation_matrix_pearson.csv')\n",
        "    spearman_corr.to_csv(output_dir / 'correlation_matrix_spearman.csv')\n",
        "    \n",
        "    if len(strong_corr_df) > 0:\n",
        "        strong_corr_df.to_csv(output_dir / 'strong_correlations_pearson.csv', index=False)\n",
        "    if len(strong_spearman_df) > 0:\n",
        "        strong_spearman_df.to_csv(output_dir / 'strong_correlations_spearman.csv', index=False)\n",
        "    \n",
        "    print(f\"\\nüíæ Matrici correlazione salvate in {output_dir}/\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Dati insufficienti per analisi correlazioni\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary-title",
      "metadata": {},
      "source": [
        "## 4. Riepilogo Finale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "summary",
      "metadata": {},
      "outputs": [],
      "source": [
        "# RIEPILOGO FINALE\n",
        "print(\"=\" * 80)\n",
        "print(\"üéâ RIEPILOGO ANALISI ESPLORATIVA AVANZATA COMPLETATA\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nüìä Dataset analizzato:\")\n",
        "print(f\"  ‚Ä¢ Dimensioni: {df_raw.shape[0]:,} righe √ó {df_raw.shape[1]} colonne\")\n",
        "print(f\"  ‚Ä¢ Memoria: {df_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Riepilogo target\n",
        "if 'available_targets' in locals():\n",
        "    print(f\"\\nüéØ Target analizzati:\")\n",
        "    for target in available_targets:\n",
        "        unit = \"‚Ç¨/mq\" if \"MQ\" in target.upper() else \"‚Ç¨\"\n",
        "        if target in df_raw.columns:\n",
        "            valid_count = df_raw[target].count()\n",
        "            mean_val = df_raw[target].mean()\n",
        "            print(f\"  ‚Ä¢ {target}: {valid_count:,} valori validi, media {unit}{mean_val:,.0f}\")\n",
        "\n",
        "# Riepilogo analisi correlazioni\n",
        "print(f\"\\nüîó Analisi correlazioni eseguite:\")\n",
        "print(f\"  ‚úÖ Correlazioni Pearson complete tra tutte le numeriche\")\n",
        "print(f\"  ‚úÖ Correlazioni Spearman per relazioni monotone\")\n",
        "print(f\"  ‚úÖ Analisi multi-target avanzata\")\n",
        "\n",
        "# Riepilogo file generati\n",
        "print(f\"\\nüíæ File generati in {output_dir}/:\")\\ n",
        "try:\n",
        "    output_files = list(output_dir.glob('*.csv'))\n",
        "    print(f\"  üìä File di analisi: {len(output_files)}\")\n",
        "    for f in sorted(output_files):\n",
        "        print(f\"    ‚Ä¢ {f.name}\")\n",
        "except:\n",
        "    print(\"  üìä Directory output verr√† popolata durante l'esecuzione\")\n",
        "\n",
        "print(f\"\\nüöÄ MIGLIORAMENTI IMPLEMENTATI:\")\n",
        "print(f\"  ‚úÖ Analisi multi-target (AI_Prezzo_Ridistribuito + AI_Prezzo_MQ)\")\n",
        "print(f\"  ‚úÖ Matrice correlazione completa (non solo con target)\")\n",
        "print(f\"  ‚úÖ Correlazioni non-lineari (Spearman)\")\n",
        "print(f\"  ‚úÖ Identificazione automatica target dalla configurazione\")\n",
        "print(f\"  ‚úÖ Confronto statistico tra target multipli\")\n",
        "\n",
        "print(f\"\\nüéØ PROSSIMI PASSI CONSIGLIATI:\")\n",
        "print(f\"  1. Utilizzare le correlazioni forti per feature engineering\")\n",
        "print(f\"  2. Sfruttare entrambi i target per modelli multi-output\")\n",
        "print(f\"  3. Analizzare le correlazioni Spearman per relazioni non-lineari\")\n",
        "print(f\"  4. Usare i file CSV generati per analisi successive\")\n",
        "\n",
        "print(f\"\\n‚úÖ Analisi esplorativa avanzata completata con successo!\")\n",
        "print(f\"Ora puoi procedere con il preprocessing e training con una comprensione pi√π profonda dei dati.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}