{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c65179d3",
   "metadata": {},
   "source": [
    "\n",
    "# üìä Exploratory Data Analysis - Raw Dataset (FIXED)\n",
    "\n",
    "Questo notebook esegue un'analisi esplorativa completa del dataset raw per il progetto StiMatrix.\n",
    "\n",
    "## üéØ Obiettivi dell'analisi:\n",
    "1. Caricamento configurazione e dati\n",
    "2. Overview del dataset (shape, dtypes, memoria, head)\n",
    "3. Analisi missingness e cardinalit√† categoriche\n",
    "4. Distribuzione del target `AI_Prezzo_Ridistribuito`\n",
    "5. Summary per gruppi (`AI_ZonaOmi`, `AI_IdCategoriaCatastale`)\n",
    "6. Correlazioni con il target\n",
    "7. Check geospaziale rapido\n",
    "\n",
    "## ‚úÖ Fix applicati:\n",
    "- Risolto problema di caricamento configurazione\n",
    "- Corretti i path per lettura dati\n",
    "- Installate dipendenze mancanti (pyarrow)\n",
    "- Migliorata gestione errori\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0342bae2",
   "metadata": {},
   "source": [
    "## 1. Setup e caricamento dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea49a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import delle librerie necessarie\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from scipy import stats as scipy_stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurazione matplotlib per grafici pi√π leggibili\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ Setup completato! Tutte le librerie caricate correttamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036cd902",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup output directory\n",
    "output_dir = Path('eda_outputs')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÅ Directory output: {output_dir}\")\n",
    "\n",
    "# Carica configurazione\n",
    "config_path = '../config/config.yaml'\n",
    "try:\n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(f\"‚úÖ Config caricata da: {config_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Errore nel caricamento config: {e}\")\n",
    "    raise\n",
    "\n",
    "# Carica dataset\n",
    "data_path = '../data/raw/raw.parquet'\n",
    "try:\n",
    "    df_raw = pd.read_parquet(data_path)\n",
    "    print(f\"‚úÖ Dataset caricato da: {data_path}\")\n",
    "    print(f\"üìä Dimensioni: {df_raw.shape[0]:,} righe √ó {df_raw.shape[1]} colonne\")\n",
    "    print(f\"üíæ Memoria utilizzata: {df_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    target_col = config['target']['column_candidates'][0]\n",
    "    print(f\"üéØ Target identificato: {target_col}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Errore nel caricamento dati: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e904e38c",
   "metadata": {},
   "source": [
    "## 2. Overview del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìã OVERVIEW DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Dimensioni: {df_raw.shape[0]:,} righe √ó {df_raw.shape[1]} colonne\")\n",
    "memory_mb = df_raw.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"üíæ Memoria utilizzata: {memory_mb:.2f} MB\")\n",
    "\n",
    "print(f\"\\nüìã Tipi di dati:\")\n",
    "dtype_counts = df_raw.dtypes.value_counts()\n",
    "for dtype, count in dtype_counts.items():\n",
    "    print(f\"  {dtype}: {count} colonne\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prime righe del dataset\n",
    "print(\"\\nüîç Prime 5 righe del dataset:\")\n",
    "display(df_raw.head())\n",
    "\n",
    "# Informazioni dettagliate sulle colonne\n",
    "print(\"\\nüìù Informazioni dettagliate sulle colonne:\")\n",
    "df_info = df_raw.dtypes.to_frame('Tipo')\n",
    "df_info['Valori Non-Nulli'] = df_raw.count()\n",
    "df_info['Valori Nulli'] = df_raw.isnull().sum()\n",
    "df_info['% Completamento'] = (1 - df_raw.isnull().mean()) * 100\n",
    "display(df_info.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4282a0f",
   "metadata": {},
   "source": [
    "## 3. Analisi Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95265a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üîç ANALISI MISSINGNESS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Totale_Null': df_raw.isnull().sum(),\n",
    "    'Percentuale_Null': (df_raw.isnull().mean() * 100).round(2),\n",
    "    'Tipo': df_raw.dtypes\n",
    "})\n",
    "\n",
    "high_missing = missing_stats[missing_stats['Percentuale_Null'] > 50].sort_values('Percentuale_Null', ascending=False)\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Colonne con >50% valori mancanti ({len(high_missing)} colonne):\")\n",
    "if len(high_missing) > 0:\n",
    "    display(high_missing.head(10))\n",
    "else:\n",
    "    print(\"  Nessuna colonna con >50% valori mancanti\")\n",
    "\n",
    "# Salva risultati\n",
    "missing_stats.to_csv(output_dir / 'missingness_analysis.csv')\n",
    "print(f\"\\nüíæ Risultati salvati in {output_dir}/missingness_analysis.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe91a6",
   "metadata": {},
   "source": [
    "## 4. Analisi del Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1357d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if target_col not in df_raw.columns:\n",
    "    print(f\"‚ùå Target '{target_col}' non trovato nelle colonne!\")\n",
    "    raise ValueError(f\"Target column '{target_col}' not found\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"üéØ ANALISI DISTRIBUZIONE TARGET: {target_col}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Info target:\")\n",
    "print(f\"  Tipo: {df_raw[target_col].dtype}\")\n",
    "print(f\"  Valori non-nulli: {df_raw[target_col].count():,}\")\n",
    "print(f\"  Valori mancanti: {df_raw[target_col].isnull().sum():,} ({df_raw[target_col].isnull().mean()*100:.2f}%)\")\n",
    "\n",
    "target_data = df_raw[target_col].dropna()\n",
    "stats = target_data.describe()\n",
    "\n",
    "print(f\"\\nüìà Statistiche descrittive:\")\n",
    "print(f\"  Conteggio: {stats['count']:,.0f}\")\n",
    "print(f\"  Media: ‚Ç¨{stats['mean']:,.2f}\")\n",
    "print(f\"  Mediana: ‚Ç¨{stats['50%']:,.2f}\")\n",
    "print(f\"  Std Dev: ‚Ç¨{stats['std']:,.2f}\")\n",
    "print(f\"  Min: ‚Ç¨{stats['min']:,.2f}\")\n",
    "print(f\"  Max: ‚Ç¨{stats['max']:,.2f}\")\n",
    "\n",
    "# Calcola fasce di prezzo a quantili\n",
    "quantiles = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "price_bands = target_data.quantile(quantiles)\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è  Fasce di prezzo (quantili):\")\n",
    "for i in range(len(quantiles)-1):\n",
    "    q_low = quantiles[i]\n",
    "    q_high = quantiles[i+1]\n",
    "    price_low = price_bands.iloc[i]\n",
    "    price_high = price_bands.iloc[i+1]\n",
    "    print(f\"  Q{int(q_low*100):02d}-Q{int(q_high*100):02d}: ‚Ç¨{price_low:,.0f} - ‚Ç¨{price_high:,.0f}\")\n",
    "\n",
    "# Salva statistiche target\n",
    "stats_df = pd.DataFrame(stats).reset_index()\n",
    "stats_df.columns = ['Statistic', 'Value']\n",
    "stats_df.to_csv(output_dir / 'target_statistics.csv', index=False)\n",
    "print(f\"\\nüíæ Statistiche target salvate in {output_dir}/target_statistics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e63caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grafici della distribuzione del target\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Istogramma\n",
    "axes[0,0].hist(target_data, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Distribuzione Target - Istogramma')\n",
    "axes[0,0].set_xlabel('Prezzo (‚Ç¨)')\n",
    "axes[0,0].set_ylabel('Frequenza')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Box plot\n",
    "axes[0,1].boxplot(target_data, vert=False)\n",
    "axes[0,1].set_title('Distribuzione Target - Box Plot')\n",
    "axes[0,1].set_xlabel('Prezzo (‚Ç¨)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. QQ Plot\n",
    "sample_size = min(5000, len(target_data))\n",
    "sample_data = target_data.sample(n=sample_size, random_state=42)\n",
    "scipy_stats.probplot(sample_data, dist=\"norm\", plot=axes[1,0])\n",
    "axes[1,0].set_title('Q-Q Plot (confronto con normale)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Quantili\n",
    "quantiles_viz = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "axes[1,1].hist(target_data, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "for q in quantiles_viz[1:-1]:\n",
    "    price_q = target_data.quantile(q)\n",
    "    axes[1,1].axvline(price_q, color='red', linestyle='--', alpha=0.7)\n",
    "    axes[1,1].text(price_q, axes[1,1].get_ylim()[1]*0.9, f'Q{int(q*100)}',\n",
    "                   rotation=90, verticalalignment='top', fontweight='bold')\n",
    "axes[1,1].set_title('Distribuzione con Quantili')\n",
    "axes[1,1].set_xlabel('Prezzo (‚Ç¨)')\n",
    "axes[1,1].set_ylabel('Frequenza')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c4bdb8",
   "metadata": {},
   "source": [
    "## 5. Correlazioni con il Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b06148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä ANALISI CORRELAZIONI CON {target_col}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Identifica colonne numeriche escludendo il target\n",
    "numeric_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if target_col in numeric_cols:\n",
    "    numeric_cols.remove(target_col)\n",
    "\n",
    "print(f\"\\nüî¢ Colonne numeriche identificate: {len(numeric_cols)}\")\n",
    "\n",
    "# Identifica colonne costanti\n",
    "constant_cols = [col for col in numeric_cols if df_raw[col].nunique() <= 1]\n",
    "print(f\"‚ö†Ô∏è  Colonne costanti identificate: {len(constant_cols)}\")\n",
    "if constant_cols:\n",
    "    print(\"  Colonne:\", constant_cols[:10])\n",
    "\n",
    "# Rimuovi colonne costanti\n",
    "analysis_cols = [c for c in numeric_cols if c not in constant_cols]\n",
    "\n",
    "corr_data = df_raw[analysis_cols + [target_col]].dropna()\n",
    "if len(corr_data) == 0:\n",
    "    print(\"‚ùå Nessun dato valido per correlazioni\")\n",
    "else:\n",
    "    correlations = corr_data.corr(numeric_only=True)[target_col].drop(target_col)\n",
    "\n",
    "    corr_df = pd.DataFrame({\n",
    "        'Colonna': correlations.index,\n",
    "        'Correlazione': correlations.values,\n",
    "        'Correlazione_Assoluta': np.abs(correlations.values)\n",
    "    }).round(4).sort_values('Correlazione_Assoluta', ascending=False)\n",
    "\n",
    "    threshold = 0.1\n",
    "    significant_corr = corr_df[corr_df['Correlazione_Assoluta'] >= threshold]\n",
    "    print(f\"\\nüìà Correlazioni significative (|r| >= {threshold}): {len(significant_corr)}\")\n",
    "    if len(significant_corr) > 0:\n",
    "        print(\"\\nüîù Top 15 correlazioni:\")\n",
    "        display(significant_corr.head(15))\n",
    "\n",
    "    print(f\"\\nüìä Statistiche correlazioni:\")\n",
    "    print(f\"  Max correlazione positiva: {corr_df['Correlazione'].max():.4f}\")\n",
    "    print(f\"  Max correlazione negativa: {corr_df['Correlazione'].min():.4f}\")\n",
    "    print(f\"  Media correlazione assoluta: {corr_df['Correlazione_Assoluta'].mean():.4f}\")\n",
    "\n",
    "    # Salva risultati\n",
    "    corr_df.to_csv(output_dir / 'correlations_with_target.csv', index=False)\n",
    "    print(f\"\\nüíæ Correlazioni salvate in {output_dir}/correlations_with_target.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340f710",
   "metadata": {},
   "source": [
    "## 6. Summary per Gruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4955662",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üë• ANALISI SUMMARY PER GRUPPI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "group_cols = ['AI_ZonaOmi', 'AI_IdCategoriaCatastale']\n",
    "\n",
    "# Verifica che le colonne esistano\n",
    "missing_group_cols = [col for col in group_cols if col not in df_raw.columns]\n",
    "if missing_group_cols:\n",
    "    print(f\"‚ùå Colonne di grouping mancanti: {missing_group_cols}\")\n",
    "    print(f\"üîç Colonne disponibili con 'AI_': {[c for c in df_raw.columns if 'AI_' in c][:10]}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Colonne di grouping trovate: {group_cols}\")\n",
    "\n",
    "group_summaries = {}\n",
    "\n",
    "for group_col in group_cols:\n",
    "    if group_col in df_raw.columns:\n",
    "        print(f\"\\nüìä Summary per gruppo: {group_col}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        valid_data = df_raw[[group_col, target_col]].dropna()\n",
    "        if len(valid_data) == 0:\n",
    "            print(f\"‚ùå Nessun dato valido per {group_col}\")\n",
    "            continue\n",
    "\n",
    "        group_stats = valid_data.groupby(group_col)[target_col].agg([\n",
    "            'count', 'mean', 'median', 'std', 'min', 'max'\n",
    "        ]).round(2)\n",
    "\n",
    "        group_stats = group_stats.sort_values('count', ascending=False)\n",
    "        group_stats['cv'] = (group_stats['std'] / group_stats['mean'] * 100).round(2)\n",
    "\n",
    "        print(f\"Gruppi trovati: {len(group_stats)}\")\n",
    "        print(f\"\\nüîù Top 10 gruppi per dimensione:\")\n",
    "        display(group_stats.head(10))\n",
    "\n",
    "        group_summaries[group_col] = group_stats\n",
    "        \n",
    "        # Salva su CSV\n",
    "        output_file = output_dir / f'group_summary_{group_col}.csv'\n",
    "        group_stats.to_csv(output_file)\n",
    "        print(f\"üíæ Salvato: {output_file}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Colonna {group_col} non trovata, skip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8703f31b",
   "metadata": {},
   "source": [
    "## 7. Check Geospaziale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70458920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üó∫Ô∏è  CHECK GEOSPAZIALE RAPIDO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "candidates = []\n",
    "all_cols = df_raw.columns.tolist()\n",
    "\n",
    "# Pattern di interesse\n",
    "geo_patterns = [\n",
    "    'wkt', 'geometry', 'geom', 'geojson', 'the_geom', 'shape', 'polygon', 'point', 'linestring',\n",
    "    'lat', 'latitude', 'lon', 'lng', 'longitude', 'coord', 'x_', 'y_', 'easting', 'northing',\n",
    "    'geo', 'spatial', 'location', 'posizione', 'indirizzo', 'address'\n",
    "]\n",
    "\n",
    "for col in all_cols:\n",
    "    col_l = col.lower()\n",
    "    for pat in geo_patterns:\n",
    "        if pat in col_l:\n",
    "            sample_vals = df_raw[col].dropna().head(3).tolist()\n",
    "            candidates.append({\n",
    "                'Colonna': col,\n",
    "                'Tipo': str(df_raw[col].dtype),\n",
    "                'Pattern': pat,\n",
    "                'NonNull_Count': int(df_raw[col].count()),\n",
    "                'Esempi': str(sample_vals)[:100]  # Limita lunghezza esempi\n",
    "            })\n",
    "            break\n",
    "\n",
    "if not candidates:\n",
    "    print(\"\\n‚ùå Nessuna colonna geospaziale candidata individuata\")\n",
    "else:\n",
    "    geo_df = pd.DataFrame(candidates).drop_duplicates(subset=['Colonna', 'Pattern'])\n",
    "    print(f\"\\nüó∫Ô∏è  Colonne candidate geospaziali: {len(geo_df)}\")\n",
    "    display(geo_df)\n",
    "    \n",
    "    # Salva risultati\n",
    "    geo_df.to_csv(output_dir / 'geospatial_columns_check.csv', index=False)\n",
    "    print(f\"\\nüíæ Check geospaziale salvato in {output_dir}/geospatial_columns_check.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a586754",
   "metadata": {},
   "source": [
    "## 8. Riepilogo finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728fdc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üéâ ANALISI ESPLORATIVA COMPLETATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Dataset analizzato:\")\n",
    "print(f\"  ‚Ä¢ Dimensioni: {df_raw.shape[0]:,} righe √ó {df_raw.shape[1]} colonne\")\n",
    "print(f\"  ‚Ä¢ Target: {target_col}\")\n",
    "print(f\"  ‚Ä¢ Memoria: {df_raw.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\nüíæ File generati in {output_dir}/:\")\n",
    "output_files = list(output_dir.glob('*.csv'))\n",
    "for f in output_files:\n",
    "    print(f\"  ‚Ä¢ {f.name}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Analisi completata con successo!\")\n",
    "print(f\"Puoi ora procedere con il preprocessing e il training del modello.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
