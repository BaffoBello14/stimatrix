{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä EDA - Stimatrix Project Analysis\n",
    "\n",
    "**Obiettivo**: Analisi esplorativa del dataset allineata alle scelte del progetto:\n",
    "- ‚úÖ Analisi dataset raw completo\n",
    "- ‚úÖ Effetto dei filtri configurati (anno>=2022, zone escluse, no ville)\n",
    "- ‚úÖ Confronto pre/post filtri\n",
    "- ‚úÖ Analisi target e feature chiave\n",
    "- ‚úÖ Validazione scelte preprocessing\n",
    "\n",
    "**Output**: `eda_project_outputs/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "# Project imports\n",
    "from utils.config import load_config\n",
    "from preprocessing.pipeline import apply_data_filters\n",
    "from utils.logger import get_logger\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Setup completato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione\n",
    "CONFIG_PATH = \"../config/config.yaml\"\n",
    "RAW_DATA_PATH = \"../data/raw/raw.parquet\"\n",
    "OUTPUT_DIR = Path(\"eda_project_outputs\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Helper per salvare plot\n",
    "def save_plot(name, dpi=100):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / f\"{name}.png\", dpi=dpi, bbox_inches='tight')\n",
    "    print(f\"üíæ Salvato: {name}.png\")\n",
    "\n",
    "print(f\"üìÇ Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. Load Data & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config = load_config(CONFIG_PATH)\n",
    "print(\"‚úÖ Config caricato\")\n",
    "\n",
    "# Mostra filtri configurati\n",
    "filters = config.get('data_filters', {})\n",
    "print(\"\\nüéØ FILTRI CONFIGURATI:\")\n",
    "for key, value in filters.items():\n",
    "    if value is not None and key not in ['description', 'experiment_name']:\n",
    "        print(f\"  - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "df_raw = pd.read_parquet(RAW_DATA_PATH)\n",
    "print(f\"‚úÖ Dataset raw caricato: {len(df_raw):,} righe √ó {len(df_raw.columns)} colonne\")\n",
    "print(f\"   Memoria: {df_raw.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 2. Dataset Raw - Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informazioni base\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET RAW - OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDimensioni: {len(df_raw):,} righe √ó {len(df_raw.columns)} colonne\")\n",
    "print(f\"Periodo: {df_raw['A_AnnoStipula'].min()} - {df_raw['A_AnnoStipula'].max()}\")\n",
    "print(f\"\\nTipi di dato:\")\n",
    "print(df_raw.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values overview\n",
    "missing = df_raw.isnull().sum()\n",
    "missing_pct = 100 * missing / len(df_raw)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Missing_Pct': missing_pct\n",
    "}).sort_values('Missing_Pct', ascending=False)\n",
    "\n",
    "print(f\"\\nüìä MISSING VALUES (Top 20):\")\n",
    "print(missing_df.head(20))\n",
    "\n",
    "# Salva\n",
    "missing_df.to_csv(OUTPUT_DIR / \"01_missing_values_raw.csv\")\n",
    "print(f\"\\nüíæ Salvato: 01_missing_values_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí∞ 3. Target Analysis (Raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target: AI_Prezzo_Ridistribuito\n",
    "target_col = 'AI_Prezzo_Ridistribuito'\n",
    "target = df_raw[target_col].dropna()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"TARGET: {target_col}\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nNon-null: {len(target):,} ({len(target)/len(df_raw)*100:.1f}%)\")\n",
    "print(f\"\\nStatistiche:\")\n",
    "print(f\"  Mean:       ‚Ç¨{target.mean():,.0f}\")\n",
    "print(f\"  Median:     ‚Ç¨{target.median():,.0f}\")\n",
    "print(f\"  Std:        ‚Ç¨{target.std():,.0f} ({target.std()/target.mean()*100:.0f}% CV)\")\n",
    "print(f\"  Min:        ‚Ç¨{target.min():,.0f}\")\n",
    "print(f\"  Max:        ‚Ç¨{target.max():,.0f}\")\n",
    "print(f\"\\nDistribuzione:\")\n",
    "print(f\"  Skewness:   {target.skew():.2f}\")\n",
    "print(f\"  Kurtosis:   {target.kurtosis():.2f}\")\n",
    "print(f\"\\nQuartili:\")\n",
    "for q in [0.25, 0.50, 0.75, 0.90, 0.95, 0.99]:\n",
    "    print(f\"  Q{int(q*100):02d}:  ‚Ç¨{target.quantile(q):>12,.0f}\")\n",
    "\n",
    "# Salva statistiche\n",
    "stats_df = pd.DataFrame({\n",
    "    'Statistic': ['count', 'mean', 'median', 'std', 'min', 'max', 'skewness', 'kurtosis'],\n",
    "    'Value': [\n",
    "        len(target),\n",
    "        target.mean(),\n",
    "        target.median(),\n",
    "        target.std(),\n",
    "        target.min(),\n",
    "        target.max(),\n",
    "        target.skew(),\n",
    "        target.kurtosis()\n",
    "    ]\n",
    "})\n",
    "stats_df.to_csv(OUTPUT_DIR / \"02_target_statistics_raw.csv\", index=False)\n",
    "print(f\"\\nüíæ Salvato: 02_target_statistics_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribuzione target\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Histogram\n",
    "axes[0, 0].hist(target, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Prezzo (‚Ç¨)')\n",
    "axes[0, 0].set_ylabel('Frequenza')\n",
    "axes[0, 0].set_title('Distribuzione Target (Raw)')\n",
    "axes[0, 0].axvline(target.mean(), color='r', linestyle='--', label=f'Mean: ‚Ç¨{target.mean():,.0f}')\n",
    "axes[0, 0].axvline(target.median(), color='g', linestyle='--', label=f'Median: ‚Ç¨{target.median():,.0f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Log scale\n",
    "axes[0, 1].hist(np.log10(target + 1), bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[0, 1].set_xlabel('log10(Prezzo + 1)')\n",
    "axes[0, 1].set_ylabel('Frequenza')\n",
    "axes[0, 1].set_title('Distribuzione Target (Log Scale)')\n",
    "\n",
    "# Boxplot\n",
    "axes[1, 0].boxplot(target, vert=True)\n",
    "axes[1, 0].set_ylabel('Prezzo (‚Ç¨)')\n",
    "axes[1, 0].set_title('Boxplot Target')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(target, dist=\"norm\", plot=axes[1, 1])\n",
    "axes[1, 1].set_title('Q-Q Plot (vs Normal)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "save_plot(\"03_target_distribution_raw\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÖ 4. Distribuzione Temporale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuzione per anno\n",
    "if 'A_AnnoStipula' in df_raw.columns:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DISTRIBUZIONE TEMPORALE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    year_counts = df_raw['A_AnnoStipula'].value_counts().sort_index()\n",
    "    print(\"\\nTransazioni per anno:\")\n",
    "    for year, count in year_counts.items():\n",
    "        pct = count / len(df_raw) * 100\n",
    "        bar = '‚ñà' * int(pct / 2)\n",
    "        print(f\"  {year}: {count:>6,} ({pct:>5.1f}%) {bar}\")\n",
    "    \n",
    "    # Salva\n",
    "    year_counts.to_csv(OUTPUT_DIR / \"04_temporal_distribution.csv\")\n",
    "    print(f\"\\nüíæ Salvato: 04_temporal_distribution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temporale\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart per anno\n",
    "year_counts.plot(kind='bar', ax=axes[0], color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Anno Stipula')\n",
    "axes[0].set_ylabel('Numero Transazioni')\n",
    "axes[0].set_title('Distribuzione Temporale')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Trend prezzo per anno\n",
    "if 'A_AnnoStipula' in df_raw.columns and target_col in df_raw.columns:\n",
    "    yearly_price = df_raw.groupby('A_AnnoStipula')[target_col].agg(['mean', 'median'])\n",
    "    axes[1].plot(yearly_price.index, yearly_price['mean'], marker='o', label='Mean', linewidth=2)\n",
    "    axes[1].plot(yearly_price.index, yearly_price['median'], marker='s', label='Median', linewidth=2)\n",
    "    axes[1].set_xlabel('Anno Stipula')\n",
    "    axes[1].set_ylabel('Prezzo (‚Ç¨)')\n",
    "    axes[1].set_title('Trend Prezzi per Anno')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "save_plot(\"05_temporal_analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è 5. Distribuzione Zone OMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi zone\n",
    "if 'AI_ZonaOmi' in df_raw.columns:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ZONE OMI\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    zone_counts = df_raw['AI_ZonaOmi'].value_counts()\n",
    "    print(f\"\\nTotale zone uniche: {df_raw['AI_ZonaOmi'].nunique()}\")\n",
    "    print(\"\\nDistribuzione:\")\n",
    "    for zone, count in zone_counts.items():\n",
    "        pct = count / len(df_raw) * 100\n",
    "        marker = \"‚ùå\" if zone in filters.get('zone_escluse', []) else \"‚úÖ\"\n",
    "        print(f\"  {marker} {zone}: {count:>6,} ({pct:>5.1f}%)\")\n",
    "    \n",
    "    # Zone da escludere\n",
    "    zone_escluse = filters.get('zone_escluse', [])\n",
    "    if zone_escluse:\n",
    "        print(f\"\\n‚ö†Ô∏è  Zone DA ESCLUDERE nella config: {zone_escluse}\")\n",
    "        for zone in zone_escluse:\n",
    "            if zone in zone_counts.index:\n",
    "                count = zone_counts[zone]\n",
    "                pct = count / len(df_raw) * 100\n",
    "                print(f\"     {zone}: {count:,} transazioni ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiche prezzo per zona\n",
    "if 'AI_ZonaOmi' in df_raw.columns and target_col in df_raw.columns:\n",
    "    zone_stats = df_raw.groupby('AI_ZonaOmi')[target_col].agg([\n",
    "        'count', 'mean', 'median', 'std', 'min', 'max'\n",
    "    ]).round(0)\n",
    "    \n",
    "    # Aggiungi CV (coefficiente variazione)\n",
    "    zone_stats['cv'] = (zone_stats['std'] / zone_stats['mean'] * 100).round(2)\n",
    "    zone_stats = zone_stats.sort_values('count', ascending=False)\n",
    "    \n",
    "    print(\"\\nüìä Statistiche Prezzo per Zona:\")\n",
    "    print(zone_stats)\n",
    "    \n",
    "    # Salva\n",
    "    zone_stats.to_csv(OUTPUT_DIR / \"06_zone_statistics_raw.csv\")\n",
    "    print(f\"\\nüíæ Salvato: 06_zone_statistics_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot zone\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Count per zona\n",
    "zone_counts.plot(kind='barh', ax=axes[0], color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Numero Transazioni')\n",
    "axes[0].set_ylabel('Zona OMI')\n",
    "axes[0].set_title('Distribuzione Transazioni per Zona')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Highlight zone da escludere\n",
    "zone_escluse = filters.get('zone_escluse', [])\n",
    "for i, zone in enumerate(zone_counts.index):\n",
    "    if zone in zone_escluse:\n",
    "        axes[0].get_children()[i].set_color('red')\n",
    "        axes[0].get_children()[i].set_alpha(0.5)\n",
    "\n",
    "# Prezzo medio per zona\n",
    "zone_stats['mean'].plot(kind='barh', ax=axes[1], color='orange', edgecolor='black')\n",
    "axes[1].set_xlabel('Prezzo Medio (‚Ç¨)')\n",
    "axes[1].set_ylabel('Zona OMI')\n",
    "axes[1].set_title('Prezzo Medio per Zona')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "save_plot(\"07_zone_analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè† 6. Distribuzione Tipologie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi tipologie\n",
    "if 'AI_IdTipologiaEdilizia' in df_raw.columns:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"TIPOLOGIE EDILIZIE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    tipo_counts = df_raw['AI_IdTipologiaEdilizia'].value_counts().sort_index()\n",
    "    print(\"\\nDistribuzione:\")\n",
    "    for tipo, count in tipo_counts.items():\n",
    "        pct = count / len(df_raw) * 100\n",
    "        marker = \"‚ùå\" if str(tipo) in filters.get('tipologie_escluse', []) else \"‚úÖ\"\n",
    "        print(f\"  {marker} Tipologia {tipo}: {count:>6,} ({pct:>5.1f}%)\")\n",
    "    \n",
    "    # Tipologie da escludere\n",
    "    tipo_escluse = filters.get('tipologie_escluse', [])\n",
    "    if tipo_escluse:\n",
    "        print(f\"\\n‚ö†Ô∏è  Tipologie DA ESCLUDERE nella config: {tipo_escluse}\")\n",
    "        for tipo in tipo_escluse:\n",
    "            count = (df_raw['AI_IdTipologiaEdilizia'].astype(str) == str(tipo)).sum()\n",
    "            if count > 0:\n",
    "                pct = count / len(df_raw) * 100\n",
    "                print(f\"     Tipologia {tipo}: {count:,} transazioni ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç 7. EFFETTO FILTRI - Confronto Pre/Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applica filtri\n",
    "print(\"=\" * 80)\n",
    "print(\"APPLICAZIONE FILTRI\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_filtered = apply_data_filters(df_raw, config)\n",
    "\n",
    "initial_rows = len(df_raw)\n",
    "final_rows = len(df_filtered)\n",
    "removed = initial_rows - final_rows\n",
    "pct_removed = removed / initial_rows * 100\n",
    "\n",
    "print(f\"\\nüìä RISULTATO:\")\n",
    "print(f\"  Dataset iniziale:  {initial_rows:>8,} righe (100.0%)\")\n",
    "print(f\"  Dataset finale:    {final_rows:>8,} righe ({final_rows/initial_rows*100:>5.1f}%)\")\n",
    "print(f\"  Rimossi:           {removed:>8,} righe ({pct_removed:>5.1f}%)\")\n",
    "\n",
    "if pct_removed > 50:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: Rimossi {pct_removed:.1f}% dei dati!\")\n",
    "elif pct_removed > 30:\n",
    "    print(f\"\\n‚ö†Ô∏è  Attenzione: Rimossi {pct_removed:.1f}% dei dati\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Rimozione moderata: {pct_removed:.1f}% dei dati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confronto statistiche target\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFRONTO TARGET: RAW vs FILTERED\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "target_raw = df_raw[target_col].dropna()\n",
    "target_filt = df_filtered[target_col].dropna()\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Raw': [\n",
    "        len(target_raw),\n",
    "        target_raw.mean(),\n",
    "        target_raw.median(),\n",
    "        target_raw.std(),\n",
    "        target_raw.min(),\n",
    "        target_raw.max(),\n",
    "        target_raw.skew(),\n",
    "        target_raw.kurtosis()\n",
    "    ],\n",
    "    'Filtered': [\n",
    "        len(target_filt),\n",
    "        target_filt.mean(),\n",
    "        target_filt.median(),\n",
    "        target_filt.std(),\n",
    "        target_filt.min(),\n",
    "        target_filt.max(),\n",
    "        target_filt.skew(),\n",
    "        target_filt.kurtosis()\n",
    "    ]\n",
    "}, index=['Count', 'Mean', 'Median', 'Std', 'Min', 'Max', 'Skewness', 'Kurtosis'])\n",
    "\n",
    "# Delta percentuale\n",
    "comparison['Delta'] = comparison['Filtered'] - comparison['Raw']\n",
    "comparison['Delta_Pct'] = 100 * comparison['Delta'] / comparison['Raw']\n",
    "\n",
    "print(\"\\n\", comparison.round(2))\n",
    "\n",
    "# Salva\n",
    "comparison.to_csv(OUTPUT_DIR / \"08_target_comparison_raw_vs_filtered.csv\")\n",
    "print(f\"\\nüíæ Salvato: 08_target_comparison_raw_vs_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confronto distribuzioni\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Histograms sovrapposti\n",
    "axes[0, 0].hist(target_raw, bins=50, alpha=0.5, label='Raw', edgecolor='black')\n",
    "axes[0, 0].hist(target_filt, bins=50, alpha=0.5, label='Filtered', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Prezzo (‚Ç¨)')\n",
    "axes[0, 0].set_ylabel('Frequenza')\n",
    "axes[0, 0].set_title('Confronto Distribuzioni: Raw vs Filtered')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Boxplots affiancati\n",
    "axes[0, 1].boxplot([target_raw, target_filt], labels=['Raw', 'Filtered'])\n",
    "axes[0, 1].set_ylabel('Prezzo (‚Ç¨)')\n",
    "axes[0, 1].set_title('Boxplot Comparison')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# KDE plots\n",
    "target_raw.plot(kind='density', ax=axes[1, 0], label='Raw', linewidth=2)\n",
    "target_filt.plot(kind='density', ax=axes[1, 0], label='Filtered', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Prezzo (‚Ç¨)')\n",
    "axes[1, 0].set_ylabel('Densit√†')\n",
    "axes[1, 0].set_title('Kernel Density Estimation')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plots sovrapposti\n",
    "stats.probplot(target_raw, dist=\"norm\", plot=axes[1, 1])\n",
    "axes[1, 1].get_lines()[0].set_marker('o')\n",
    "axes[1, 1].get_lines()[0].set_markersize(3)\n",
    "axes[1, 1].get_lines()[0].set_alpha(0.5)\n",
    "axes[1, 1].get_lines()[0].set_label('Raw')\n",
    "stats.probplot(target_filt, dist=\"norm\", plot=axes[1, 1])\n",
    "axes[1, 1].get_lines()[2].set_marker('s')\n",
    "axes[1, 1].get_lines()[2].set_markersize(3)\n",
    "axes[1, 1].get_lines()[2].set_alpha(0.5)\n",
    "axes[1, 1].get_lines()[2].set_label('Filtered')\n",
    "axes[1, 1].set_title('Q-Q Plot Comparison')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "save_plot(\"09_distribution_comparison_raw_vs_filtered\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confronto zone\n",
    "if 'AI_ZonaOmi' in df_raw.columns:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"CONFRONTO ZONE: RAW vs FILTERED\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    zone_raw = df_raw['AI_ZonaOmi'].value_counts()\n",
    "    zone_filt = df_filtered['AI_ZonaOmi'].value_counts()\n",
    "    \n",
    "    zone_comp = pd.DataFrame({\n",
    "        'Raw': zone_raw,\n",
    "        'Filtered': zone_filt\n",
    "    }).fillna(0).astype(int)\n",
    "    \n",
    "    zone_comp['Removed'] = zone_comp['Raw'] - zone_comp['Filtered']\n",
    "    zone_comp['Removed_Pct'] = 100 * zone_comp['Removed'] / zone_comp['Raw']\n",
    "    \n",
    "    zone_comp = zone_comp.sort_values('Raw', ascending=False)\n",
    "    \n",
    "    print(\"\\n\", zone_comp)\n",
    "    \n",
    "    # Salva\n",
    "    zone_comp.to_csv(OUTPUT_DIR / \"10_zone_comparison_raw_vs_filtered.csv\")\n",
    "    print(f\"\\nüíæ Salvato: 10_zone_comparison_raw_vs_filtered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 8. Top Correlazioni con Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola correlazioni (solo colonne numeriche)\n",
    "numeric_cols = df_filtered.select_dtypes(include=[np.number]).columns\n",
    "numeric_cols = [c for c in numeric_cols if c != target_col]  # Escludi target stesso\n",
    "\n",
    "correlations = []\n",
    "for col in numeric_cols:\n",
    "    try:\n",
    "        corr = df_filtered[[col, target_col]].corr().iloc[0, 1]\n",
    "        if not np.isnan(corr):\n",
    "            correlations.append({\n",
    "                'Feature': col,\n",
    "                'Correlation': corr,\n",
    "                'Abs_Correlation': abs(corr)\n",
    "            })\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('Abs_Correlation', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TOP 30 CORRELAZIONI CON TARGET\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n\", corr_df.head(30))\n",
    "\n",
    "# Salva\n",
    "corr_df.to_csv(OUTPUT_DIR / \"11_correlations_with_target.csv\", index=False)\n",
    "print(f\"\\nüíæ Salvato: 11_correlations_with_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top correlazioni\n",
    "top_corr = corr_df.head(20)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['red' if x < 0 else 'steelblue' for x in top_corr['Correlation']]\n",
    "plt.barh(range(len(top_corr)), top_corr['Correlation'], color=colors, edgecolor='black')\n",
    "plt.yticks(range(len(top_corr)), top_corr['Feature'])\n",
    "plt.xlabel('Correlazione con Target')\n",
    "plt.title('Top 20 Correlazioni con Target (Filtered Dataset)')\n",
    "plt.axvline(x=0, color='black', linewidth=0.8)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "save_plot(\"12_top_correlations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ 9. Feature Droppate nella Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature droppate dalla config\n",
    "drop_cols = config.get('feature_pruning', {}).get('drop_columns', [])\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE DROPPATE NELLA CONFIG\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotale feature da droppare: {len(drop_cols)}\")\n",
    "print(\"\\nCategorie:\")\n",
    "print(\"  - ID e chiavi esterne: ~12 colonne\")\n",
    "print(\"  - Superfici ridondanti: ~5 colonne\")\n",
    "print(\"  - Indicatori ISTAT ridondanti: ~7 colonne\")\n",
    "print(\"  - OmiValori ridondanti: ~4 colonne\")\n",
    "print(\"  - Metadata e tecniche: ~13 colonne\")\n",
    "print(\"  - Codici catastali: ~8 colonne\")\n",
    "print(\"  - Poco predittive: ~7 colonne\")\n",
    "\n",
    "# Verifica quali sono presenti nel dataset\n",
    "present_drops = [c for c in drop_cols if c in df_filtered.columns]\n",
    "missing_drops = [c for c in drop_cols if c not in df_filtered.columns]\n",
    "\n",
    "print(f\"\\nPresenti nel dataset: {len(present_drops)}/{len(drop_cols)}\")\n",
    "if missing_drops:\n",
    "    print(f\"\\n‚ö†Ô∏è  Colonne non trovate (gi√† rimosse o mai presenti):\")\n",
    "    for col in missing_drops[:10]:\n",
    "        print(f\"     - {col}\")\n",
    "    if len(missing_drops) > 10:\n",
    "        print(f\"     ... altre {len(missing_drops)-10} colonne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 10. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera report finale\n",
    "report = {\n",
    "    'dataset': {\n",
    "        'raw_rows': len(df_raw),\n",
    "        'raw_cols': len(df_raw.columns),\n",
    "        'filtered_rows': len(df_filtered),\n",
    "        'filtered_cols': len(df_filtered.columns),\n",
    "        'rows_removed': len(df_raw) - len(df_filtered),\n",
    "        'rows_removed_pct': 100 * (len(df_raw) - len(df_filtered)) / len(df_raw),\n",
    "    },\n",
    "    'target_raw': {\n",
    "        'count': int(len(target_raw)),\n",
    "        'mean': float(target_raw.mean()),\n",
    "        'median': float(target_raw.median()),\n",
    "        'std': float(target_raw.std()),\n",
    "        'skewness': float(target_raw.skew()),\n",
    "        'kurtosis': float(target_raw.kurtosis()),\n",
    "    },\n",
    "    'target_filtered': {\n",
    "        'count': int(len(target_filt)),\n",
    "        'mean': float(target_filt.mean()),\n",
    "        'median': float(target_filt.median()),\n",
    "        'std': float(target_filt.std()),\n",
    "        'skewness': float(target_filt.skew()),\n",
    "        'kurtosis': float(target_filt.kurtosis()),\n",
    "    },\n",
    "    'filters_applied': {\n",
    "        'anno_min': filters.get('anno_min'),\n",
    "        'zone_escluse': filters.get('zone_escluse'),\n",
    "        'tipologie_escluse': filters.get('tipologie_escluse'),\n",
    "    },\n",
    "    'top_correlations': corr_df.head(10).to_dict('records')\n",
    "}\n",
    "\n",
    "# Salva report JSON\n",
    "import json\n",
    "with open(OUTPUT_DIR / \"00_summary_report.json\", 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(report, indent=2))\n",
    "print(f\"\\nüíæ Salvato: 00_summary_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusioni\n",
    "\n",
    "### File Generati\n",
    "\n",
    "1. `00_summary_report.json` - Report completo in JSON\n",
    "2. `01_missing_values_raw.csv` - Missing values overview\n",
    "3. `02_target_statistics_raw.csv` - Statistiche target raw\n",
    "4. `03_target_distribution_raw.png` - Distribuzione target raw\n",
    "5. `04_temporal_distribution.csv` - Distribuzione temporale\n",
    "6. `05_temporal_analysis.png` - Analisi temporale\n",
    "7. `06_zone_statistics_raw.csv` - Statistiche zone\n",
    "8. `07_zone_analysis.png` - Analisi zone\n",
    "9. `08_target_comparison_raw_vs_filtered.csv` - Confronto target\n",
    "10. `09_distribution_comparison_raw_vs_filtered.png` - Confronto distribuzioni\n",
    "11. `10_zone_comparison_raw_vs_filtered.csv` - Confronto zone\n",
    "12. `11_correlations_with_target.csv` - Correlazioni complete\n",
    "13. `12_top_correlations.png` - Top 20 correlazioni\n",
    "\n",
    "### Prossimi Passi\n",
    "\n",
    "1. Verificare effetto filtri su performance modello\n",
    "2. Analizzare preprocessed data (feature contestuali, encoding)\n",
    "3. Confrontare con risultati training\n",
    "4. Iterare su filtri se necessario"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
