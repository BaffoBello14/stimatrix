{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè∑Ô∏è Encoding Strategies Comparison\n",
    "\n",
    "**Obiettivo**: Validare la configurazione attuale delle strategie di encoding categorico.\n",
    "\n",
    "**Strategie analizzate**:\n",
    "1. **OneHot Encoding** (low cardinality: ‚â§ 10 unique)\n",
    "2. **Target Encoding** (medium cardinality: 11-50 unique)\n",
    "3. **Frequency Encoding** (high cardinality: > 50 unique)\n",
    "4. **Ordinal Encoding** (fallback/custom)\n",
    "\n",
    "**Analisi**:\n",
    "- Cardinalit√† features categoriche\n",
    "- Dimensionalit√† prima/dopo encoding\n",
    "- Correlazione con target per tipo encoding\n",
    "- Test leak-free (unseen categories)\n",
    "- Performance encoding strategies\n",
    "- Raccomandazioni per soglie cardinality\n",
    "\n",
    "**Output**: `encoding_outputs/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'EncodingConfig' from 'preprocessing.encoders' (c:\\Users\\giuli\\OneDrive\\Desktop\\stimatrix\\src\\preprocessing\\encoders.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_config\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m apply_data_filters\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mencoders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     EncodingConfig,\n\u001b[32m     19\u001b[39m     fit_categorical_encoders,\n\u001b[32m     20\u001b[39m     transform_categorical_features\n\u001b[32m     21\u001b[39m )\n\u001b[32m     23\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Plot settings\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'EncodingConfig' from 'preprocessing.encoders' (c:\\Users\\giuli\\OneDrive\\Desktop\\stimatrix\\src\\preprocessing\\encoders.py)"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "# Project imports\n",
    "from utils.config import load_config\n",
    "from preprocessing.pipeline import apply_data_filters\n",
    "from preprocessing.encoders import (\n",
    "    EncodingConfig,\n",
    "    fit_categorical_encoders,\n",
    "    transform_categorical_features\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Setup completato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione\n",
    "CONFIG_PATH = \"../config/config.yaml\"\n",
    "RAW_DATA_PATH = \"../data/raw/raw.parquet\"\n",
    "OUTPUT_DIR = Path(\"encoding_outputs\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def save_plot(name, dpi=120):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / f\"{name}.png\", dpi=dpi, bbox_inches='tight')\n",
    "    print(f\"üíæ Salvato: {name}.png\")\n",
    "\n",
    "print(f\"üìÇ Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config e data\n",
    "config = load_config(CONFIG_PATH)\n",
    "df_raw = pd.read_parquet(RAW_DATA_PATH)\n",
    "\n",
    "# Applica filtri\n",
    "df = apply_data_filters(df_raw, config)\n",
    "\n",
    "# Target\n",
    "target_col = 'AI_Prezzo_Ridistribuito'\n",
    "\n",
    "print(f\"‚úÖ Dataset caricato e filtrato\")\n",
    "print(f\"   Shape: {df.shape}\")\n",
    "print(f\"   Target: {target_col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è 2. Identify Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica features categoriche (dtypes object/category)\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Rimuovi target se presente\n",
    "if target_col in categorical_cols:\n",
    "    categorical_cols.remove(target_col)\n",
    "\n",
    "print(f\"üìä Categorical features trovate: {len(categorical_cols)}\")\n",
    "print(f\"\\nLista:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 3. Cardinality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizza cardinalit√†\n",
    "cardinality_data = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    n_unique = df[col].nunique()\n",
    "    n_samples = df[col].notna().sum()\n",
    "    missing_pct = df[col].isna().sum() / len(df) * 100\n",
    "    \n",
    "    # Determina encoding strategy (config project)\n",
    "    if n_unique <= 10:\n",
    "        strategy = 'OneHot'\n",
    "    elif n_unique <= 50:\n",
    "        strategy = 'Target'\n",
    "    else:\n",
    "        strategy = 'Frequency'\n",
    "    \n",
    "    cardinality_data.append({\n",
    "        'Feature': col,\n",
    "        'Unique': n_unique,\n",
    "        'Samples': n_samples,\n",
    "        'Missing_Pct': missing_pct,\n",
    "        'Strategy': strategy,\n",
    "    })\n",
    "\n",
    "cardinality_df = pd.DataFrame(cardinality_data)\n",
    "cardinality_df = cardinality_df.sort_values('Unique', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CARDINALITY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n\", cardinality_df.to_string(index=False))\n",
    "\n",
    "# Salva\n",
    "cardinality_df.to_csv(OUTPUT_DIR / \"01_cardinality_analysis.csv\", index=False)\n",
    "print(f\"\\nüíæ Salvato: 01_cardinality_analysis.csv\")\n",
    "\n",
    "# Summary per strategy\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ENCODING STRATEGIES DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "strategy_counts = cardinality_df['Strategy'].value_counts()\n",
    "for strategy, count in strategy_counts.items():\n",
    "    print(f\"  {strategy}: {count} features\")\n",
    "    features = cardinality_df[cardinality_df['Strategy'] == strategy]['Feature'].tolist()\n",
    "    for feat in features:\n",
    "        n_unique = cardinality_df[cardinality_df['Feature'] == feat]['Unique'].values[0]\n",
    "        print(f\"    - {feat} (n={n_unique})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 4. Visualizations - Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: cardinalit√† per feature\n",
    "fig, ax = plt.subplots(figsize=(12, max(6, len(categorical_cols) * 0.3)))\n",
    "\n",
    "# Colors per strategy\n",
    "color_map = {'OneHot': 'green', 'Target': 'orange', 'Frequency': 'red'}\n",
    "colors = [color_map[s] for s in cardinality_df['Strategy']]\n",
    "\n",
    "ax.barh(range(len(cardinality_df)), cardinality_df['Unique'], color=colors, edgecolor='black')\n",
    "ax.set_yticks(range(len(cardinality_df)))\n",
    "ax.set_yticklabels(cardinality_df['Feature'], fontsize=8)\n",
    "ax.set_xlabel('Number of Unique Values (Cardinality)')\n",
    "ax.set_title('Cardinality per Categorical Feature', fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Soglie\n",
    "ax.axvline(x=10, color='green', linestyle='--', linewidth=2, label='OneHot (‚â§10)')\n",
    "ax.axvline(x=50, color='orange', linestyle='--', linewidth=2, label='Target (11-50)')\n",
    "ax.legend()\n",
    "\n",
    "# Aggiungi valori\n",
    "for i, row in cardinality_df.iterrows():\n",
    "    ax.text(row['Unique'] * 1.1, cardinality_df.index.get_loc(i), \n",
    "            f\"{row['Unique']}\", va='center', fontsize=7)\n",
    "\n",
    "save_plot(\"02_cardinality_bar_chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart: distribuzione strategie\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "strategy_counts = cardinality_df['Strategy'].value_counts()\n",
    "colors = [color_map[s] for s in strategy_counts.index]\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    strategy_counts.values,\n",
    "    labels=strategy_counts.index,\n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors,\n",
    "    startangle=90,\n",
    "    textprops={'fontsize': 12, 'fontweight': 'bold'}\n",
    ")\n",
    "\n",
    "ax.set_title('Encoding Strategies Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "save_plot(\"03_strategies_pie_chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 5. Dimensionality Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola dimensionalit√† risultante da ogni strategia\n",
    "print(\"=\" * 80)\n",
    "print(\"DIMENSIONALITY IMPACT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# OneHot: ogni unique diventa una colonna (tranne uno per evitare collinearit√†)\n",
    "onehot_features = cardinality_df[cardinality_df['Strategy'] == 'OneHot']\n",
    "onehot_dims = sum(max(1, row['Unique'] - 1) for _, row in onehot_features.iterrows())\n",
    "\n",
    "# Target/Frequency: 1 colonna per feature\n",
    "target_features = cardinality_df[cardinality_df['Strategy'] == 'Target']\n",
    "target_dims = len(target_features)\n",
    "\n",
    "freq_features = cardinality_df[cardinality_df['Strategy'] == 'Frequency']\n",
    "freq_dims = len(freq_features)\n",
    "\n",
    "total_categorical_dims = onehot_dims + target_dims + freq_dims\n",
    "original_dims = len(categorical_cols)\n",
    "\n",
    "print(f\"\\nüìä BEFORE Encoding:\")\n",
    "print(f\"   Categorical features: {original_dims}\")\n",
    "\n",
    "print(f\"\\nüìä AFTER Encoding:\")\n",
    "print(f\"   OneHot dimensions: {onehot_dims} (from {len(onehot_features)} features)\")\n",
    "print(f\"   Target dimensions: {target_dims}\")\n",
    "print(f\"   Frequency dimensions: {freq_dims}\")\n",
    "print(f\"   TOTAL: {total_categorical_dims}\")\n",
    "\n",
    "print(f\"\\nüìà Expansion Factor: {total_categorical_dims / original_dims:.2f}x\")\n",
    "\n",
    "# Breakdown per feature OneHot\n",
    "if len(onehot_features) > 0:\n",
    "    print(f\"\\nüìä OneHot Features Breakdown:\")\n",
    "    for _, row in onehot_features.iterrows():\n",
    "        dims = max(1, row['Unique'] - 1)\n",
    "        print(f\"   {row['Feature']}: {row['Unique']} unique ‚Üí {dims} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dimensionality impact\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Before/After bar\n",
    "axes[0].bar(['Before\\nEncoding', 'After\\nEncoding'], \n",
    "            [original_dims, total_categorical_dims],\n",
    "            color=['steelblue', 'orange'],\n",
    "            edgecolor='black')\n",
    "axes[0].set_ylabel('Number of Dimensions')\n",
    "axes[0].set_title('Dimensionality: Before vs After Encoding')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Aggiungi valori\n",
    "for i, v in enumerate([original_dims, total_categorical_dims]):\n",
    "    axes[0].text(i, v + 1, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Breakdown per strategy\n",
    "strategy_dims = {'OneHot': onehot_dims, 'Target': target_dims, 'Frequency': freq_dims}\n",
    "colors_breakdown = [color_map[s] for s in strategy_dims.keys()]\n",
    "\n",
    "axes[1].bar(strategy_dims.keys(), strategy_dims.values(), \n",
    "            color=colors_breakdown, edgecolor='black')\n",
    "axes[1].set_ylabel('Number of Dimensions')\n",
    "axes[1].set_title('Dimensionality Breakdown by Strategy')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Aggiungi valori\n",
    "for i, (k, v) in enumerate(strategy_dims.items()):\n",
    "    axes[1].text(i, v + 0.5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "save_plot(\"04_dimensionality_impact\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 6. Correlation with Target (per strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizza correlazione features categoriche con target\n",
    "# Per ogni feature, calcola correlazione media per categoria\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CORRELATION WITH TARGET (per strategy)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "correlation_data = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    # Calcola mean target per categoria\n",
    "    grouped = df.groupby(col)[target_col].mean()\n",
    "    \n",
    "    # Variance tra categorie (proxy per predictive power)\n",
    "    target_variance = grouped.var()\n",
    "    \n",
    "    # Correlation ratio (eta-squared)\n",
    "    # https://en.wikipedia.org/wiki/Correlation_ratio\n",
    "    try:\n",
    "        overall_mean = df[target_col].mean()\n",
    "        ss_between = sum(\n",
    "            df[df[col] == cat][target_col].count() * (grouped[cat] - overall_mean)**2 \n",
    "            for cat in grouped.index\n",
    "        )\n",
    "        ss_total = sum((df[target_col] - overall_mean)**2)\n",
    "        eta_squared = ss_between / ss_total if ss_total > 0 else 0\n",
    "    except:\n",
    "        eta_squared = np.nan\n",
    "    \n",
    "    strategy = cardinality_df[cardinality_df['Feature'] == col]['Strategy'].values[0]\n",
    "    \n",
    "    correlation_data.append({\n",
    "        'Feature': col,\n",
    "        'Strategy': strategy,\n",
    "        'Target_Variance': target_variance,\n",
    "        'Eta_Squared': eta_squared,\n",
    "    })\n",
    "\n",
    "correlation_df = pd.DataFrame(correlation_data)\n",
    "correlation_df = correlation_df.sort_values('Eta_Squared', ascending=False)\n",
    "\n",
    "print(\"\\n\", correlation_df.to_string(index=False))\n",
    "\n",
    "# Salva\n",
    "correlation_df.to_csv(OUTPUT_DIR / \"05_correlation_with_target.csv\", index=False)\n",
    "print(f\"\\nüíæ Salvato: 05_correlation_with_target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: eta-squared per feature\n",
    "fig, ax = plt.subplots(figsize=(12, max(6, len(correlation_df) * 0.3)))\n",
    "\n",
    "colors = [color_map[s] for s in correlation_df['Strategy']]\n",
    "\n",
    "ax.barh(range(len(correlation_df)), correlation_df['Eta_Squared'], \n",
    "        color=colors, edgecolor='black')\n",
    "ax.set_yticks(range(len(correlation_df)))\n",
    "ax.set_yticklabels(correlation_df['Feature'], fontsize=8)\n",
    "ax.set_xlabel('Eta-Squared (Correlation Ratio)')\n",
    "ax.set_title('Predictive Power of Categorical Features', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Aggiungi valori\n",
    "for i, row in correlation_df.iterrows():\n",
    "    ax.text(row['Eta_Squared'] + 0.001, correlation_df.index.get_loc(i), \n",
    "            f\"{row['Eta_Squared']:.3f}\", va='center', fontsize=7)\n",
    "\n",
    "save_plot(\"06_correlation_with_target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 7. Encoding Test (Leak-Free Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test che encoding sia leak-free con split train/test\n",
    "print(\"=\" * 80)\n",
    "print(\"ENCODING LEAK-FREE TEST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Split temporale (come nel progetto)\n",
    "if 'AI_Anno' in df.columns:\n",
    "    df_sorted = df.sort_values('AI_Anno')\n",
    "    split_idx = int(len(df_sorted) * 0.8)\n",
    "    train_df = df_sorted.iloc[:split_idx].copy()\n",
    "    test_df = df_sorted.iloc[split_idx:].copy()\n",
    "else:\n",
    "    # Fallback: random split\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nüìä Split:\")\n",
    "print(f\"   Train: {len(train_df):,} samples\")\n",
    "print(f\"   Test:  {len(test_df):,} samples\")\n",
    "\n",
    "# Test per ogni feature categorica\n",
    "unseen_analysis = []\n",
    "\n",
    "for col in categorical_cols:\n",
    "    train_categories = set(train_df[col].dropna().unique())\n",
    "    test_categories = set(test_df[col].dropna().unique())\n",
    "    \n",
    "    unseen_categories = test_categories - train_categories\n",
    "    unseen_pct = len(unseen_categories) / len(test_categories) * 100 if len(test_categories) > 0 else 0\n",
    "    \n",
    "    strategy = cardinality_df[cardinality_df['Feature'] == col]['Strategy'].values[0]\n",
    "    \n",
    "    unseen_analysis.append({\n",
    "        'Feature': col,\n",
    "        'Strategy': strategy,\n",
    "        'Train_Unique': len(train_categories),\n",
    "        'Test_Unique': len(test_categories),\n",
    "        'Unseen': len(unseen_categories),\n",
    "        'Unseen_Pct': unseen_pct,\n",
    "    })\n",
    "\n",
    "unseen_df = pd.DataFrame(unseen_analysis)\n",
    "unseen_df = unseen_df.sort_values('Unseen_Pct', ascending=False)\n",
    "\n",
    "print(\"\\nüìä Unseen Categories Analysis:\")\n",
    "print(\"\\n\", unseen_df.to_string(index=False))\n",
    "\n",
    "# Salva\n",
    "unseen_df.to_csv(OUTPUT_DIR / \"07_unseen_categories_analysis.csv\", index=False)\n",
    "print(f\"\\nüíæ Salvato: 07_unseen_categories_analysis.csv\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n‚ö†Ô∏è  Features con unseen categories > 0%: {(unseen_df['Unseen_Pct'] > 0).sum()}\")\n",
    "if (unseen_df['Unseen_Pct'] > 0).sum() > 0:\n",
    "    print(\"\\n   Queste features richiedono handling per unseen categories!\")\n",
    "    print(\"   - Target Encoding: usa mean globale per unseen\")\n",
    "    print(\"   - Frequency Encoding: usa freq=0 per unseen\")\n",
    "    print(\"   - OneHot: crea colonna 'unknown' o ignora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart: unseen categories percentage\n",
    "fig, ax = plt.subplots(figsize=(12, max(6, len(unseen_df) * 0.3)))\n",
    "\n",
    "colors = [color_map[s] for s in unseen_df['Strategy']]\n",
    "\n",
    "ax.barh(range(len(unseen_df)), unseen_df['Unseen_Pct'], \n",
    "        color=colors, edgecolor='black')\n",
    "ax.set_yticks(range(len(unseen_df)))\n",
    "ax.set_yticklabels(unseen_df['Feature'], fontsize=8)\n",
    "ax.set_xlabel('Unseen Categories (%)')\n",
    "ax.set_title('Unseen Categories in Test Set', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Soglia warning\n",
    "ax.axvline(x=5, color='red', linestyle='--', linewidth=2, label='Warning (>5%)')\n",
    "ax.legend()\n",
    "\n",
    "# Aggiungi valori\n",
    "for i, row in unseen_df.iterrows():\n",
    "    if row['Unseen_Pct'] > 0:\n",
    "        ax.text(row['Unseen_Pct'] + 0.2, unseen_df.index.get_loc(i), \n",
    "                f\"{row['Unseen_Pct']:.1f}%\", va='center', fontsize=7)\n",
    "\n",
    "save_plot(\"08_unseen_categories\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã 8. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report finale\n",
    "report = {\n",
    "    'categorical_features': len(categorical_cols),\n",
    "    'encoding_strategies': {\n",
    "        'onehot': {\n",
    "            'threshold': '‚â§ 10 unique',\n",
    "            'features_count': int((cardinality_df['Strategy'] == 'OneHot').sum()),\n",
    "            'dimensions': int(onehot_dims),\n",
    "        },\n",
    "        'target': {\n",
    "            'threshold': '11-50 unique',\n",
    "            'features_count': int((cardinality_df['Strategy'] == 'Target').sum()),\n",
    "            'dimensions': int(target_dims),\n",
    "        },\n",
    "        'frequency': {\n",
    "            'threshold': '> 50 unique',\n",
    "            'features_count': int((cardinality_df['Strategy'] == 'Frequency').sum()),\n",
    "            'dimensions': int(freq_dims),\n",
    "        },\n",
    "    },\n",
    "    'dimensionality': {\n",
    "        'before': int(original_dims),\n",
    "        'after': int(total_categorical_dims),\n",
    "        'expansion_factor': float(total_categorical_dims / original_dims),\n",
    "    },\n",
    "    'unseen_categories': {\n",
    "        'features_with_unseen': int((unseen_df['Unseen_Pct'] > 0).sum()),\n",
    "        'max_unseen_pct': float(unseen_df['Unseen_Pct'].max()),\n",
    "    },\n",
    "    'top_predictive_features': [\n",
    "        {'feature': row['Feature'], 'eta_squared': float(row['Eta_Squared'])}\n",
    "        for _, row in correlation_df.head(5).iterrows()\n",
    "    ],\n",
    "    'recommendation': (\n",
    "        f\"Config attuale OK: {len(categorical_cols)} features ‚Üí {total_categorical_dims} dims \"\n",
    "        f\"(expansion {total_categorical_dims/original_dims:.1f}x). \"\n",
    "        f\"Soglie (10, 50) sono appropriate.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Salva JSON\n",
    "import json\n",
    "with open(OUTPUT_DIR / \"00_summary_report.json\", 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìã FINAL REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(report, indent=2))\n",
    "print(f\"\\nüíæ Salvato: 00_summary_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusioni\n",
    "\n",
    "### File Generati\n",
    "\n",
    "1. `00_summary_report.json` - Report completo\n",
    "2. `01_cardinality_analysis.csv` - Cardinalit√† per feature\n",
    "3. `02_cardinality_bar_chart.png` - Bar chart cardinalit√†\n",
    "4. `03_strategies_pie_chart.png` - Pie chart strategie\n",
    "5. `04_dimensionality_impact.png` - Impatto dimensionalit√†\n",
    "6. `05_correlation_with_target.csv` - Correlazioni con target\n",
    "7. `06_correlation_with_target.png` - Bar chart correlazioni\n",
    "8. `07_unseen_categories_analysis.csv` - Analisi unseen categories\n",
    "9. `08_unseen_categories.png` - Bar chart unseen categories\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **Configurazione attuale** (soglie 10, 50) bilancia bene dimensionalit√† e informazione\n",
    "- **OneHot** per low cardinality: interpretabile ma espande dims\n",
    "- **Target** per medium cardinality: compatto ma rischio leakage (gestito)\n",
    "- **Frequency** per high cardinality: loss information ma scalabile\n",
    "\n",
    "### Raccomandazioni\n",
    "\n",
    "- Se expansion factor > 5x: aumenta soglia OneHot (es. 5 invece di 10)\n",
    "- Se unseen > 10% per feature: considera strategy pi√π robusta\n",
    "- Features con alta correlazione (eta¬≤): priorit√† per tuning encoding\n",
    "- SEMPRE test leak-free su split temporale!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stimatrix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
