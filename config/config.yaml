# Configurazione Preprocessing Pipeline
# =================================

# Logging Configuration
logging:
  level: ${LOG_LEVEL:-INFO}
  format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
  file: ${LOG_FILE:-'logs/pipeline.log'}
  console: ${LOG_CONSOLE:-true}
  rotate:
    enabled: ${LOG_ROTATE:-false}
    max_bytes: ${LOG_MAX_BYTES:-10485760}
    backup_count: ${LOG_BACKUP_COUNT:-5}

# Execution Configuration
execution:
  steps: ["all"]
  force_reload: true

# Experiment tracking (Weights & Biases)
tracking:
  wandb:
    enabled: ${WANDB_ENABLED:-true}
    project: ${WANDB_PROJECT:-'stimatrix'}
    entity: ${WANDB_ENTITY:-null}
    group: ${WANDB_GROUP:-null}
    tags: []
    mode: ${WANDB_MODE:-'online'}  # online | offline | disabled
    name: null

# Paths Configuration
paths:
  raw_data: ${RAW_DATA_DIR:-'data/raw'}
  preprocessed_data: ${PREPROC_DIR:-'data/preprocessed'}
  schema: ${SCHEMA_PATH:-'schema/db_schema.json'}
  models_dir: ${MODELS_DIR:-'models'}
  raw_filename: 'raw.parquet'
  preprocessed_filename: 'preprocessed.parquet'

# Database Configuration (for data retrieval)
database:
  schema_name: null
  selected_aliases: ['A', 'AI', 'PC', 'ISC', 'II', 'PC_OZ', 'OZ', 'OV', 'C1', 'C2']  # C1=attiimmobili_cened1, C2=attiimmobili_cened2
  # Custom alias mapping for specific tables/views (optional)
  # If not specified, defaults are used for known views (C1, C2)
  custom_aliases:
    attiimmobili_cened1: 'C1'
    attiimmobili_cened2: 'C2'
  use_poi: true
  use_ztl: true
  output_format: 'parquet'
  compression: 'snappy'

# Target configuration
target:
  # Choose among ['AI_Prezzo_Ridistribuito', 'AI_Prezzo_MQ']
  column_candidates: ['AI_Prezzo_Ridistribuito', 'AI_Prezzo_MQ']
  
  # Target transformation
  # Options: 'none', 'log', 'log10', 'sqrt', 'boxcox', 'yeojohnson'
  # Default: 'boxcox' (often works better for price data than log)
  transform: 'boxcox'
  log10_offset: 1.0  # Used only for log10 transform

# Outlier detection
outliers:
  method: 'ensemble'       # 'iqr' | 'zscore' | 'iso_forest' | 'ensemble'
  z_thresh: 3.0
  iqr_factor: 1.5
  iso_forest_contamination: 0.02
  group_by_col: 'AI_IdTipologiaEdilizia'
  min_group_size: 30       # minimum samples per group to apply group-wise outlier detection
  fallback_strategy: 'global'  # 'skip' keeps all small groups; 'global' applies global detection

# Missing value imputation
imputation:
  numeric_strategy: 'median'      # 'median' | 'mean'
  categorical_strategy: 'most_frequent'
  group_by_col: 'AI_IdTipologiaEdilizia'

# Categorical encoding
# Advanced multi-strategy encoding (enabled via profile config)
# Automatic strategy selection based on cardinality:
# - ≤one_hot_max → One-Hot Encoding
# - target_encoding_range → Target Encoding (smoothed)
# - frequency_encoding_range → Frequency Encoding
# - ordinal_encoding_range → Ordinal Encoding
# - >drop_above → DROP
encoding: &encoding_defaults
  one_hot_max: 10
  target_encoding_range: [11, 30]
  frequency_encoding_range: [31, 100]
  ordinal_encoding_range: [101, 200]
  drop_above: 200
  
  # Target encoder settings (category_encoders.TargetEncoder)
  target_encoder:
    smoothing: 1.0  # Regularization parameter
    min_samples_leaf: 1
  
  # Boolean handling
  handle_booleans: true
  boolean_null_value: -1  # Value for missing booleans

# Temporal split configuration
temporal_split:
  year_col: 'A_AnnoStipula'
  month_col: 'A_MeseStipula'
  mode: 'fraction'      # 'date' | 'fraction'
  fraction:
    train: 0.7          # fraction of time-ordered data for train
    valid: 0.2          # fraction of time-ordered data for validation (0 disables val)
  date:
    test_start_year: 2023 # used only if mode=='date'
    test_start_month: 1   # used only if mode=='date'

# Numeric coercion configuration
numeric_coercion:
  enabled: true
  threshold: 0.95
  blacklist_globs:
    - 'II_*'
    - 'AI_Id*'
    - 'Foglio'
    - 'Particella*'
    - 'Subalterno'
    - 'SezioneAmministrativa'
    - 'ZonaOmi'
    - '*COD*'

# PCA configuration
pca: &pca_defaults
  enabled: false
  n_components: 0.95
  random_state: 42

# Correlation pruning
correlation: &correlation_defaults
  numeric_threshold: 0.95

# Non-descriptive columns pruning
drop_non_descriptive:
  na_threshold: 0.80

# Feature extraction toggles
feature_extraction:
  geometry: true
  json: true

# ✨ NEW: Advanced Features Configuration
advanced_features:
  # === TEMPORAL FEATURES ===
  temporal:
    enabled: true
    features:
      - 'quarter'              # Q1, Q2, Q3, Q4
      - 'is_summer'            # June-August flag
      - 'month_sin'            # Cyclic encoding (sin)
      - 'month_cos'            # Cyclic encoding (cos)
      - 'months_since_start'   # Progressive time counter
  
  # === GEOGRAPHIC FEATURES ===
  geographic:
    enabled: true
    # Spatial clustering (KMeans on lat/lon)
    spatial_clusters:
      enabled: true
      n_clusters: 8
      feature_name: 'geo_cluster'
    # Distance from city center (Haversine)
    distance_to_center:
      enabled: true
      center_lat: 45.1564  # Mantova center
      center_lon: 10.7914
      feature_name: 'distance_to_center_km'
    # Property density (neighbors within radius)
    density:
      enabled: true
      radius_km: 0.5  # 500m radius
      feature_name: 'density_500m'
  
  # === INTERACTION FEATURES ===
  interactions:
    enabled: true
    # Categorical × Numeric interactions
    categorical_numeric:
      - ['AI_Superficie', 'AI_ZonaOmi']
      - ['AI_Superficie', 'AI_IdTipologiaEdilizia']
    # Categorical × Categorical interactions
    categorical_categorical:
      - ['AI_IdCategoriaCatastale', 'AI_ZonaOmi']
    # Polynomial features
    polynomial:
      columns: ['AI_Superficie']
      degree: 2  # superficie²
  
  # === MISSING PATTERN FLAGS ===
  missing_patterns:
    enabled: true
    # Create "has_CENED" flags for CENED data availability
    create_flags_for_prefixes: ['C1_', 'C2_']
    feature_name_template: 'has_{prefix}'

# Feature pruning
feature_pruning:
  drop_columns:
    - 'A_ImmobiliPrincipaliConSuperficieValorizzata'
    - 'AI_SuperficieCalcolata'
    - 'AI_SuperficieVisuraTotale'
    - 'AI_SuperficieVisuraTotaleE'
    - 'AI_SuperficieVisuraTotaleAttuale'
    - 'AI_SuperficieVisuraTotaleEAttuale'
    - 'A_AcquirentiCount'
    - 'A_VenditoriCount'
    - 'A_EtaMediaAcquirenti'
    - 'A_EtaMediaVenditori'
    - 'A_AcquirentiVenditoriStessoCognome'
    - 'A_VenditoriEredita'
    - 'AI_Subalterno'
    - 'AI_Piano'
    - 'AI_Rendita'
  # Keep AI_Superficie as a feature (set to false to drop from X)
  include_ai_superficie: true

# Scaling configuration
scaling: &scaling_defaults
  scaler_type: 'standard'   # 'standard' | 'robust' | 'none'
  with_mean: true
  with_std: true

# Winsorization (quantile clipping on numeric features)
winsorization: &winsor_defaults
  enabled: true
  lower_quantile: 0.01
  upper_quantile: 0.99

# Profiles: generate multiple datasets tailored to model families
profiles:
  scaled:
    enabled: false
    output_prefix: 'scaled'
    encoding: *encoding_defaults
    winsorization: *winsor_defaults
    scaling: *scaling_defaults
    pca: *pca_defaults
    correlation: *correlation_defaults
    apply_advanced_encoding: false
  tree:
    enabled: true
    output_prefix: 'tree'
    encoding: *encoding_defaults
    correlation: *correlation_defaults
    apply_advanced_encoding: true
  catboost:
    enabled: true
    output_prefix: 'catboost'
    correlation: *correlation_defaults
    apply_advanced_encoding: false

# Training configuration
training:
  # Opzioni globali
  primary_metric: "neg_root_mean_squared_error" # 'r2' | 'neg_root_mean_squared_error' | 'neg_mean_squared_error' | 'neg_mean_absolute_error' | 'neg_mean_absolute_percentage_error'
  report_metrics: ["r2", "rmse", "mse", "mae", "mape"]
  sampler: "auto"   # auto (OptunaHub) | tpe
  seed: ${SEED:-42}
  n_jobs_default: ${N_JOBS:--1}
  timeout: ${TRAIN_TIMEOUT:-null}
  trials_base: &trials_base 50
  trials_advanced: &trials_advanced 100
  
  # ✨ NEW: Optuna Pruner for early stopping of unpromising trials
  pruner:
    enabled: true
    type: "median"  # 'median' | 'percentile'
    n_warmup_steps: 10  # Number of warmup steps before pruning starts
    # percentile: 25.0  # Only for percentile pruner
  
  # Cross-validation usata quando non esiste un validation set esterno (valid_fraction=0)
  cv_when_no_val:
    enabled: true
    kind: kfold   # 'timeseries' | 'kfold'
    n_splits: 5
    shuffle: true     # usato solo per kfold

  models:
    linear:
      enabled: false
      profile: scaled
      trials: 1
      base_params: {}
      fit_params: {}
      search_space: {}
    ridge:
      enabled: false
      profile: scaled
      trials: *trials_base
      base_params: {}
      fit_params: {}
      search_space:
        alpha: {type: float, low: 0.000001, high: 1000.0, log: true}
    lasso:
      enabled: false
      profile: scaled
      trials: *trials_base
      base_params: {}
      fit_params: {}
      search_space:
        alpha: {type: float, low: 0.0001, high: 10.0, log: true}
    elasticnet:
      enabled: false
      profile: scaled
      trials: *trials_base
      base_params: {}
      fit_params: {}
      search_space:
        alpha: {type: float, low: 0.0001, high: 10.0, log: true}
        l1_ratio: {type: float, low: 0.0, high: 1.0}
    knn:
      enabled: false
      profile: scaled
      trials: *trials_base
      base_params: {}
      fit_params: {}
      search_space:
        n_neighbors: {type: int, low: 3, high: 50}
        weights: {type: categorical, choices: ["uniform", "distance"]}
        p: {type: int, low: 1, high: 2}
    svr:
      enabled: false
      profile: scaled
      trials: *trials_base
      base_params: {}
      fit_params: {}
      search_space:
        kernel: {type: categorical, choices: ["rbf", "poly", "sigmoid"]}
        C: {type: float, low: 0.01, high: 1000.0, log: true}
        epsilon: {type: float, low: 0.001, high: 1.0, log: true}
        gamma: {type: float, low: 0.0001, high: 10.0, log: true}
        degree: {type: int, low: 2, high: 5}
        coef0: {type: float, low: 0.0, high: 1.0}
    dt:
      enabled: false
      profile: tree
      trials: *trials_advanced
      base_params: {}
      fit_params: {}
      search_space:
        max_depth: {type: int, low: 3, high: 30}
        min_samples_split: {type: int, low: 2, high: 20}
        min_samples_leaf: {type: int, low: 1, high: 20}
        max_features: {type: categorical, choices: ["sqrt", "log2", null]}
        min_impurity_decrease: {type: float, low: 0.0, high: 0.01}
    rf:
      enabled: true
      profile: tree
      trials: *trials_advanced
      base_params: {}
      fit_params: {}
      search_space:
        n_estimators: {type: int, low: 200, high: 1200}
        max_depth: {type: int, low: 4, high: 40}
        min_samples_split: {type: int, low: 2, high: 20}
        min_samples_leaf: {type: int, low: 1, high: 20}
        max_features: {type: categorical, choices: ["sqrt", "log2", null]}
        bootstrap: {type: categorical, choices: [true, false]}
    gbr:
      enabled: true
      profile: tree
      trials: 150
      base_params: {}
      fit_params: {}
      search_space:
        learning_rate: {type: float, low: 0.001, high: 0.3, log: true}
        n_estimators: {type: int, low: 200, high: 1500}
        max_depth: {type: int, low: 2, high: 8}
        subsample: {type: float, low: 0.5, high: 1.0}
        min_samples_leaf: {type: int, low: 1, high: 20}
        max_features: {type: categorical, choices: ["sqrt", "log2", null]}
        min_samples_split: {type: int, low: 2, high: 20}
        min_impurity_decrease: {type: float, low: 0.0, high: 0.01}
    hgbt:
      enabled: true
      profile: tree
      trials: *trials_advanced
      base_params: {}
      fit_params: {}
      search_space:
        learning_rate: {type: float, low: 0.001, high: 0.3, log: true}
        max_depth: {type: int, low: 2, high: 16}
        max_leaf_nodes: {type: int, low: 7, high: 255}
        l2_regularization: {type: float, low: 0.000001, high: 10.0, log: true}
        max_bins: {type: int, low: 64, high: 255}
        min_samples_leaf: {type: int, low: 1, high: 50}
    xgboost:
      enabled: true
      profile: tree
      trials: 150
      base_params: {}
      fit_params: {}
      search_space:
        n_estimators: {type: int, low: 300, high: 1500}
        max_depth: {type: int, low: 3, high: 8}
        learning_rate: {type: float, low: 0.01, high: 0.1, log: true}
        subsample: {type: float, low: 0.6, high: 0.9}
        colsample_bytree: {type: float, low: 0.6, high: 0.9}
        min_child_weight: {type: float, low: 1.0, high: 10.0, log: true}
        reg_alpha: {type: float, low: 1e-4, high: 10.0, log: true}
        reg_lambda: {type: float, low: 1e-4, high: 10.0, log: true}
        gamma: {type: float, low: 1e-4, high: 10.0, log: true}
    lightgbm:
      enabled: true
      profile: tree
      trials: 150
      base_params: {}
      fit_params: {}
      search_space:
        n_estimators: {type: int, low: 300, high: 1500}
        max_depth: {type: categorical, choices: [-1, 4, 5, 6, 7, 8]}
        learning_rate: {type: float, low: 0.01, high: 0.1, log: true}
        num_leaves: {type: int, low: 16, high: 63}
        subsample: {type: float, low: 0.6, high: 0.9}
        colsample_bytree: {type: float, low: 0.6, high: 0.9}
        reg_alpha: {type: float, low: 1e-4, high: 10.0, log: true}
        reg_lambda: {type: float, low: 1e-4, high: 10.0, log: true}
        min_child_samples: {type: int, low: 20, high: 200}
        min_split_gain: {type: float, low: 0.0, high: 1.0}
    catboost:
      enabled: true
      profile: catboost
      trials: *trials_advanced
      base_params: {}
      fit_params:
        cat_features: __categorical_indices__
      search_space:
        depth: {type: int, low: 4, high: 10}
        learning_rate: {type: float, low: 0.001, high: 0.3, log: true}
        l2_leaf_reg: {type: float, low: 1.0, high: 15.0}
        bagging_temperature: {type: float, low: 0.0, high: 5.0}
        border_count: {type: int, low: 16, high: 255}
        random_strength: {type: float, low: 0.0, high: 2.0}
        rsm: {type: float, low: 0.5, high: 1.0}

  # SHAP feature importance
  shap:
    enabled: true
    sample_size: 500
    max_display: 50
    save_plots: true
    save_values: true

  # Ensemble settings
  ensembles:
    voting:
      enabled: true
      top_n: 3
      tune_weights: true
    stacking:
      enabled: true
      top_n: 5
      final_estimator: "ridge"
      cv_folds: 5

# ✨ NEW: Advanced Diagnostics Configuration
diagnostics:
  # Residual analysis by group
  residual_analysis:
    enabled: true
    by_groups:
      - 'AI_ZonaOmi'
      - 'AI_IdCategoriaCatastale'
      - 'AI_IdTipologiaEdilizia'
      - 'price_quartile'  # Errors higher on expensive properties?
    save_worst_predictions: true
    top_n_worst: 50
    plots:
      - 'residual_vs_predicted'
      - 'residual_vs_actual'
      - 'residual_distribution'
  
  # Drift detection (train vs test)
  drift_detection:
    enabled: true
    methods:
      - 'psi'      # Population Stability Index
      - 'ks_test'  # Kolmogorov-Smirnov
    alert_threshold: 0.15  # PSI > 0.15 = significant drift
    save_report: true
    output_file: 'models/drift_report.json'

# ✨ NEW: Uncertainty Quantification
uncertainty:
  # Prediction intervals (empirical, fast)
  prediction_intervals:
    enabled: true
    method: 'residual_bootstrap'
    n_bootstraps: 100
    confidence_levels: [0.8, 0.9]  # 80% and 90% CI

# Evaluation configuration
evaluation:
  group_metrics:
    enabled: true
    group_by_columns: ['AI_ZonaOmi', 'AI_IdCategoriaCatastale', 'AI_IdTipologiaEdilizia']
    min_group_size: 10
    original_scale: true
    report_metrics: ['r2', 'rmse', 'mse', 'mae', 'mape', 'medae']
    price_band:
      method: 'quantile'   # 'quantile' | 'fixed'
      quantiles: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
      # fixed_edges: [0, 100000, 200000, 400000, 800000, 1600000, .inf]
      mape_floor: 1000.0
      merge_small_bins: true
      label_prefix: 'PREZZO_'