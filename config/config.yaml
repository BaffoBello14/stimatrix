# Configurazione Preprocessing Pipeline
# =================================

# Logging Configuration
logging:
  level: INFO
  format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
  file: 'logs/pipeline.log'

# Paths Configuration
paths:
  raw_data: 'data/raw'
  preprocessed_data: 'data/preprocessed'
  schema: 'schema/db_schema.json'
  models_dir: 'models'
  raw_filename: 'raw.parquet'
  preprocessed_filename: 'preprocessed.parquet'

# Database Configuration (for data retrieval)
database:
  schema_name: null
  selected_aliases: ['A', 'AI', 'PC', 'ISC', 'II', 'PC_OZ', 'OZ', 'OV']
  use_poi: true
  use_ztl: true
  output_format: 'parquet'
  compression: 'snappy'

# Target configuration
target:
  column_candidates: ['AI_Prezzo_Ridistribuito']
  log_transform: false

# Outlier detection
outliers:
  method: 'ensemble'       # 'iqr' | 'zscore' | 'iso_forest' | 'ensemble'
  z_thresh: 4.0
  iqr_factor: 1.5
  iso_forest_contamination: 0.02
  group_by_col: 'AI_IdCategoriaCatastale'
  min_group_size: 30       # minimum samples per group to apply group-wise outlier detection
  fallback_strategy: 'global'  # 'skip' keeps all small groups; 'global' applies global detection

# Missing value imputation
imputation:
  numeric_strategy: 'median'      # 'median' | 'mean'
  categorical_strategy: 'most_frequent'
  group_by_col: 'AI_IdCategoriaCatastale'

# Categorical encoding
encoding:
  max_ohe_cardinality: 12

# Temporal split configuration
temporal_split:
  year_col: 'A_AnnoStipula'
  month_col: 'A_MeseStipula'
  mode: 'fraction'      # 'date' | 'fraction'
  train_fraction: 0.8   # fraction of time-ordered data for train
  valid_fraction: 0.1   # fraction of time-ordered data for validation (0 disables val)
  test_start_year: 2023 # used only if mode=='date'
  test_start_month: 1   # used only if mode=='date'

# PCA configuration
pca:
  enabled: false
  n_components: 0.95
  random_state: 42

# Correlation pruning
correlation:
  numeric_threshold: 0.98

# Feature extraction toggles
feature_extraction:
  geometry: true
  json: true

# Scaling configuration
scaling:
  scaler_type: 'standard'   # 'standard' | 'robust' | 'none'
  with_mean: true
  with_std: true

# Winsorization (quantile clipping on numeric features)
winsorization:
  enabled: false
  lower_quantile: 0.01
  upper_quantile: 0.99

# Profiles: generate multiple datasets tailored to model families
profiles:
  scaled:
    enabled: true
    output_prefix: 'scaled'
    encoding:
      max_ohe_cardinality: 12
    winsorization:
      enabled: false
      lower_quantile: 0.01
      upper_quantile: 0.99
    scaling:
      scaler_type: 'standard'   # 'standard' | 'robust' | 'none'
      with_mean: true
      with_std: true
    pca:
      enabled: false
      n_components: 0.95
      random_state: 42
    correlation:
      numeric_threshold: 0.98
  tree:
    enabled: false
    output_prefix: 'tree'
    encoding:
      max_ohe_cardinality: 12
    correlation:
      numeric_threshold: 0.98
  catboost:
    enabled: false
    output_prefix: 'catboost'
    correlation:
      numeric_threshold: 0.98

# Training configuration
training:
  # Modelli da addestrare (identificatori)
  # Possibili: linear, ridge, lasso, elasticnet, dt, knn, svr, rf, gbr, hgbt, xgboost, lightgbm, catboost, voting, stacking
  models: ["ridge", "rf", "lightgbm", "xgboost", "catboost"]

  # Profilo dataset per famiglia di modelli (se non presente, fallback ai file senza suffisso)
  profile_map:
    linear: "scaled"
    ridge: "scaled"
    lasso: "scaled"
    elasticnet: "scaled"
    knn: "scaled"
    svr: "scaled"
    dt: "tree"
    rf: "tree"
    gbr: "tree"
    hgbt: "tree"
    xgboost: "tree"
    lightgbm: "tree"
    catboost: "catboost"

  # Metrica primaria da massimizzare durante il tuning
  # Supportate: r2, neg_mean_squared_error, neg_root_mean_squared_error, neg_mean_absolute_error, neg_mean_absolute_percentage_error
  primary_metric: "r2"

  # Metrica per il report finale (sempre calcoliamo tutte queste positive); non influenza la direzione del tuning
  report_metrics: ["r2", "rmse", "mse", "mae", "mape"]

  # Optuna/OptunaHub
  optuna:
    n_trials: 50
    timeout: null  # secondi, null per nessun timeout
    sampler: "auto"  # "auto" usa optunahub samplers/auto_sampler; "tpe" per TPE standard
    seed: 42

  # SHAP feature importance
  shap:
    enabled: true
    sample_size: 2000
    max_display: 30
    save_plots: true
    save_values: false  # salva shap_values completi (pu√≤ essere molto pesante)

  # Ensemble settings
  ensembles:
    voting:
      enabled: true
      top_n: 3
      tune_weights: true
    stacking:
      enabled: true
      top_n: 5
      final_estimator: "ridge"  # ridge | lgbm
      cv_folds: 5