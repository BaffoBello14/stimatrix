# ==========================================
# CONFIGURAZIONE FAST - STIMATRIX
# ==========================================
# 
# Config per test rapidi e sviluppo.
# Usa meno trial per hyperparameter tuning (20 vs 150)
# e disabilita modelli secondari.
#
# â±ï¸ Tempo stimato: ~15-20 minuti (vs 2-3 ore config normale)
# ðŸ“Š Performance: Leggermente inferiore al config.yaml
# ðŸŽ¯ Uso: Testing, debug, iterazione veloce
# ==========================================

# Logging Configuration
logging:
  level: ${LOG_LEVEL:-INFO}
  format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
  file: ${LOG_FILE:-'logs/pipeline_fast.log'}
  console: ${LOG_CONSOLE:-true}
  rotate:
    enabled: ${LOG_ROTATE:-false}
    max_bytes: ${LOG_MAX_BYTES:-10485760}
    backup_count: ${LOG_BACKUP_COUNT:-5}

# Execution Configuration
execution:
  steps: ["preprocessing", "training", "evaluation"]
  force_reload: true

# Experiment tracking (Weights & Biases)
tracking:
  wandb:
    enabled: ${WANDB_ENABLED:-true}
    project: ${WANDB_PROJECT:-'stimatrix-fast'}
    entity: ${WANDB_ENTITY:-null}
    group: ${WANDB_GROUP:-'fast-test'}
    tags: ['fast', 'test', 'development']
    mode: ${WANDB_MODE:-'online'}
    name: 'fast_test'

# Paths Configuration
paths:
  raw_data: ${RAW_DATA_DIR:-'data/raw'}
  preprocessed_data: ${PREPROC_DIR:-'data/preprocessed'}
  schema: ${SCHEMA_PATH:-'schema/db_schema.json'}
  models_dir: ${MODELS_DIR:-'models'}
  raw_filename: 'raw.parquet'
  preprocessed_filename: 'preprocessed.parquet'

# ==========================================
# DATA FILTERS (Sperimentazione)
# ==========================================
# Filtri applicati al dataset INTERO (prima dello split) per sperimentazione
# Usare per testare modelli specializzati su sottoinsiemi specifici
# Tutti i filtri sono opzionali (null = no filter)
data_filters:
  # Metadata
  experiment_name: "baseline_full"
  description: "Baseline completo - tutti immobili post-2022"
  
  # Temporali
  anno_min: null      # Min anno stipula (null = no limit)
  anno_max: null      # Max anno stipula
  mese_min: null      # Min mese 1-12 (null = no limit)
  mese_max: null      # Max mese 1-12
  
  # Target (prezzo) - âš ï¸ USARE CON CAUTELA! Limita generalizzazione
  prezzo_min: null       # Min prezzo â‚¬ (null = no limit)
  prezzo_max: null       # Max prezzo â‚¬
  prezzo_mq_min: null    # Min â‚¬/mÂ² (null = no limit)
  prezzo_mq_max: null    # Max â‚¬/mÂ²
  
  # Caratteristiche immobile
  superficie_min: null   # Min mÂ² (null = no limit)
  superficie_max: null   # Max mÂ²
  locali_min: null       # Min numero locali
  locali_max: null       # Max numero locali
  piano_min: null        # Min piano (-1 per seminterrato)
  piano_max: null        # Max piano
  
  # Geografiche (null = no filter)
  zone_incluse: null     # Lista zone OMI da includere (null = tutte)
  zone_escluse: null     # Lista zone OMI da escludere
  tipologie_incluse: null  # Lista tipologie da includere
  tipologie_escluse: null  # Lista tipologie da escludere
  
  # QualitÃ  dati
  max_missing_ratio: null  # Max % missing per record (es. 0.5 = max 50% missing)
  remove_outliers_iqr: false  # Rimuovi outliers IQR sul prezzo
  iqr_factor: 1.5         # Fattore IQR (se remove_outliers_iqr=true)

# Esempi per sperimentazione:
#
# Esperimento "Mid-Range":
#   experiment_name: "midrange_50k_150k"
#   description: "Immobili mid-range 50k-150kâ‚¬"
#   prezzo_min: 50000
#   prezzo_max: 150000
#
# Esperimento "Luxury":
#   experiment_name: "luxury_segment"
#   description: "Segmento luxury >200k, >3kâ‚¬/mÂ²"
#   prezzo_min: 200000
#   prezzo_mq_min: 3000
#   zone_incluse: ['C1', 'C2', 'D2']
#
# Esperimento "Large Properties":
#   experiment_name: "large_properties"
#   description: "Immobili grandi 100-300mÂ²"
#   superficie_min: 100
#   superficie_max: 300

# Temporal and zone filtering
temporal_filter:
  enabled: true
  min_year: 2022
  min_month: null
  exclude_zones:
    - 'E1'
    - 'E2'
    - 'E3'
    - 'R1'
  exclude_tipologie:
    - '4'  # Ville

# Database Configuration
database:
  schema_name: null
  selected_aliases: ['A', 'AI', 'PC', 'ISC', 'II', 'PC_OZ', 'OZ', 'OV', 'C1', 'C2']
  custom_aliases:
    attiimmobili_cened1: 'C1'
    attiimmobili_cened2: 'C2'
  use_poi: true
  use_ztl: true
  output_format: 'parquet'
  compression: 'snappy'

# Target configuration - MIGLIORATO
target:
  column_candidates: ['AI_Prezzo_Ridistribuito']  # âœ… Solo prezzo redistribuito (prezzo/mq rimosso)
  
  # Yeo-Johnson Ã¨ piÃ¹ flessibile di log per distribuzioni eterogenee
  transform: 'yeojohnson'  # âœ… CAMBIATO da 'log' - trova automaticamente lambda ottimale
  
  # Fallback se yeojohnson da problemi
  # transform: 'log'
  log10_offset: 1.0

# Outlier detection - PIÃ™ AGGRESSIVO
outliers:
  method: 'ensemble'
  z_thresh: 2.5           # âœ… RIDOTTO da 3.0 - piÃ¹ aggressivo
  iqr_factor: 1.0         # âœ… RIDOTTO da 1.2
  iso_forest_contamination: 0.08  # âœ… AUMENTATO da 0.05
  group_by_col: 'AI_ZonaOmi'
  min_group_size: 20      # âœ… RIDOTTO da 30
  fallback_strategy: 'global'

# Missing value imputation
imputation:
  numeric_strategy: 'median'
  categorical_strategy: 'most_frequent'
  group_by_col: 'AI_ZonaOmi'

# Categorical encoding - PIÃ™ CONSERVATIVO
encoding: &encoding_defaults
  one_hot_max: 8          # âœ… RIDOTTO da 10
  target_encoding_range: [9, 20]    # âœ… RIDOTTO upper da 30
  frequency_encoding_range: [21, 100]
  ordinal_encoding_range: [101, 200]
  drop_above: 200
  
  # Target encoding con piÃ¹ smoothing per prevenire overfitting
  target_encoder:
    smoothing: 5.0        # âœ… AUMENTATO da 1.0
    min_samples_leaf: 10  # âœ… AUMENTATO da 1
    # noise: 0.01         # Opzionale: aggiungi rumore per regularizzazione

# Temporal split configuration
temporal_split:
  year_col: 'A_AnnoStipula'
  month_col: 'A_MeseStipula'
  mode: 'fraction'
  fraction:
    train: 0.7
    valid: 0.2
  date:
    test_start_year: 2023
    test_start_month: 1

# Numeric coercion configuration - âœ… CORRETTO (data-driven)
numeric_coercion:
  enabled: true
  threshold: 0.95  # Converti solo se â‰¥95% valori sono convertibili
  
  # Blacklist: colonne che SEMBRANO numeriche ma NON devono essere convertite
  # (es. "00020" = codice catastale â†’ deve rimanere string per CatBoost)
  blacklist_globs:
    # ID e chiavi esterne
    - '*Id'                        # Tutti gli ID (A_Id, AI_Id, PC_Id, ...)
    - '*_Id*'                      # Varianti (IdAtto, IdParticella, ...)
    
    # Codici catastali (con leading zeros)
    - 'Foglio*'                    # Foglio catastale ("0001")
    - '*Particella*'               # Particella ("00350")
    - '*Subalterno*'               # Subalterno ("0001")
    - '*Sezione*'                  # Sezioni catastali ("01")
    
    # Codici e zone (categorici)
    - '*COD*'                      # Tutti i codici
    - '*Codice*'                   # Varianti
    - 'AI_ZonaOmi'                 # Zona OMI ("D2", "C4") - CATEGORICO
    - 'OZ_CodiceZona'              # Codice zona
    - '*IdCategoriaCatastale*'     # Categorie ("00210", "00020")
    - '*IdTipologiaEdilizia*'      # Tipologie ("2", "3", "8")
    
    # Metadata
    - '*Repertorio*'               # Numero repertorio notaio
    
    # IMPORTANTE: Solo ID Istat, NON metriche II_ST* (sono numerici veri!)
    - 'II_IdIstatZonaCensuaria'    # ID (non metrica)
    - 'ISC_Id'                     # ID sezione
    # NOTA: II_ST1, II_ST2, II_P98, ecc. â†’ DEVONO essere convertiti in float!

# PCA configuration (DISABILITATO - mantiene piÃ¹ informazioni)
pca: &pca_defaults
  enabled: false
  n_components: 0.95
  random_state: 42

# Correlation pruning - RIDOTTA soglia
correlation: &correlation_defaults
  numeric_threshold: 0.98  # âœ… AUMENTATO da 0.95 (mantiene piÃ¹ feature)

# Non-descriptive columns pruning
drop_non_descriptive:
  na_threshold: 0.80

# Feature extraction toggles
feature_extraction:
  geometry: false
  json: false

# Feature pruning - âœ… ESPANSO (data-driven: ~56 colonne)
feature_pruning:
  drop_columns:
    # === ID e chiavi esterne (12 colonne) === #
    - 'A_Id'                        # ID atto (univoco)
    - 'AI_Id'                       # ID atto immobile (quasi univoco)
    - 'AI_IdAtto'                   # Foreign key
    - 'AI_IdParticellaCatastale'    # Foreign key
    - 'AI_IdImmobile'               # ID univoco
    - 'PC_Id'                       # ID particella
    - 'PC_IdSezioneCensuaria'       # Foreign key
    - 'ISC_Id'                      # ID sezione censuaria
    - 'II_IdIstatZonaCensuaria'     # Foreign key
    - 'OZ_Id'                       # ID zona OMI
    - 'PC_OZ_IdParticella'          # Foreign key
    - 'PC_OZ_IdZona'                # Foreign key
    
    # === Superficie ridondanti (5 colonne - correlazione > 0.98) === #
    - 'AI_SuperficieCalcolata'           # r=0.91 con AI_Superficie
    - 'AI_SuperficieVisuraTotale'        # r=1.0 con AI_Superficie (IDENTICA!)
    - 'AI_SuperficieVisuraTotaleE'       # r=0.995 con Totale
    - 'AI_SuperficieVisuraTotaleAttuale' # r=0.98 con AI_Superficie
    - 'AI_SuperficieVisuraTotaleEAttuale' # r=0.976 con Totale
    
    # === Indicatori Istat ridondanti (7 colonne - correlazione > 0.95) === #
    # Cluster 1: II_ST2_B, II_ST21, II_ST29 (r > 0.98) - keep II_ST1
    - 'II_ST2_B'                    # r=0.99 con II_ST21, II_ST29
    - 'II_ST21'                     # r=0.98 con II_ST1, II_ST29
    - 'II_ST29'                     # r=0.98 con II_ST2_B, II_ST1
    # Cluster 2: II_ST31, II_ST32 (r > 0.98) - keep II_ST23
    - 'II_ST31'                     # r=0.99 con II_ST23
    - 'II_ST32'                     # r=0.98 con II_ST23, II_ST31
    # Cluster 3: II_ST22, II_ST26 (r > 0.98) - keep II_ST2, II_ST20
    - 'II_ST22'                     # r=0.94 con II_ST2, II_ST20
    - 'II_ST26'                     # r=0.99 con II_ST2, II_ST20
    
    # === OmiValori ridondanti (4 colonne - correlazione > 0.98) === #
    - 'OV_ValoreMercatoMax_normale'      # r=0.98 con Min_normale
    - 'OV_ValoreMercatoMax_ottimo'       # r=0.98 con Min_ottimo
    - 'OV_ValoreMercatoMin_scadente'     # Pochi dati (scadente poco usato)
    - 'OV_ValoreMercatoMax_scadente'     # Pochi dati
    
    # === Metadata e colonne tecniche (13 colonne) === #
    - 'A_Semestre'                  # Ridondante con AnnoStipula/MeseStipula
    - 'OZ_IdAnnoSemestre'           # Ridondante
    - 'A_DataStipula'               # GiÃ  estratti anno/mese
    - 'A_DataRegistrazione'         # Metadata, non feature
    - 'A_TotaleFabbricati'          # Sempre uguale a TotaleImmobili (filtro WHERE)
    - 'A_TotaleImmobili'            # Constant dopo filtro
    - 'A_NumeroRepertorio'          # Metadata notaio
    - 'A_IdNotaio'                  # ID univoco, troppi unique
    - 'PC_PoligonoMetricoSrid'      # Constant (sempre stesso SRID)
    - 'PC_PoligonoMetrico'          # WKT grezzo (processato da feature extraction)
    - 'AI_IndirizzoGeometry'        # Geometry raw (processato da feature extraction)
    - 'OZ_IdComune'                 # Constant (singolo comune)
    - 'A_ImmobiliPrincipaliConSuperficieValorizzata'  # Metadata
    
    # === Codici catastali (8 colonne - poco predittivi) === #
    - 'PC_Foglio'                   # Codice catastale (troppi unique)
    - 'PC_Particella'               # Codice catastale (troppi unique)
    - 'PC_SezioneUrbana'            # Codice (molti missing)
    - 'PC_SezioneAmministrativa'    # Codice (molti missing)
    - 'PC_SezioneAggraria'          # Quasi sempre missing
    - 'OZ_CodiceZona'               # Codice (ridondante con AI_ZonaOmi)
    - 'OZ_DescrizioneZona'          # Testo (ridondante con CodiceZona)
    - 'AI_Subalterno'               # Codice catastale (non predittivo)
    
    # === Colonne processate o poco predittive (7 colonne) === #
    - 'AI_Piano'                    # Raw (estratte floor features dal preprocessing)
    - 'AI_Civico'                   # Raw (estratto AI_Civico_num)
    - 'AI_Rendita'                  # Alta correlazione con Prezzo (risk leakage)
    - 'A_AcquirentiCount'           # Poco predittivo
    - 'A_VenditoriCount'            # Poco predittivo
    - 'A_EtaMediaAcquirenti'        # Privacy + poco predittivo
    - 'A_EtaMediaVenditori'         # Privacy + poco predittivo
    - 'A_AcquirentiVenditoriStessoCognome'  # Poco predittivo
    - 'A_VenditoriEredita'          # Poco predittivo
    
    # === CENED con troppo missing (opzionale - verificare prima!) === #
    # Uncomment se missing > 50%:
    # - 'C1_EPGlNren'               # Metrica tecnica con troppi missing
    # - 'C1_EPHTot'                 # Metrica tecnica con troppi missing
    # - 'C2_ClasseEnergetica'       # Ridondante con C1
    # - 'C2_EPGlNren'               # Ridondante con C1

# Scaling configuration
scaling: &scaling_defaults
  scaler_type: 'standard'
  with_mean: true
  with_std: true

# Winsorization
winsorization: &winsor_defaults
  enabled: true
  lower_quantile: 0.01
  upper_quantile: 0.99

# Profiles
profiles:
  scaled:
    enabled: false
    output_prefix: 'scaled'
    encoding: *encoding_defaults
    winsorization: *winsor_defaults
    scaling: *scaling_defaults
    pca: *pca_defaults
    correlation: *correlation_defaults
  tree:
    enabled: true
    output_prefix: 'tree'
    encoding: *encoding_defaults
    correlation: *correlation_defaults
  catboost:
    enabled: true
    output_prefix: 'catboost'
    correlation: *correlation_defaults

# Diagnostics configuration
diagnostics:
  residual_analysis:
    enabled: true
    by_groups:
      - AI_ZonaOmi
      - AI_IdCategoriaCatastale
      - price_quartile
    save_worst_predictions: true
    top_n_worst: 50
    plots:
      - residual_vs_predicted
      - residual_vs_actual
      - residual_distribution
      - qq_plot
  
  drift_detection:
    enabled: true
    methods:
      - psi
      - ks_test
    alert_threshold: 0.15
    save_report: true

# Uncertainty quantification
uncertainty:
  prediction_intervals:
    enabled: true
    method: 'residual_bootstrap'
    n_bootstraps: 100
    confidence_levels: [0.8, 0.9]

# ==========================================
# TRAINING CONFIGURATION - OTTIMIZZATO
# ==========================================
training:
  primary_metric: "neg_mean_absolute_percentage_error"
  report_metrics: ["r2", "rmse", "mse", "mae", "mape"]
  sampler: "auto"
  seed: ${SEED:-42}
  n_jobs_default: ${N_JOBS:--1}
  timeout: ${TRAIN_TIMEOUT:-null}
  trials_base: &trials_base 10   # âš¡ RIDOTTO per test rapidi
  trials_advanced: &trials_advanced 20  # âš¡ RIDOTTO per test rapidi
  
  # Cross-validation robusta
  cv_when_no_val:
    enabled: true
    kind: kfold
    n_splits: 5           # âš¡ RIDOTTO per test rapidi
    shuffle: true

  # ==========================================
  # MODELLI - REGULARIZZAZIONE AGGRESSIVA
  # ==========================================
  models:
    # ========================================
    # CATBOOST - REGULARIZZATO
    # ========================================
    catboost:
      enabled: true
      profile: catboost
      trials: *trials_advanced
      base_params:
        allow_writing_files: false
        iterations: 800        # âœ… AUMENTATO - piÃ¹ iterazioni con regularizzazione
        verbose: False         # âœ… Riduce output
      fit_params:
        cat_features: __categorical_indices__
      search_space:
        depth: {type: int, low: 4, high: 7}  # âœ… RIDOTTO max da 10 a 7
        learning_rate: {type: float, low: 0.01, high: 0.12, log: true}  # âœ… RIDOTTO upper da 0.3
        l2_leaf_reg: {type: float, low: 3.0, high: 30.0}  # âœ… RIDOTTO range (piÃ¹ regularizzazione)
        bagging_temperature: {type: float, low: 0.0, high: 1.5}  # âœ… RIDOTTO max da 5.0
        border_count: {type: int, low: 32, high: 128}  # âœ… RIDOTTO max da 255
        random_strength: {type: float, low: 0.0, high: 1.0}  # âœ… RIDOTTO max da 2.0
        rsm: {type: float, low: 0.5, high: 0.85}  # âœ… RIDOTTO max da 1.0
        min_data_in_leaf: {type: int, low: 20, high: 80}  # âœ… NUOVO - previene overfitting
        max_ctr_complexity: {type: int, low: 1, high: 3}  # âœ… NUOVO - limita categorical interactions

    # ========================================
    # XGBOOST - REGULARIZZATO
    # ========================================
    xgboost:
      enabled: true
      profile: tree
      trials: *trials_advanced
      base_params: {}
      fit_params: {}
      search_space:
        n_estimators: {type: int, low: 400, high: 1200}
        max_depth: {type: int, low: 3, high: 6}  # âœ… RIDOTTO max da 8
        learning_rate: {type: float, low: 0.005, high: 0.05, log: true}  # âœ… RIDOTTO da 0.01-0.1
        subsample: {type: float, low: 0.6, high: 0.85}  # âœ… RIDOTTO max da 0.9
        colsample_bytree: {type: float, low: 0.6, high: 0.85}
        min_child_weight: {type: float, low: 5.0, high: 20.0}  # âœ… AUMENTATO min da 1.0
        reg_alpha: {type: float, low: 0.1, high: 50.0, log: true}  # âœ… AUMENTATO min da 1e-4
        reg_lambda: {type: float, low: 1.0, high: 100.0, log: true}  # âœ… AUMENTATO min da 1e-4
        gamma: {type: float, low: 0.0, high: 5.0}  # âœ… RIDOTTO max da 10.0 (linear scale)

    # ========================================
    # LIGHTGBM - REGULARIZZATO
    # ========================================
    lightgbm:
      enabled: true
      profile: tree
      trials: *trials_advanced
      base_params: {}
      fit_params: {}
      search_space:
        n_estimators: {type: int, low: 400, high: 1200}
        max_depth: {type: categorical, choices: [4, 5, 6]}  # âœ… RIDOTTO - rimossi 7, 8, -1
        learning_rate: {type: float, low: 0.01, high: 0.08, log: true}  # âœ… RIDOTTO da 0.1
        num_leaves: {type: int, low: 16, high: 40}  # âœ… RIDOTTO max da 63
        subsample: {type: float, low: 0.65, high: 0.85}
        colsample_bytree: {type: float, low: 0.65, high: 0.85}
        reg_alpha: {type: float, low: 0.1, high: 50.0, log: true}  # âœ… AUMENTATO min
        reg_lambda: {type: float, low: 1.0, high: 100.0, log: true}  # âœ… AUMENTATO min
        min_child_samples: {type: int, low: 50, high: 200}  # âœ… AUMENTATO min da 20
        min_split_gain: {type: float, low: 0.0, high: 0.5}  # âœ… RIDOTTO max da 1.0

    # ========================================
    # GRADIENT BOOSTING (sklearn) - REGULARIZZATO
    # ========================================
    gbr:
      enabled: false  # âš¡ Disabilitato per test rapidi
      profile: tree
      trials: *trials_advanced
      base_params: {}
      fit_params: {}
      search_space:
        learning_rate: {type: float, low: 0.01, high: 0.08, log: true}  # âœ… RIDOTTO
        n_estimators: {type: int, low: 300, high: 1000}  # âœ… RIDOTTO max da 1500
        max_depth: {type: int, low: 2, high: 6}  # âœ… RIDOTTO max da 8
        subsample: {type: float, low: 0.6, high: 0.9}
        min_samples_leaf: {type: int, low: 20, high: 60}  # âœ… AUMENTATO min da 1
        max_features: {type: categorical, choices: ["sqrt", "log2", null]}
        min_samples_split: {type: int, low: 10, high: 40}  # âœ… AUMENTATO min da 2
        min_impurity_decrease: {type: float, low: 0.0, high: 0.005}  # âœ… RIDOTTO max

    # ========================================
    # HIST GRADIENT BOOSTING - REGULARIZZATO
    # ========================================
    hgbt:
      enabled: false  # âš¡ Disabilitato per test rapidi
      profile: tree
      trials: *trials_advanced
      base_params: {}
      fit_params: {}
      search_space:
        learning_rate: {type: float, low: 0.01, high: 0.15, log: true}  # âœ… RIDOTTO da 0.3
        max_depth: {type: int, low: 3, high: 10}  # âœ… RIDOTTO max da 16
        max_leaf_nodes: {type: int, low: 15, high: 100}  # âœ… RIDOTTO max da 255
        l2_regularization: {type: float, low: 0.1, high: 10.0, log: true}  # âœ… AUMENTATO min
        max_bins: {type: int, low: 64, high: 200}  # âœ… RIDOTTO max da 255
        min_samples_leaf: {type: int, low: 20, high: 80}  # âœ… AUMENTATO min da 1

    # ========================================
    # RANDOM FOREST - REGULARIZZATO
    # ========================================
    rf:
      enabled: true
      profile: tree
      trials: *trials_advanced
      base_params: {}
      fit_params: {}
      search_space:
        n_estimators: {type: int, low: 300, high: 1000}  # âœ… RIDOTTO max da 1200
        max_depth: {type: int, low: 6, high: 30}  # âœ… AUMENTATO min da 4 (RF meno prone a overfit)
        min_samples_split: {type: int, low: 10, high: 40}  # âœ… AUMENTATO min da 2
        min_samples_leaf: {type: int, low: 5, high: 25}  # âœ… AUMENTATO min da 1
        max_features: {type: categorical, choices: ["sqrt", "log2", null]}
        bootstrap: {type: categorical, choices: [true]}  # âœ… FORZATO true (piÃ¹ robusto)

    # Modelli lineari/KNN/SVR/DT disabilitati (invariato)
    linear:
      enabled: false
    ridge:
      enabled: false
    lasso:
      enabled: false
    elasticnet:
      enabled: false
    knn:
      enabled: false
    svr:
      enabled: false
    dt:
      enabled: false

  # ==========================================
  # SHAP
  # ==========================================
  shap:
    enabled: true
    sample_size: 500
    max_display: 50
    save_plots: true
    save_values: true

  # ==========================================
  # ENSEMBLE - MIGLIORATO
  # ==========================================
  ensembles:
    voting:
      enabled: false        # âš¡ Disabilitato per test rapidi
      top_n: 5
      tune_weights: true
    stacking:
      enabled: true         # âš¡ Mantenuto ma con meno modelli
      top_n: 4              # âš¡ RIDOTTO da 7 (max 4 modelli)
      final_estimator: "ridge"
      cv_folds: 5           # âš¡ RIDOTTO da 10

# ==========================================
# EVALUATION
# ==========================================
evaluation:
  group_metrics:
    enabled: true
    group_by_columns: ['AI_ZonaOmi', 'AI_IdCategoriaCatastale', 'AI_IdTipologiaEdilizia']
    min_group_size: 10
    original_scale: true
    report_metrics: ['r2', 'rmse', 'mse', 'mae', 'mape', 'medae']
    price_band:
      method: 'quantile'
      quantiles: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
      mape_floor: 1000.0
      merge_small_bins: true
      label_prefix: 'PREZZO_'
