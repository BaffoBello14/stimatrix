# üìö INDICE COMPLETO: Analisi Subset Configuration 2022+

**Branch**: `cursor/analyze-and-test-data-subset-176c`  
**Data**: 2025-11-14  
**Status**: ‚úÖ Analisi completata, architettura leak-free verificata

---

## üéØ INIZIA QUI

### Per chi ha fretta (5 min)

üìä **[QUICKSTART_ANALYSIS.md](./QUICKSTART_ANALYSIS.md)**  
‚Üí Guida rapida per eseguire analisi impatto filtri

### Per manager/stakeholder (10 min)

üìã **[EXECUTIVE_SUMMARY_FILTERS.md](./EXECUTIVE_SUMMARY_FILTERS.md)**  
‚Üí Sintesi esecutiva: cosa sono i filtri, perch√©, impatto stimato, raccomandazioni

### Per sviluppatori/data scientist (30 min)

üìñ **[ANALISI_SUBSET_CONFIG_2022.md](./ANALISI_SUBSET_CONFIG_2022.md)**  
‚Üí Analisi approfondita: 654 righe di analisi tecnica completa

---

## üìÑ DOCUMENTI GENERATI

### 1. EXECUTIVE_SUMMARY_FILTERS.md (9.3 KB)

**Contenuto**:
- Configurazione attuale filtri
- Verifica non-leakage (3 livelli)
- Impatto stimato sui dati
- Raccomandazioni prioritarie
- Metriche attese
- Decisione: modello specializzato vs generalizzato
- Piano prossimi passi

**Audience**: Manager, Product Owner, Stakeholder tecnici  
**Tempo lettura**: 10 minuti

### 2. ANALISI_SUBSET_CONFIG_2022.md (21 KB)

**Contenuto**:
- Executive summary
- Dataset overview completo
- Impatto dettagliato filtri (con calcoli)
- Verifica non-leakage approfondita (con codice)
- Top correlazioni con target
- Configurazione training dettagliata
- 6 potenziali problemi + raccomandazioni
- Piano di test completo (4 test suite)
- Checklist deployment
- Conclusioni e riferimenti

**Audience**: Data Scientist, ML Engineer, Developer  
**Tempo lettura**: 30 minuti

### 3. QUICKSTART_ANALYSIS.md (3.5 KB)

**Contenuto**:
- Comandi rapidi per eseguire analisi
- Cosa aspettarsi dall'output
- Filtri configurati
- Threshold critici
- Troubleshooting comune

**Audience**: Tutti (quick reference)  
**Tempo lettura**: 5 minuti

### 4. analyze_filters_impact.py (13 KB)

**Script Python** per analisi automatica:
- Analisi distribuzione temporale
- Simulazione filtri con statistiche dettagliate
- Confronto distribuzioni pre/post filtri
- Warning automatici se dataset troppo piccolo
- Stima split train/val/test

**Usage**:
```bash
python analyze_filters_impact.py
```

**Output**: Report completo su console + verifiche automatiche

---

## üîç ARGOMENTI TRATTATI

### Configurazione

- ‚úÖ Filtri applicati: anno >= 2022, zone escluse (E1/E2/E3/R1), no ville
- ‚úÖ Motivazione: ridurre temporal drift, focus urbano, escludi nicchie
- ‚úÖ Modalit√† applicazione: pre-split (no leakage)

### Verifica Non-Leakage

- ‚úÖ Filtri applicati pre-split temporale
- ‚úÖ Feature contestuali calcolate solo su train (9 feature rimosse)
- ‚úÖ Encoding multi-strategy fit solo su train (test coverage completo)
- ‚úÖ Split temporale preserva ordinamento cronologico

### Dataset

- ‚úÖ 5,733 righe √ó 265 colonne
- ‚úÖ Target: ‚Ç¨62,592 mean, ‚Ç¨42,000 median, skewness 5.16
- ‚úÖ Top feature: AI_Rendita (0.68), AI_Superficie (0.67)
- ‚úÖ 13 zone OMI, 8 categorie catastali

### Impatto Filtri

- ‚úÖ Zone escluse: ~153 righe (2.7%)
- ‚úÖ Tipologie escluse: ~41 righe (0.7%)
- ‚ö†Ô∏è Anno >= 2022: **DA VERIFICARE** (probabile 40-60%)
- ‚ö†Ô∏è Dataset finale stimato: 2,500-4,500 righe

### Raccomandazioni

1. **Immediata**: Eseguire `analyze_filters_impact.py` per conferma dimensioni
2. **Prioritaria**: Se < 3,000 righe ‚Üí usare `config_fast.yaml`
3. **Consigliata**: Baseline comparison (train con e senza filtri)
4. **Opzionale**: Ablation study (quale filtro impatta di pi√π?)

### Training

- ‚úÖ 6 modelli (CatBoost, XGBoost, LightGBM, RF, GBR, HGBT)
- ‚úÖ 150 trial Optuna (config completo) o 5 trial (config fast)
- ‚úÖ Ensemble: Voting (top 5) + Stacking (top 7, Ridge, CV 10-fold)
- ‚úÖ Target transform: Yeo-Johnson (ottimo per skewness 5.16)
- ‚úÖ Outlier detection: Ensemble (IQR + Z-score + Isolation Forest)

---

## üöÄ QUICK ACTIONS

### Analizza Impatto Filtri

```bash
python analyze_filters_impact.py
```

### Training Veloce con Filtri

```bash
python main.py --config fast --steps preprocessing training evaluation
```

### Training Baseline (No Filtri)

```bash
# 1. Disabilita filtri in config.yaml
data_filters:
  anno_min: null
  zone_escluse: null
  tipologie_escluse: null

# 2. Esegui training
python main.py --config fast --steps preprocessing training evaluation
```

### Confronto Metriche

```bash
# Dopo aver eseguito entrambi i training, confronta:
# - R¬≤ (higher is better)
# - RMSE (lower is better)
# - MAPE (lower is better)

# Verifica se filtri migliorano abbastanza da giustificare perdita di generalizzazione
```

---

## üìä METRICHE & THRESHOLD

### Dimensione Dataset

| Righe Finali | Status | Azione |
|--------------|--------|--------|
| **< 2,000** | üö® Critico | Ridurre filtri o complessit√† |
| **2,000-3,000** | ‚ö†Ô∏è Attenzione | Usare `config_fast.yaml` |
| **3,000-4,000** | ‚úÖ Accettabile | Config normale OK |
| **> 4,000** | ‚úÖ Ottimo | Tutti i config OK |

### Miglioramento Atteso

| Scenario | R¬≤ Improvement | RMSE Reduction | Decisione |
|----------|----------------|----------------|-----------|
| **Forte** | > +7 punti | > -20% | ‚úÖ Usa filtri |
| **Medio** | +3-7 punti | -10-20% | ‚ö†Ô∏è Valuta trade-off |
| **Debole** | < +3 punti | < -10% | ‚ùå No filtri |

### Test Coverage

- ‚úÖ `test_encoding_no_leakage.py`: 8 test, 267 righe
- ‚úÖ `test_temporal_split_fix.py`: Split corretto
- ‚úÖ `test_target_transforms.py`: Transform leak-free
- ‚úÖ `test_preprocessing_pipeline.py`: Pipeline completa

---

## üéì CONCLUSIONI CHIAVE

### ‚úÖ Punti di Forza

1. **Architettura robusta**: Fit/transform pattern corretto, no leakage
2. **Test coverage**: Suite completa di test automatici
3. **Configurazione flessibile**: Facile testare diversi subset
4. **Documentazione**: 40+ KB di documentazione tecnica

### ‚ö†Ô∏è Aree di Attenzione

1. **Dataset size**: Verifica che post-filtri sia ‚â• 2,000 righe
2. **Generalizzazione**: Modello non generalizza a zone/tipologie escluse
3. **Temporal drift**: Modello valido solo per periodo 2022+
4. **Hyperparameter tuning**: Con dataset ridotto, 150 trial eccessivi

### üéØ Next Steps

1. ‚úÖ Esegui `analyze_filters_impact.py` ‚Üí conferma fattibilit√†
2. ‚úÖ Train baseline + filtrato ‚Üí confronta metriche
3. ‚úÖ Ablation study ‚Üí identifica filtro pi√π efficace
4. ‚úÖ Production readiness ‚Üí documenta scope e limitazioni

---

## üìû SUPPORTO

### Domande Frequenti

**Q: I filtri causano data leakage?**  
A: ‚ùå NO. Verificato a 3 livelli (filtri pre-split, feature leak-free, encoding corretto).

**Q: Quanto dataset rimane dopo filtri?**  
A: ‚ö†Ô∏è DA VERIFICARE con `analyze_filters_impact.py`. Stima: 2,500-4,500 righe.

**Q: Posso usare config.yaml con dataset ridotto?**  
A: ‚ö†Ô∏è Se < 3,000 righe, meglio usare `config_fast.yaml` (5 trial vs 150).

**Q: Il modello generalizza a tutte le zone?**  
A: ‚ùå NO. Modello specializzato, non generalizza a zone E1/E2/E3/R1 escluse.

**Q: Quali metriche confrontare con baseline?**  
A: ‚úÖ R¬≤, RMSE, MAPE su test set (scala originale).

### Contatti

- **Issues**: [GitHub Issues]
- **Team**: [Data Science Team]
- **Docs**: Questa cartella (`/workspace/`)

---

## üìÅ FILE TREE

```
/workspace/
‚îú‚îÄ‚îÄ INDICE_ANALISI.md                  # ‚Üê Questo file
‚îú‚îÄ‚îÄ QUICKSTART_ANALYSIS.md             # Quick start guide
‚îú‚îÄ‚îÄ EXECUTIVE_SUMMARY_FILTERS.md       # Executive summary
‚îú‚îÄ‚îÄ ANALISI_SUBSET_CONFIG_2022.md      # Analisi approfondita
‚îú‚îÄ‚îÄ analyze_filters_impact.py          # Script analisi automatica
‚îú‚îÄ‚îÄ README.md                          # README principale (aggiornato)
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml                    # Config completo (filtri attivi)
‚îÇ   ‚îî‚îÄ‚îÄ config_fast.yaml               # Config veloce (filtri attivi)
‚îú‚îÄ‚îÄ src/preprocessing/
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py                    # apply_data_filters (linee 98-212)
‚îÇ   ‚îî‚îÄ‚îÄ contextual_features.py         # Leak-free features
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_encoding_no_leakage.py    # 8 test, 267 righe
‚îú‚îÄ‚îÄ notebooks/eda_outputs/
‚îÇ   ‚îú‚îÄ‚îÄ target_statistics.csv          # 5,733 righe, skew 5.16
‚îÇ   ‚îú‚îÄ‚îÄ correlations_with_target.csv   # Top: Rendita 0.68
‚îÇ   ‚îî‚îÄ‚îÄ group_summary_AI_ZonaOmi.csv   # 13 zone, E1/E2/E3/R1 da escludere
‚îî‚îÄ‚îÄ data/raw/
    ‚îî‚îÄ‚îÄ raw.parquet                    # 5,733 righe √ó 265 colonne
```

---

**Analisi completata il**: 2025-11-14  
**Autore**: Claude (Sonnet 4.5)  
**Versione**: 1.0

**Pronto per iniziare?**

```bash
python analyze_filters_impact.py
```
