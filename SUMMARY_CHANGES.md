# üìã Summary Modifiche - Data-Driven Optimization

## üéØ Cosa √à Stato Fatto

Ho implementato **3 modifiche chiave** basate su **analisi data-driven** del dataset:

---

## 1Ô∏è‚É£ **FEATURE PRUNING** (-56 colonne inutili) üóëÔ∏è

### Analisi Eseguita
- ‚úÖ Letta correlation matrix (`notebooks/eda_comprehensive_outputs/correlation_matrix_pearson.csv`)
- ‚úÖ Analizzata SQL query (`sql/base_query.sql`)
- ‚úÖ Identificate colonne ridondanti, costanti, ID, poco predittive

### Colonne Rimosse (Data-Driven)

| Categoria | # Colonne | Esempi | Ragione |
|-----------|-----------|---------|---------|
| **ID e Foreign Keys** | 12 | `A_Id`, `AI_Id`, `PC_Id`, `OZ_Id` | Identificatori univoci (non feature) |
| **Superficie Ridondanti** | 5 | `AI_SuperficieVisuraTotale` (r=1.0 con `AI_Superficie`) | Correlazione > 0.98 |
| **Indicatori Istat Ridondanti** | 7 | `II_ST2_B`, `II_ST21`, `II_ST29` (r > 0.98) | Cluster ad alta correlazione |
| **OmiValori Ridondanti** | 4 | `OV_ValoreMercatoMax_normale` (r=0.98 con Min) | Max vs Min quasi identici |
| **Metadata/Tecnici** | 13 | `A_Semestre`, `A_DataStipula`, `PC_PoligonoMetrico` | Non feature predittive |
| **Codici Catastali** | 8 | `PC_Foglio`, `PC_Particella`, `PC_Subalterno` | Troppi unique, poco predittivi |
| **Privacy/Poco Predittivi** | 7 | `A_EtaMediaAcquirenti`, `A_VenditoriCount` | Scarsa utilit√† predittiva |
| **TOTALE** | **56** | - | **~40% feature in meno** |

### Benefici Attesi
- ‚úÖ **Meno noise**: Modello pi√π robusto e generalizzabile
- ‚úÖ **Meno multicollinearit√†**: Coefficienti pi√π stabili
- ‚úÖ **Training pi√π veloce**: ~40% feature in meno ‚Üí ~30% tempo training
- ‚úÖ **Meno overfitting**: Feature ridondanti causano memorizzazione

---

## 2Ô∏è‚É£ **NUMERIC_COERCION CORRETTO** üîß

### Problema Identificato
```yaml
# PRIMA (ERRATO):
blacklist_globs:
  - 'II_*'  # ‚ùå Blocca TUTTI gli indicatori Istat!
```

**Effetto**: Metriche numeriche come `II_ST1`, `II_P98` (popolazione, densit√†) rimanevano stringhe invece di essere convertite in float ‚Üí modelli lineari/tree non le usavano correttamente!

### Soluzione (Data-Driven)
```yaml
# DOPO (CORRETTO):
blacklist_globs:
  - 'II_IdIstatZonaCensuaria'  # ‚úÖ Solo ID Istat (codice)
  # II_ST1, II_ST2, II_P98, ... ‚Üí CONVERTITI in float (corretto!)
```

**Analisi**: 
- `II_ST*` e `II_P*` sono **metriche numeriche** (es. `II_ST1 = 3245.7` = popolazione)
- `II_IdIstatZonaCensuaria` √® **codice ID** (es. `"123456789"` ‚Üí deve rimanere string)

### Altre Correzioni Blacklist

**Aggiunti pattern pi√π specifici**:
```yaml
- '*Id'               # Tutti gli ID (A_Id, AI_Id, ...)
- '*_Id*'             # Varianti (IdAtto, IdParticella, ...)
- 'AI_ZonaOmi'        # Zona OMI ("D2", "C4") - CATEGORICO
- '*IdCategoriaCatastale*'  # "00210", "00020" - con leading zeros
- '*IdTipologiaEdilizia*'   # "2", "3", "8" - codici categorici
```

**Beneficio**: Le metriche Istat ora sono convertite correttamente in float ‚Üí modelli possono usarle!

---

## 3Ô∏è‚É£ **FEATURE CONTESTUALI** (+44 feature) üéØ

### Cosa Fanno
Aggiungono **contesto di mercato locale** che prima mancava:

**Zone Statistics** (13 feature):
- `zone_price_mean`, `zone_price_median`, `zone_price_std`: Prezzo medio/mediano/std per zona
- `zone_price_q25`, `zone_price_q75`: Quartili
- `price_vs_zone_mean_ratio`: Posizione immobile rispetto a media zona
- `price_zone_zscore`: Z-score nella zona
- ...

**Typology√óZone Statistics** (8 feature):
- `type_zone_price_mean`: Prezzo per tipologia √ó zona (nicchie di mercato)
- `type_zone_rarity`: Quanto √® rara questa combinazione
- ...

**Surface Context** (5 feature):
- `surface_vs_zone_mean`: Superficie relativa alla zona
- `surface_vs_type_zone_mean`: Superficie relativa a tipologia√ózona
- ...

**Interaction Features** (4+ feature):
- `prezzo_mq`: Prezzo al metro quadro
- `prezzo_mq_vs_zone`: Prezzo/mq relativo alla zona
- `log_superficie`: Effetti scala
- ...

**Temporal Context** (7 feature):
- `temporal_price_mean`: Trend temporale prezzi
- `quarter`: Stagionalit√†
- `months_from_start`: Trend lineare
- ...

### Perch√© Aiutano

**PRIMA**: 
```
Modello vede: Immobile 150k‚Ç¨ in zona "D2"
Modello NON sa: 150k‚Ç¨ √® tanto? Poco? Nella media?
```

**DOPO**:
```
Modello vede: 
- Immobile 150k‚Ç¨ in zona "D2"
- Zona D2: prezzo medio 160k‚Ç¨, mediano 155k‚Ç¨
- Questo immobile: 6% sotto media ‚Üí "normale, leggermente economico"
- Prezzo/mq: 2500‚Ç¨/mq vs zona media 2600‚Ç¨/mq ‚Üí "in linea"
```

**Risultato**: Il modello capisce il **contesto** e fa previsioni pi√π accurate!

---

## 4Ô∏è‚É£ **REGULARIZZAZIONE AGGRESSIVA** üõ°Ô∏è

### Problema
**Overfitting MASSICCIO**:
- Gap R¬≤ train-test: 0.214 (21%!)
- RMSE ratio: 2.67x (train 13k‚Ç¨ vs test 37k‚Ç¨)

### Soluzione
Ridotti tutti gli hyperparameter ranges per prevenire overfitting:

**CatBoost** (esempio):
```yaml
depth: 4-10 ‚Üí 4-7                 ‚úÖ RIDOTTO
learning_rate: 0.001-0.3 ‚Üí 0.01-0.12  ‚úÖ RIDOTTO
l2_leaf_reg: 10-100 ‚Üí 3-30        ‚úÖ RIDOTTO
+ early_stopping_rounds: 50       ‚úÖ NUOVO
+ min_data_in_leaf: 20-80         ‚úÖ NUOVO
```

Stesso principio per **XGBoost**, **LightGBM**, **GBR**, **HGBT**, **RF**.

---

## üìä Risultati Attesi (Baseline ‚Üí Target)

### Metriche Test (Scala Originale - EURO)

| Metrica | Baseline | Target | Miglioramento |
|---------|----------|--------|---------------|
| **RMSE** | 36,767‚Ç¨ | 22-26k‚Ç¨ | **-30% a -40%** ‚úÖ‚úÖ |
| **MAE** | 19,811‚Ç¨ | 12-15k‚Ç¨ | **-35% a -40%** ‚úÖ‚úÖ |
| **MAPE** | 58.1% | 25-35% | **-40% a -55%** ‚úÖ‚úÖ‚úÖ |
| **R¬≤** | 0.736 | 0.82-0.87 | **+10% a +18%** ‚úÖ |

### Overfitting

| Metrica | Baseline | Target | Miglioramento |
|---------|----------|--------|---------------|
| **Gap R¬≤** | 0.214 | <0.10 | **-50% a -70%** ‚úÖ‚úÖ |
| **RMSE Ratio** | 2.67x | <1.8x | **-30% a -40%** ‚úÖ |

### Performance Gruppi

**Baseline**: R¬≤ NEGATIVI per fasce prezzo basse, MAPE 134% per zona C4

**Target**: 
- ‚úÖ Tutte zone con R¬≤ > 0.60
- ‚úÖ Tutte fasce prezzo con R¬≤ > 0.40
- ‚úÖ Nessuna zona/fascia con MAPE > 60%

---

## üìÅ File Modificati/Creati

### Creati
```
‚úÖ src/preprocessing/contextual_features.py    (44 feature contestuali)
‚úÖ config/config_optimized.yaml                (config completa ottimizzata)
‚úÖ run_optimization.py                         (script esecuzione automatica)
‚úÖ OPTIMIZATION_GUIDE.md                       (guida dettagliata)
‚úÖ DATA_DRIVEN_ANALYSIS.md                     (analisi data-driven)
‚úÖ QUICK_START_OPTIMIZATION.md                 (quick start)
‚úÖ SUMMARY_CHANGES.md                          (questo file)
```

### Modificati
```
‚úÖ src/preprocessing/pipeline.py  ‚Üí Integrata chiamata a add_all_contextual_features()
```

---

## üöÄ Come Eseguire

### Opzione 1: Script Automatico (CONSIGLIATO)
```bash
python run_optimization.py
```

Fa tutto:
1. ‚úÖ Preprocessing con feature contestuali
2. ‚úÖ Training con regularizzazione aggressiva
3. ‚úÖ Evaluation
4. ‚úÖ Confronto baseline vs ottimizzato

**Tempo**: ~30-45 min (solo CatBoost) o ~2 ore (tutti i modelli)

### Opzione 2: Manuale
```bash
python main.py --config config/config_optimized.yaml --steps preprocessing
python main.py --config config/config_optimized.yaml --steps training
python main.py --config config/config_optimized.yaml --steps evaluation
```

---

## üìã Checklist Modifiche

### Feature Pruning
- [x] Identificate 56 colonne da droppare (data-driven)
- [x] Aggiunte a `config_optimized.yaml` ‚Üí `feature_pruning.drop_columns`
- [x] Categorizzate per ragione (ID, ridondanti, metadata, ecc.)

### Numeric Coercion
- [x] Corretto errore `'II_*'` che bloccava metriche numeriche
- [x] Aggiunti pattern specifici per ID e codici categorici
- [x] Verificato che `II_ST*`, `II_P*` siano convertiti in float

### Feature Contestuali
- [x] Creato modulo `contextual_features.py`
- [x] Implementate 5 funzioni (zone, typology, surface, interactions, temporal)
- [x] Integrato in `pipeline.py` PRIMA dello split temporale
- [x] Testate feature aggiunte (44 totali)

### Regularizzazione
- [x] Ridotti hyperparameter ranges per tutti i modelli tree-based
- [x] Aggiunto early_stopping per CatBoost/XGBoost
- [x] Aumentati constraint min (min_samples_leaf, min_child_weight, ecc.)
- [x] Aumentata CV folds da 5 a 10

### Documentazione
- [x] `OPTIMIZATION_GUIDE.md`: Guida completa
- [x] `DATA_DRIVEN_ANALYSIS.md`: Analisi data-driven feature pruning
- [x] `QUICK_START_OPTIMIZATION.md`: Quick start
- [x] `SUMMARY_CHANGES.md`: Questo summary

---

## ‚úÖ Pronto per Esecuzione

**TUTTO √® pronto**. Ora puoi eseguire:

```bash
# Backup baseline (opzionale)
cp -r models/ models_baseline/

# Run ottimizzazione
python run_optimization.py

# Verifica risultati
cat models/catboost/metrics.json | grep -A 15 metrics_test_original
```

**Atteso**: MAPE da 58% a 25-35%, RMSE da 37k‚Ç¨ a 22-26k‚Ç¨ üéØ

---

**Domande?** Leggi:
- `QUICK_START_OPTIMIZATION.md` per esecuzione rapida
- `DATA_DRIVEN_ANALYSIS.md` per dettagli feature pruning
- `OPTIMIZATION_GUIDE.md` per guida completa e fasi successive
